{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vxLsu_5_Ao80"
   },
   "outputs": [],
   "source": [
    "# %% Deep learning - Section 10.100\n",
    "#    Optimizer comparison\n",
    "\n",
    "# This code pertains a deep learning course provided by Mike X. Cohen on Udemy:\n",
    "#   > https://www.udemy.com/course/deeplearning_x\n",
    "# The \"base\" code in this repository is adapted (with very minor modifications)\n",
    "# from code developed by the course instructor (Mike X. Cohen), while the\n",
    "# \"exercises\" and the \"code challenges\" contain more original solutions and\n",
    "# creative input from my side. If you are interested in DL (and if you are\n",
    "# reading this statement, chances are that you are), go check out the course, it\n",
    "# is singularly good.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eFOW2iaUArr4"
   },
   "outputs": [],
   "source": [
    "# %% Libraries and modules\n",
    "import numpy               as np\n",
    "import matplotlib.pyplot   as plt\n",
    "import torch\n",
    "import torch.nn            as nn\n",
    "import seaborn             as sns\n",
    "import copy\n",
    "import torch.nn.functional as F\n",
    "import pandas              as pd\n",
    "import scipy.stats         as stats\n",
    "import time\n",
    "\n",
    "from torch.utils.data                 import DataLoader,TensorDataset\n",
    "from sklearn.model_selection          import train_test_split\n",
    "from google.colab                     import files\n",
    "from torchsummary                     import summary\n",
    "from IPython                          import display\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5KralTKgSi53"
   },
   "outputs": [],
   "source": [
    "# %% Create data\n",
    "\n",
    "# General params\n",
    "n_by_clust = 300\n",
    "blurring   = 1\n",
    "\n",
    "# Centroids\n",
    "A = [1,1]\n",
    "B = [5,1]\n",
    "C = [4,4]\n",
    "\n",
    "# Generate data\n",
    "a = [ A[0]+np.random.randn(n_by_clust)*blurring, A[1]+np.random.randn(n_by_clust)*blurring ]\n",
    "b = [ B[0]+np.random.randn(n_by_clust)*blurring, B[1]+np.random.randn(n_by_clust)*blurring ]\n",
    "c = [ C[0]+np.random.randn(n_by_clust)*blurring, C[1]+np.random.randn(n_by_clust)*blurring ]\n",
    "\n",
    "# Labels\n",
    "labels_np = np.hstack(( np.zeros((n_by_clust)),\n",
    "                        np.ones((n_by_clust)),\n",
    "                        2*np.ones((n_by_clust)) ))\n",
    "\n",
    "# Data matrix\n",
    "data_np = np.hstack((a,b,c)).T\n",
    "\n",
    "# Data into PyTorch tensors (long format for CCE)\n",
    "data   = torch.tensor(data_np).float()\n",
    "labels = torch.tensor(labels_np).long()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "executionInfo": {
     "elapsed": 714,
     "status": "ok",
     "timestamp": 1748895637274,
     "user": {
      "displayName": "Edoardo Gornetti",
      "userId": "05048424707797899325"
     },
     "user_tz": -120
    },
    "id": "sojlLsx1S5VY",
    "outputId": "76e6faac-c37e-485e-8904-b41ae8da9196"
   },
   "outputs": [],
   "source": [
    "# %% Plotting\n",
    "\n",
    "phi = ( 1 + np.sqrt(5) ) / 2\n",
    "fig = plt.figure(figsize=(6*phi,6))\n",
    "\n",
    "plt.plot(data[np.where(labels==0)[0],0],data[np.where(labels==0)[0],1],'s',alpha=.75)\n",
    "plt.plot(data[np.where(labels==1)[0],0],data[np.where(labels==1)[0],1],'o',alpha=.75)\n",
    "plt.plot(data[np.where(labels==2)[0],0],data[np.where(labels==2)[0],1],'^',alpha=.75)\n",
    "\n",
    "plt.title('Some clusters')\n",
    "plt.xlabel('Dimension 1')\n",
    "plt.ylabel('Dimension 2')\n",
    "plt.grid()\n",
    "\n",
    "plt.savefig('figure76_optimizer_comparison.png')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "files.download('figure76_optimizer_comparison.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GeKupuRqMXWL"
   },
   "outputs": [],
   "source": [
    "# %% Split into train and test data\n",
    "\n",
    "# Split with scikitlearn\n",
    "train_data,test_data,train_labels,test_labels = train_test_split(data,labels,test_size=0.1)\n",
    "\n",
    "# Convert into PyTorch datasets\n",
    "train_data = TensorDataset(train_data,train_labels)\n",
    "test_data  = TensorDataset(test_data,test_labels)\n",
    "\n",
    "# Convert into DataLoader objects\n",
    "batch_size   = 16\n",
    "train_loader = DataLoader(train_data,batch_size=batch_size,shuffle=True,drop_last=True)\n",
    "test_loader  = DataLoader(test_data,batch_size=test_data.tensors[0].shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vp2y6xFMMfsL"
   },
   "outputs": [],
   "source": [
    "# %% Create the model\n",
    "\n",
    "def gen_model(optimizer_alg):\n",
    "\n",
    "    class model(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "\n",
    "            # Architecture\n",
    "            self.input  = nn.Linear(2,8)\n",
    "            self.hid1   = nn.Linear(8,8)\n",
    "            self.output = nn.Linear(8,3)\n",
    "\n",
    "        # Forward propagation\n",
    "        def forward(self,x):\n",
    "            x = F.relu(self.input(x))\n",
    "            x = F.relu(self.hid1(x))\n",
    "            x = self.output(x)\n",
    "\n",
    "            return x\n",
    "\n",
    "    # Model instance\n",
    "    ANN = model()\n",
    "\n",
    "    # Loss function and optimizer (get optimizer attribute)\n",
    "    loss_fun  = nn.CrossEntropyLoss()\n",
    "    opti_fun  = getattr( torch.optim,optimizer_alg )\n",
    "    optimizer = opti_fun(ANN.parameters(),lr=0.1)\n",
    "\n",
    "    return ANN,loss_fun,optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1748898974986,
     "user": {
      "displayName": "Edoardo Gornetti",
      "userId": "05048424707797899325"
     },
     "user_tz": -120
    },
    "id": "IDGEPCweM1un",
    "outputId": "9d3d4ef0-3469-4888-8a1b-43965c489c06"
   },
   "outputs": [],
   "source": [
    "# %% Test momentum\n",
    "\n",
    "# Try 'SGD', 'RMSprop', and 'Adam'\n",
    "optim = gen_model('Adam')[2]\n",
    "print(optim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F2PfHUWfNNiN"
   },
   "outputs": [],
   "source": [
    "# %% Function to train the model\n",
    "\n",
    "def train_model(optimizer_alg):\n",
    "\n",
    "    # Epochs\n",
    "    num_epochs = 50\n",
    "\n",
    "    # Model instance\n",
    "    ANN,loss_fun,optimizer = gen_model(optimizer_alg)\n",
    "\n",
    "    # Initialise\n",
    "    losses    = []\n",
    "    train_acc = []\n",
    "    test_acc  = []\n",
    "\n",
    "    # Epochs loop\n",
    "    for epoch_i in range(num_epochs):\n",
    "\n",
    "        # Train mode on\n",
    "        ANN.train()\n",
    "\n",
    "        # Initialise and loop over batches\n",
    "        batch_losses = []\n",
    "        batch_acc    = []\n",
    "\n",
    "        for X,y in train_loader:\n",
    "\n",
    "            # Forward propagation and loss\n",
    "            yHat = ANN(X)\n",
    "            loss = loss_fun(yHat,y)\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Compute loss and accuracy from this batch\n",
    "            batch_losses.append(loss.item())\n",
    "\n",
    "            matches     = torch.argmax(yHat,axis=1) == y  # booleans\n",
    "            matches_num = matches.float()                 # convert to numbers\n",
    "            acc_percent = 100*torch.mean(matches_num)     # average and percent\n",
    "            batch_acc.append(acc_percent)\n",
    "\n",
    "        # Average train accuracy and losses from batches\n",
    "        train_acc.append(np.mean(batch_acc))\n",
    "        losses.append(np.mean(batch_losses))\n",
    "\n",
    "        # Test accuracy (turn autograd off)\n",
    "        ANN.eval()\n",
    "        X,y = next(iter(test_loader))\n",
    "        with torch.no_grad():\n",
    "            yHat = ANN(X)\n",
    "        test_acc.append( 100*torch.mean((torch.argmax(yHat,axis=1)==y).float()) )\n",
    "\n",
    "    return train_acc,test_acc,losses,ANN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SRsRIv3gS-qn"
   },
   "outputs": [],
   "source": [
    "# %% Function to plot the results\n",
    "\n",
    "def plot_results(optimizer_alg):\n",
    "\n",
    "    # Compute accuracy over entire dataset (train and test) ...\n",
    "    yHat        = ANN(data)\n",
    "    predictions = torch.argmax(yHat,axis=1)\n",
    "    accuracy    = (predictions==labels).float()\n",
    "    total_acc   = torch.mean(100*accuracy).item()\n",
    "\n",
    "    # ... and accuracy by group\n",
    "    accuracy_by_group = np.zeros(3)\n",
    "    for i in range(3):\n",
    "        accuracy_by_group[i] = 100*torch.mean(accuracy[labels==i])\n",
    "\n",
    "    # Create the figure\n",
    "    phi = ( 1 + np.sqrt(5) ) / 2\n",
    "    fig,ax = plt.subplots(2,2,figsize=(6*phi,6))\n",
    "\n",
    "    # Plot the loss function\n",
    "    ax[0,0].plot(losses)\n",
    "    ax[0,0].set_ylabel('Loss')\n",
    "    ax[0,0].set_xlabel('Epoch')\n",
    "    ax[0,0].set_title(f'{optimizer_alg}: Losses')\n",
    "\n",
    "    # plot the accuracy functions\n",
    "    ax[0,1].plot(train_acc,label='Train')\n",
    "    ax[0,1].plot(test_acc,label='Test')\n",
    "    ax[0,1].set_ylabel('Accuracy (%)')\n",
    "    ax[0,1].set_xlabel('Epoch')\n",
    "    ax[0,1].set_title(f'{optimizer_alg}: Accuracy')\n",
    "    ax[0,1].legend()\n",
    "\n",
    "    # Plot overall accuracy by group\n",
    "    ax[1,0].bar(range(3),accuracy_by_group)\n",
    "    ax[1,0].set_ylim([np.min(accuracy_by_group)-5,np.max(accuracy_by_group)+5])\n",
    "    ax[1,0].set_xticks([0,1,2])\n",
    "    ax[1,0].set_xlabel('Group')\n",
    "    ax[1,0].set_ylabel('Accuracy (%)')\n",
    "    ax[1,0].set_title(f'{optimizer_alg}: Accuracy by group')\n",
    "\n",
    "    # Scatterplot of correct and incorrect labeled data\n",
    "    colorShapes = [ 's','o','^' ]\n",
    "    for i in range(3):\n",
    "        ax[1,1].plot(data[labels==i,0],data[labels==i,1],\n",
    "                    colorShapes[i],alpha=.3,label=f'Group {i}')\n",
    "\n",
    "        idxErr = (accuracy==0) & (labels==i)\n",
    "        ax[1,1].plot(data[idxErr,0],data[idxErr,1],'rx')\n",
    "\n",
    "    ax[1,1].set_title(f'{optimizer_alg}: Total accuracy: {total_acc:.2f}%')\n",
    "    ax[1,1].set_xlabel('Dimension 1')\n",
    "    ax[1,1].set_ylabel('Dimension 2')\n",
    "    ax[1,1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig('figure77_optimizer_comparison.png')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    files.download('figure77_optimizer_comparison.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 586
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 5710,
     "status": "ok",
     "timestamp": 1748900147840,
     "user": {
      "displayName": "Edoardo Gornetti",
      "userId": "05048424707797899325"
     },
     "user_tz": -120
    },
    "id": "UGhNbtmIX0vu",
    "outputId": "dd9da8b9-49fe-4864-8032-0c43ef8c1173"
   },
   "outputs": [],
   "source": [
    "# %% Test model once\n",
    "\n",
    "optimizer_type = 'Adam'\n",
    "train_acc,test_acc,losses,ANN = train_model(optimizer_type)\n",
    "plot_results(optimizer_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 15426,
     "status": "ok",
     "timestamp": 1748899835784,
     "user": {
      "displayName": "Edoardo Gornetti",
      "userId": "05048424707797899325"
     },
     "user_tz": -120
    },
    "id": "kgaGZSsrYsOI",
    "outputId": "8bfbf7d6-f783-483f-c466-0c3f05895ddc"
   },
   "outputs": [],
   "source": [
    "# %% Parametric experiment over three optimizer\n",
    "\n",
    "# Average performance\n",
    "performance = []\n",
    "\n",
    "for optimizer in ['SGD','RMSprop','Adam']:\n",
    "\n",
    "    train_acc,test_acc,losses,ANN = train_model(optimizer)\n",
    "    plot_results(optimizer)\n",
    "\n",
    "    train = np.mean(train_acc[-10:])\n",
    "    test  = np.mean(test_acc[-10:])\n",
    "\n",
    "    performance.append(f'{optimizer}: train {train:.1f}%, test {test:.1f}%')\n",
    "\n",
    "print(performance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Fi6sKiwaFda"
   },
   "outputs": [],
   "source": [
    "# %% Exercise 1\n",
    "#    Accuracy seems to be different between the different qwerties categories. Is this consistent across the optimizers?\n",
    "#    Or does it seem like some optimizers are better at some categories? How do you interpret your answer, and what does\n",
    "#    it indicate about metaparameters of DL and their effects on performance?\n",
    "\n",
    "# There are differences across optimizers, I'd guess it's mostly due to randomness\n",
    "# in the training, but it's clearl that the distribution of the data has a role too;\n",
    "# for example in this case there is more overlap between group 1 and 2, and indeed\n",
    "# the classification is lower for either of those two categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TUjNEDLxaQXz"
   },
   "outputs": [],
   "source": [
    "# %% Exercise 2\n",
    "#    The results here indicate that all three optimizers perform roughly equally well, but SGD needs more training. Is\n",
    "#    that still the case with a smaller or larger learning rate?\n",
    "\n",
    "# Trying with lr = 0.001 and lr = 0.1. With lr = 0.001 SGD can't keep up with the\n",
    "# learning and the model basically classify accurately only some of the data,\n",
    "# the performance for RMSprop and Adam is still optimal. With lr = 0.1 all the\n",
    "# models perform quite well, with SGD even slightly better;Â interesting that in\n",
    "# this case the output of Adam is a bit bumpy, I'm not sure whether it's related\n",
    "# to the losses, because the scale of the losses is still quite small\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 586
    },
    "executionInfo": {
     "elapsed": 440,
     "status": "ok",
     "timestamp": 1748899231607,
     "user": {
      "displayName": "Edoardo Gornetti",
      "userId": "05048424707797899325"
     },
     "user_tz": -120
    },
    "id": "JBtq3u9waiB4",
    "outputId": "bd7e2661-3df0-44d4-f4f2-7067b93fe725"
   },
   "outputs": [],
   "source": [
    "# %% Exercise 3\n",
    "#    The method of showing the final performance (printing out a list) is... not very pretty. What kind of visualization\n",
    "#    do you think would better illustrate the performances across the optimizers? Code it!\n",
    "\n",
    "# A bar plot should do the trick\n",
    "\n",
    "# Raw data strings\n",
    "results = performance\n",
    "\n",
    "# Extract info\n",
    "optimizers = []\n",
    "train_acc  = []\n",
    "test_acc   = []\n",
    "\n",
    "for r in results:\n",
    "    parts  = r.split(':')\n",
    "    name   = parts[0]\n",
    "    values = parts[1].split(',')\n",
    "    train  = float(values[0].strip().split()[1].strip('%'))\n",
    "    test   = float(values[1].strip().split()[1].strip('%'))\n",
    "\n",
    "    optimizers.append(name)\n",
    "    train_acc.append(train)\n",
    "    test_acc.append(test)\n",
    "\n",
    "# Bar plot\n",
    "x = np.arange(len(optimizers))\n",
    "width = 0.35\n",
    "\n",
    "phi = ( 1 + np.sqrt(5) ) / 2\n",
    "fig,ax = plt.subplots(figsize=(6*phi,6))\n",
    "\n",
    "ax.grid(axis='y',linestyle='--',alpha=0.6)\n",
    "bars1 = ax.bar(x-width/2,train_acc,width,label='Train accuracy',zorder=2)\n",
    "bars2 = ax.bar(x+width/2,test_acc,width,label='Test accuracy',zorder=2)\n",
    "\n",
    "# Labels and formatting\n",
    "ax.set_ylabel('Accuracy (%)')\n",
    "ax.set_title('Train and test accuracy by optimizer')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(optimizers)\n",
    "ax.set_ylim(85,100)\n",
    "ax.legend()\n",
    "\n",
    "# Annotate bars\n",
    "for bar in bars1 + bars2:\n",
    "    height = bar.get_height()\n",
    "    ax.annotate(f'{height:.1f}%',\n",
    "                xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                xytext=(0, 3),\n",
    "                textcoords=\"offset points\",\n",
    "                ha='center',va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('figure86_optimizer_comparison_extra3.png')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "files.download('figure86_optimizer_comparison_extra3.png')\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPXXCDa1wezfYZ8z5sdFwYT",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
