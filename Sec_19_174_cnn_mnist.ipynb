{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tc0TUnlTsAoF"
      },
      "outputs": [],
      "source": [
        "# %% Deep learning - Section 19.174\n",
        "#    CNN to classify MNIST digits\n",
        "\n",
        "# This code pertains a deep learning course provided by Mike X. Cohen on Udemy:\n",
        "#   > https://www.udemy.com/course/deeplearning_x\n",
        "# The \"base\" code in this repository is adapted (with very minor modifications)\n",
        "# from code developed by the course instructor (Mike X. Cohen), while the\n",
        "# \"exercises\" and the \"code challenges\" contain more original solutions and\n",
        "# creative input from my side. If you are interested in DL (and if you are\n",
        "# reading this statement, chances are that you are), go check out the course, it\n",
        "# is singularly good.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Q549Ew7bsLpw"
      },
      "outputs": [],
      "source": [
        "# %% Libraries and modules\n",
        "import numpy                  as np\n",
        "import matplotlib.pyplot      as plt\n",
        "import torch\n",
        "import torch.nn               as nn\n",
        "import seaborn                as sns\n",
        "import copy\n",
        "import torch.nn.functional    as F\n",
        "import pandas                 as pd\n",
        "import scipy.stats            as stats\n",
        "import sklearn.metrics        as skm\n",
        "import time\n",
        "import sys\n",
        "import imageio.v2             as imageio\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "\n",
        "from torch.utils.data                 import DataLoader,TensorDataset,Dataset\n",
        "from sklearn.model_selection          import train_test_split\n",
        "from google.colab                     import files\n",
        "from torchsummary                     import summary\n",
        "from scipy.stats                      import zscore\n",
        "from sklearn.decomposition            import PCA\n",
        "from scipy.signal                     import convolve2d\n",
        "from torchsummary                     import summary\n",
        "from IPython                          import display\n",
        "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
        "set_matplotlib_formats('svg')\n",
        "plt.style.use('default')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "c9qYXoDzvC9Y"
      },
      "outputs": [],
      "source": [
        "# %% Data\n",
        "\n",
        "# Load data\n",
        "data = np.loadtxt(open('sample_data/mnist_train_small.csv','rb'),delimiter=',')\n",
        "\n",
        "# Split labels from data\n",
        "labels = data[:,0]\n",
        "data   = data[:,1:]\n",
        "\n",
        "# Normalise data (original range is (0,255))\n",
        "data_norm = data / np.max(data)\n",
        "\n",
        "# New here: reshape to 2D actual images\n",
        "data_norm = data_norm.reshape(data_norm.shape[0],1,28,28)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4UHzw7Ox7Z5",
        "outputId": "6173804c-a025-4446-b3eb-5a1c595ee608"
      },
      "outputs": [],
      "source": [
        "# %% Check size\n",
        "\n",
        "print(data_norm.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "5X9PgwZ4vY-A"
      },
      "outputs": [],
      "source": [
        "# %% Create train and test datasets\n",
        "\n",
        "# Convert to tensor (float and integers)\n",
        "data_tensor   = torch.tensor(data_norm).float()\n",
        "labels_tensor = torch.tensor(labels).long()\n",
        "\n",
        "# Split data with scikitlearn (10% test data)\n",
        "train_data,test_data,train_labels,test_labels = train_test_split(data_tensor,labels_tensor,test_size=0.1)\n",
        "\n",
        "# Convert to PyTorch datasets\n",
        "train_data = TensorDataset(train_data,train_labels)\n",
        "test_data  = TensorDataset(test_data,test_labels)\n",
        "\n",
        "# Convert into DataLoader objects\n",
        "batch_size   = 32\n",
        "train_loader = DataLoader(train_data,batch_size=batch_size,shuffle=True,drop_last=True)\n",
        "test_loader  = DataLoader(test_data,batch_size=test_data.tensors[0].shape[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDLVl48gvY7e",
        "outputId": "d82eb461-6873-48fc-fb23-e721910f314b"
      },
      "outputs": [],
      "source": [
        "# %% Check size\n",
        "\n",
        "# Should be (images x channels x width x height)\n",
        "print(train_loader.dataset.tensors[0].shape)\n",
        "print(test_loader.dataset.tensors[0].shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "KC5XsEauvY5L"
      },
      "outputs": [],
      "source": [
        "# %% Function to generate the model\n",
        "\n",
        "def gen_model(printing_toggle=False):\n",
        "\n",
        "    class mnist_CNN(nn.Module):\n",
        "        def __init__(self,printing_toggle):\n",
        "            super().__init__()\n",
        "\n",
        "            # Convolution layer 1\n",
        "            # size = np.floor( (28+2*1-5)/1 )+1 = 26/2 = 13 (divide by 2 because\n",
        "            # will have maxpool with extent 2)\n",
        "            self.conv1 = nn.Conv2d(1,10,kernel_size=5,stride=1,padding=1)\n",
        "\n",
        "            # Convolution layer 2\n",
        "            # size = np.floor( (13+2*1-5)/1 )+1 = 11/2 = 5 (divide by 2 because\n",
        "            # will have maxpool with extent 2)\n",
        "            self.conv2 = nn.Conv2d(10,20,kernel_size=5,stride=1,padding=1)\n",
        "\n",
        "            # Number of units expected in fully connected layer (out of conv2);\n",
        "            # note that c1 layer has no padding nor kernel, so we set those\n",
        "            # params to be 0 and 1 respectively; we can also square because the\n",
        "            # images are squares\n",
        "            expected_size = np.floor( 5+2*0-1 ) + 1\n",
        "            expected_size = 20*int(expected_size**2)\n",
        "\n",
        "            # Fully connected layer\n",
        "            self.fc1 = nn.Linear(expected_size,50)\n",
        "\n",
        "            # Output layer\n",
        "            self.output = nn.Linear(50,10)\n",
        "\n",
        "            # Toggle for the printing of tensor sizes during forward propagation\n",
        "            self.print = printing_toggle\n",
        "\n",
        "        def forward(self,x):\n",
        "\n",
        "            # Print input layer size\n",
        "            print(f'Input size: {x.shape}') if self.print else None\n",
        "\n",
        "            # MaxPool and ReLu on convolution layer 1\n",
        "            x = F.relu(F.max_pool2d(self.conv1(x),2))\n",
        "            print(f'Conv. layer 1 size: {x.shape}') if self.print else None\n",
        "\n",
        "            # MaxPool and ReLu on convolution layer 2\n",
        "            x = F.relu(F.max_pool2d(self.conv2(x),2))\n",
        "            print(f'Conv. layer 2 size: {x.shape}') if self.print else None\n",
        "\n",
        "            # Vectorise for linear layer\n",
        "            n_units = x.shape.numel() / x.shape[0]\n",
        "            x       = x.view(-1,int(n_units))\n",
        "            print(f'Vectorised conv. 2 layer size: {x.shape}') if self.print else None\n",
        "\n",
        "            # Linear and output layers\n",
        "            x = F.relu(self.fc1(x))\n",
        "            print(f'Linear layer size: {x.shape}') if self.print else None\n",
        "            x = self.output(x)\n",
        "            print(f'Output layer size: {x.shape}') if self.print else None\n",
        "\n",
        "            return x\n",
        "\n",
        "    # Create model instance\n",
        "    CNN = mnist_CNN(printing_toggle)\n",
        "\n",
        "    # Loss function\n",
        "    loss_fun = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Optimizer\n",
        "    optimizer = torch.optim.Adam(CNN.parameters(),lr=0.001)\n",
        "\n",
        "    return CNN,loss_fun,optimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRs9IYh1vY2V",
        "outputId": "079294f2-7fee-40f2-da25-1cec3aca6e89"
      },
      "outputs": [],
      "source": [
        "# %% Test the model on one batch\n",
        "\n",
        "CNN,loss_fun,optimizer = gen_model(printing_toggle=True)\n",
        "\n",
        "X,y  = next(iter(train_loader))\n",
        "yHat = CNN(X)\n",
        "\n",
        "# Check sizes of output and target variable\n",
        "print()\n",
        "print(yHat.shape), print()\n",
        "print(y.shape), print()\n",
        "\n",
        "# Check loss\n",
        "loss = loss_fun(yHat,y)\n",
        "print(loss)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F07Q0nl1vYz6",
        "outputId": "d12d7f7d-465c-473e-a2c6-69b845b47ff4"
      },
      "outputs": [],
      "source": [
        "# %% Check all the parameters in the model\n",
        "\n",
        "summary(CNN,(1,28,28))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "eHVB51yV4FK6"
      },
      "outputs": [],
      "source": [
        "# %% Function to train the model\n",
        "\n",
        "# Nothing new on the western front\n",
        "\n",
        "def train_model():\n",
        "\n",
        "    # Parameters, model instance, inizialise vars\n",
        "    num_epochs = 10\n",
        "    CNN,loss_fun,optimizer = gen_model()\n",
        "\n",
        "    losses    = []\n",
        "    train_acc = []\n",
        "    test_acc  = []\n",
        "\n",
        "    # Loop over epochs\n",
        "    for epoch_i in range(num_epochs):\n",
        "\n",
        "        # Loop over training batches\n",
        "        batch_acc  = []\n",
        "        batch_loss = []\n",
        "\n",
        "        for X,y in train_loader:\n",
        "\n",
        "            # Forward propagation and loss\n",
        "            yHat = CNN(X)\n",
        "            loss = loss_fun(yHat,y)\n",
        "\n",
        "            # Backpropagation\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Loss and accuracy from this batch\n",
        "            batch_loss.append(loss.item())\n",
        "\n",
        "            matches     = torch.argmax(yHat,axis=1) == y\n",
        "            matches_num = matches.float()\n",
        "            accuracy    = 100 * torch.mean(matches_num)\n",
        "            batch_acc.append(accuracy)\n",
        "\n",
        "        losses.append( np.mean(batch_loss) )\n",
        "        train_acc.append( np.mean(batch_acc) )\n",
        "\n",
        "        # Test accuracy\n",
        "        CNN.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            X,y = next(iter(test_loader))\n",
        "            yHat = CNN(X)\n",
        "            test_acc.append( 100*torch.mean((torch.argmax(yHat,axis=1)==y).float()) )\n",
        "\n",
        "        CNN.train()\n",
        "\n",
        "    return train_acc,test_acc,losses,CNN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "pi2gG4B-6gfo"
      },
      "outputs": [],
      "source": [
        "# %% Run the model\n",
        "\n",
        "train_acc,test_acc,losses,CNN = train_model()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "id": "hWUENp0S6gBT",
        "outputId": "f5f3df48-acb3-4047-9591-38d75b78a76a"
      },
      "outputs": [],
      "source": [
        "# Plotting\n",
        "\n",
        "# Remember how the FFN could never really go higher than ~95% ?\n",
        "phi = (1 + np.sqrt(5)) / 2\n",
        "fig,ax = plt.subplots(1,2,figsize=(1.5*phi*5,5))\n",
        "\n",
        "ax[0].plot(losses,'s-')\n",
        "ax[0].set_xlabel('Epochs')\n",
        "ax[0].set_ylabel('Loss')\n",
        "ax[0].set_title('Model loss')\n",
        "\n",
        "ax[1].plot(train_acc,'s-',label='Train')\n",
        "ax[1].plot(test_acc,'o-',label='Test')\n",
        "ax[1].set_xlabel('Epochs')\n",
        "ax[1].set_ylabel('Accuracy (%)')\n",
        "ax[1].set_title(f'Final model test accuracy: {test_acc[-1]:.2f}%')\n",
        "ax[1].legend()\n",
        "\n",
        "plt.savefig('figure1_mnist_cnn.png')\n",
        "plt.show()\n",
        "files.download('figure1_mnist_cnn.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "wgqteTEk6f-g"
      },
      "outputs": [],
      "source": [
        "# %% Exercise 1\n",
        "#    Do we need both convolution layers in this model? Comment out the \"conv2\" layers in the mode definition. What else\n",
        "#    needs to be changed in the code for this to work with one convolution layer? Once you get it working, how does the\n",
        "#    accuracy compare between one and two conv layers? (hint: perhaps try adding some more training epochs)\n",
        "\n",
        "# Function to generate the model\n",
        "def gen_model(printing_toggle=False):\n",
        "\n",
        "    class mnist_CNN(nn.Module):\n",
        "        def __init__(self,printing_toggle):\n",
        "            super().__init__()\n",
        "\n",
        "            # Convolution layer 1\n",
        "            self.conv1 = nn.Conv2d(1,10,kernel_size=5,stride=1,padding=1)\n",
        "\n",
        "            # Number of units expected in fully connected layer (out of conv1)\n",
        "            expected_size = np.floor( 13+2*0-1 ) + 1\n",
        "            expected_size = 10*int(expected_size**2)\n",
        "\n",
        "            # Fully connected layer\n",
        "            self.fc1 = nn.Linear(expected_size,50)\n",
        "\n",
        "            # Output layer\n",
        "            self.output = nn.Linear(50,10)\n",
        "\n",
        "            # Toggle for the printing of tensor sizes during forward propagation\n",
        "            self.print = printing_toggle\n",
        "\n",
        "        def forward(self,x):\n",
        "\n",
        "            # Print input layer size\n",
        "            print(f'Input size: {x.shape}') if self.print else None\n",
        "\n",
        "            # MaxPool and ReLu on convolution layer 1\n",
        "            x = F.relu(F.max_pool2d(self.conv1(x),2))\n",
        "            print(f'Conv. layer 1 size: {x.shape}') if self.print else None\n",
        "\n",
        "            # Vectorise for linear layer\n",
        "            n_units = x.shape.numel() / x.shape[0]\n",
        "            x       = x.view(-1,int(n_units))\n",
        "            print(f'Vectorised conv. 1 layer size: {x.shape}') if self.print else None\n",
        "\n",
        "            # Linear and output layers\n",
        "            x = F.relu(self.fc1(x))\n",
        "            print(f'Linear layer size: {x.shape}') if self.print else None\n",
        "            x = self.output(x)\n",
        "            print(f'Output layer size: {x.shape}') if self.print else None\n",
        "\n",
        "            return x\n",
        "\n",
        "    # Create model instance\n",
        "    CNN = mnist_CNN(printing_toggle)\n",
        "\n",
        "    # Loss function\n",
        "    loss_fun = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Optimizer\n",
        "    optimizer = torch.optim.Adam(CNN.parameters(),lr=0.001)\n",
        "\n",
        "    return CNN,loss_fun,optimizer\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
