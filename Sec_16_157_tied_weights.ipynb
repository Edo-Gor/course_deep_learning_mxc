{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y2ZPyPT3D_VG"
      },
      "outputs": [],
      "source": [
        "# %% Deep learning - Section 16.157\n",
        "#    Autoencoders with tied weights\n",
        "\n",
        "# This code pertains a deep learning course provided by Mike X. Cohen on Udemy:\n",
        "#   > https://www.udemy.com/course/deeplearning_x\n",
        "# The \"base\" code in this repository is adapted (with very minor modifications)\n",
        "# from code developed by the course instructor (Mike X. Cohen), while the\n",
        "# \"exercises\" and the \"code challenges\" contain more original solutions and\n",
        "# creative input from my side. If you are interested in DL (and if you are\n",
        "# reading this statement, chances are that you are), go check out the course, it\n",
        "# is singularly good.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "oIWD8TazEUtR"
      },
      "outputs": [],
      "source": [
        "# %% Libraries and modules\n",
        "import numpy               as np\n",
        "import matplotlib.pyplot   as plt\n",
        "import torch\n",
        "import torch.nn            as nn\n",
        "import seaborn             as sns\n",
        "import copy\n",
        "import torch.nn.functional as F\n",
        "import pandas              as pd\n",
        "import scipy.stats         as stats\n",
        "import sklearn.metrics     as skm\n",
        "import time\n",
        "import sys\n",
        "\n",
        "from torch.utils.data                 import DataLoader,TensorDataset\n",
        "from sklearn.model_selection          import train_test_split\n",
        "from google.colab                     import files\n",
        "from torchsummary                     import summary\n",
        "from scipy.stats                      import zscore\n",
        "from sklearn.decomposition            import PCA\n",
        "from IPython                          import display\n",
        "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
        "set_matplotlib_formats('svg')\n",
        "plt.style.use('default')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1y-Gx6lJxi3M",
        "outputId": "038744b3-a8fb-49bc-81f3-e4a4f961362d"
      },
      "outputs": [],
      "source": [
        "# %% A brief aside on Linear and Parameter classes\n",
        "\n",
        "# Input and weights with nn.Parameter()\n",
        "X  = torch.rand(10,50)\n",
        "W1 = nn.Parameter(torch.rand(128,50))\n",
        "\n",
        "# Print some info\n",
        "print(W1)\n",
        "print()\n",
        "\n",
        "print(W1.shape)\n",
        "print(W1.t().shape)\n",
        "print()\n",
        "\n",
        "# Compute an output\n",
        "Y = X@W1.t()\n",
        "print(Y.shape),print(),print()\n",
        "\n",
        "# Input and weights with nn.Linear()\n",
        "W2 = nn.Linear(128,50)\n",
        "print()\n",
        "\n",
        "# Print some info\n",
        "print(W2)\n",
        "print()\n",
        "\n",
        "print(W2.weight.shape)\n",
        "print(W2.weight.t().shape)\n",
        "print()\n",
        "\n",
        "# Compute an output\n",
        "Y = X @ (W2.weight)\n",
        "print(Y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-xhUP3txiwc",
        "outputId": "bf292057-3523-4f10-b6de-bb768d233a87"
      },
      "outputs": [],
      "source": [
        "# %% Notice the swapped order\n",
        "\n",
        "# With nn.Parameter() the size of W is [output,input], while with nn.Linear we\n",
        "# have [input,output]; once more, freaking Python chaos\n",
        "print(W1.shape)\n",
        "print(W2.weight.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Z12g_IqNxiqm"
      },
      "outputs": [],
      "source": [
        "# %% See all attributes of Linear class\n",
        "\n",
        "dir(nn.Linear)\n",
        "\n",
        "# When Linear uses Parameter the order is swapped\n",
        "??nn.Linear.forward\n",
        "??nn.Linear.__init__\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "UyPPtljBxij6"
      },
      "outputs": [],
      "source": [
        "# %% Data\n",
        "\n",
        "# Load data\n",
        "data = np.loadtxt(open('sample_data/mnist_train_small.csv','rb'),delimiter=',')\n",
        "\n",
        "# Split labels from data\n",
        "labels = data[:,0]\n",
        "data   = data[:,1:]\n",
        "\n",
        "# Normalise data (original range is (0,255))\n",
        "data_norm = data / np.max(data)\n",
        "\n",
        "# Convert to tensor\n",
        "data_tensor = torch.tensor(data_norm).float()\n",
        "labels_tensor = torch.tensor(labels).long()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "YbMNmCzHxihL"
      },
      "outputs": [],
      "source": [
        "# %% Model class\n",
        "\n",
        "def gen_model():\n",
        "\n",
        "    class mnist_AE(nn.Module):\n",
        "        def __init__(self):\n",
        "            super().__init__()\n",
        "\n",
        "            # Architecture (tied weights with nn.Parameter(); initialise some\n",
        "            # random weights)\n",
        "            self.input  = nn.Linear(784,128)\n",
        "            self.encode = nn.Parameter(torch.randn(50,128))\n",
        "            #self.encode = nn.Linear(128, 50)\n",
        "            #self.mid    = nn.Linear( 50,128)\n",
        "            self.decode = nn.Linear(128,784)\n",
        "\n",
        "        # Forward propagation (with tied weights)\n",
        "        def forward(self,x):\n",
        "\n",
        "            # Normal first step\n",
        "            x = F.relu(self.input(x))\n",
        "\n",
        "            # Second pass (direct multiplication)\n",
        "            x = x.t()\n",
        "            x = F.relu(self.encode @ x)\n",
        "\n",
        "            # Mirror decoding layer (transpose back)\n",
        "            x = F.relu(self.encode.t() @ x)\n",
        "            x = x.t()\n",
        "\n",
        "            # Normal final step\n",
        "            x = torch.sigmoid(self.decode(x))\n",
        "\n",
        "            return x\n",
        "\n",
        "    # Generate model instance\n",
        "    ANN = mnist_AE()\n",
        "\n",
        "    # Loss function\n",
        "    loss_fun = nn.MSELoss()\n",
        "\n",
        "    # Optimizer\n",
        "    optimizer = torch.optim.Adam(ANN.parameters(),lr=0.001)\n",
        "\n",
        "    return ANN,loss_fun,optimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3oyjXJX2WO2",
        "outputId": "91c43a2a-fb9b-4969-aa34-63c9c5faf1f3"
      },
      "outputs": [],
      "source": [
        "# %% Test on some data\n",
        "\n",
        "ANN,loss_fun,optimizer = gen_model()\n",
        "\n",
        "X = data_tensor[:5,:]\n",
        "yHat = ANN(X)\n",
        "\n",
        "print(X.shape)\n",
        "print(yHat.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "Pz1Fx0MN2V01"
      },
      "outputs": [],
      "source": [
        "# %% Function to train the model\n",
        "\n",
        "def train_model(ANN,loss_fun,optimizer):\n",
        "\n",
        "    # Parameters, inizialise vars\n",
        "    num_epochs = 10000\n",
        "    losses     = []\n",
        "\n",
        "    # Loop over epochs (no minibatch loop)\n",
        "    for epoch_i in range(num_epochs):\n",
        "\n",
        "        # Select only a random subset of images\n",
        "        random_i = np.random.choice(data_tensor.shape[0],size=32)\n",
        "        X        = data_tensor[random_i,:]\n",
        "\n",
        "        # Forward propagation and loss\n",
        "        yHat = ANN(X)\n",
        "        loss = loss_fun(yHat,X)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Loss in this epoch\n",
        "        losses.append(loss.item())\n",
        "\n",
        "    return losses,ANN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "6uDxi20LJHUr"
      },
      "outputs": [],
      "source": [
        "# %% Train and fit\n",
        "\n",
        "ANN,loss_fun,optimizer = gen_model()\n",
        "losses,ANN             = train_model(ANN,loss_fun,optimizer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "JHZ0KzIEJHSH",
        "outputId": "65ae8b85-2b53-4e0a-b96f-a7f7ae2dbeb8"
      },
      "outputs": [],
      "source": [
        "# %% Plotting\n",
        "\n",
        "phi = (1 + np.sqrt(5)) / 2\n",
        "fig = plt.figure(figsize=(phi*5,5))\n",
        "\n",
        "plt.plot(losses,'-')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Model loss')\n",
        "plt.title('Model loss over epochs\\n(tied weights)')\n",
        "\n",
        "plt.savefig('figure47_tied_weights.png')\n",
        "plt.show()\n",
        "files.download('figure47_tied_weights.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "dL2TrpGWJHPl",
        "outputId": "c31878a3-35fa-488f-958a-d24ecf65d0a6"
      },
      "outputs": [],
      "source": [
        "# %% Plotting\n",
        "\n",
        "X = data_tensor[:5,:]\n",
        "yHat = ANN(X)\n",
        "\n",
        "phi = (1 + np.sqrt(5)) / 2\n",
        "fig,axs = plt.subplots(2,5,figsize=(1.5*phi*5,5))\n",
        "\n",
        "for i in range(5):\n",
        "    axs[0,i].imshow(X[i,:].view(28,28).detach() ,cmap='gray')\n",
        "    axs[1,i].imshow(yHat[i,:].view(28,28).detach() ,cmap='gray')\n",
        "    axs[0,i].set_xticks([]), axs[0,i].set_yticks([])\n",
        "    axs[1,i].set_xticks([]), axs[1,i].set_yticks([])\n",
        "\n",
        "plt.suptitle('Post-training performance')\n",
        "\n",
        "plt.savefig('figure48_tied_weights.png')\n",
        "plt.show()\n",
        "files.download('figure48_tied_weights.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "8FvjRtW8JNPh",
        "outputId": "df9164f1-b7a4-4151-8c60-8233eba2d0c0"
      },
      "outputs": [],
      "source": [
        "# %% Add noise\n",
        "\n",
        "# Get a small set of images and add uniform noise to simulate a noisy input\n",
        "X       = data_tensor[:10,:]\n",
        "X_noise = X + torch.rand_like(X)/4\n",
        "\n",
        "# clip at 1 to maintain normalisation\n",
        "X_noise[X_noise>1] = 1\n",
        "\n",
        "# Plotting\n",
        "phi = (1 + np.sqrt(5)) / 2\n",
        "fig,axs = plt.subplots(2,5,figsize=(1.5*phi*5,5))\n",
        "\n",
        "for i in range(5):\n",
        "    axs[0,i].imshow(X[i,:].view(28,28).detach() ,cmap='gray')\n",
        "    axs[1,i].imshow(X_noise[i,:].view(28,28).detach() ,cmap='gray')\n",
        "    axs[0,i].set_xticks([]), axs[0,i].set_yticks([])\n",
        "    axs[1,i].set_xticks([]), axs[1,i].set_yticks([])\n",
        "\n",
        "plt.suptitle('Noisy data')\n",
        "\n",
        "plt.savefig('figure49_tied_weights.png')\n",
        "plt.show()\n",
        "files.download('figure49_tied_weights.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "5Ce4e5NGJNMF",
        "outputId": "eb3a82a8-162f-4375-8724-3e3570d27492"
      },
      "outputs": [],
      "source": [
        "# %% Run the model on simulated noisy data\n",
        "\n",
        "# Model pass\n",
        "Y = ANN(X_noise)\n",
        "\n",
        "# Plotting\n",
        "phi = (1 + np.sqrt(5)) / 2\n",
        "fig,axs = plt.subplots(3,10,figsize=(1.5*phi*5,5))\n",
        "\n",
        "for i in range(10):\n",
        "    axs[0,i].imshow(X[i,:].view(28,28).detach(),cmap='gray')\n",
        "    axs[1,i].imshow(X_noise[i,:].view(28,28).detach(),cmap='gray')\n",
        "    axs[2,i].imshow(Y[i,:].view(28,28).detach(),cmap='gray')\n",
        "    axs[0,i].set_xticks([]), axs[0,i].set_yticks([])\n",
        "    axs[1,i].set_xticks([]), axs[1,i].set_yticks([])\n",
        "    axs[2,i].set_xticks([]), axs[2,i].set_yticks([])\n",
        "\n",
        "plt.suptitle('Reconstruction of noisy data')\n",
        "\n",
        "plt.savefig('figure50_tied_weights.png')\n",
        "plt.show()\n",
        "files.download('figure50_tied_weights.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "8OA4eTgOKAW-"
      },
      "outputs": [],
      "source": [
        "# %% Exercise 1\n",
        "#    The network we built here is not a truly mirrored network: We tied the encoder/decoder layers, but left the input\n",
        "#    and output layers separate. That's not wrong or bad or anything; it's just a choice. Modify the code to create\n",
        "#    a truly mirrored network, where all decoding layers are tied to their corresponding encoding layers.\n",
        "\n",
        "# Model class\n",
        "def gen_model():\n",
        "\n",
        "    class mnist_AE(nn.Module):\n",
        "        def __init__(self):\n",
        "            super().__init__()\n",
        "\n",
        "            # Architecture (tied weights with nn.Parameter())\n",
        "            self.input  = nn.Parameter(torch.randn(128,784))\n",
        "            self.encode = nn.Parameter(torch.randn(50,128))\n",
        "\n",
        "        # Forward propagation (with tied weights)\n",
        "        def forward(self,x):\n",
        "\n",
        "            # Encoder part\n",
        "            x = x.t()\n",
        "            x = F.relu(self.input @ x)\n",
        "            x = F.relu(self.encode @ x)\n",
        "\n",
        "            # Decoder (mirrored) part\n",
        "            x = F.relu(self.encode.t() @ x)\n",
        "            x = torch.sigmoid(self.input.t() @ x)\n",
        "            x = x.t()\n",
        "\n",
        "            return x\n",
        "\n",
        "    # Generate model instance\n",
        "    ANN = mnist_AE()\n",
        "\n",
        "    # Loss function\n",
        "    loss_fun = nn.MSELoss()\n",
        "\n",
        "    # Optimizer\n",
        "    optimizer = torch.optim.Adam(ANN.parameters(),lr=0.001)\n",
        "\n",
        "    return ANN,loss_fun,optimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "U-TLo67lKARx"
      },
      "outputs": [],
      "source": [
        "# %% Exercise 2\n",
        "#    You don't need to use nn.Parameter; you can still accomplish what we did by using nn.Linear and extracting the\n",
        "#    weights matrices. Rewrite the code to use nn.Linear instead of nn.Parameter.\n",
        "\n",
        "# Model class\n",
        "def gen_model():\n",
        "\n",
        "    class mnist_AE(nn.Module):\n",
        "        def __init__(self):\n",
        "            super().__init__()\n",
        "\n",
        "            # Architecture (tied weights with nn.Parameter())\n",
        "            self.input  = nn.Linear(784,128)\n",
        "            self.encode = nn.Linear(128, 50, bias=False)\n",
        "            self.decode = nn.Linear(128,784)\n",
        "\n",
        "        def forward(self,x):\n",
        "\n",
        "            # First layer\n",
        "            x = F.relu(self.input(x))\n",
        "\n",
        "            # Encoder\n",
        "            x = F.relu(self.encode(x))\n",
        "\n",
        "            # Decoder (mirrored)\n",
        "            x = F.relu(x @ self.encode.weight)\n",
        "\n",
        "            # Output layer\n",
        "            x = torch.sigmoid(self.decode(x))\n",
        "\n",
        "            return x\n",
        "\n",
        "    # Generate model instance\n",
        "    ANN = mnist_AE()\n",
        "\n",
        "    # Loss function\n",
        "    loss_fun = nn.MSELoss()\n",
        "\n",
        "    # Optimizer\n",
        "    optimizer = torch.optim.Adam(ANN.parameters(),lr=0.001)\n",
        "\n",
        "    return ANN,loss_fun,optimizer\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
