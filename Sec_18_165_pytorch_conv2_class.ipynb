{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tc0TUnlTsAoF"
      },
      "outputs": [],
      "source": [
        "# %% Deep learning - Section 18.165\n",
        "#    The Conv2d class in PyTorch\n",
        "\n",
        "# This code pertains a deep learning course provided by Mike X. Cohen on Udemy:\n",
        "#   > https://www.udemy.com/course/deeplearning_x\n",
        "# The \"base\" code in this repository is adapted (with very minor modifications)\n",
        "# from code developed by the course instructor (Mike X. Cohen), while the\n",
        "# \"exercises\" and the \"code challenges\" contain more original solutions and\n",
        "# creative input from my side. If you are interested in DL (and if you are\n",
        "# reading this statement, chances are that you are), go check out the course, it\n",
        "# is singularly good.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Q549Ew7bsLpw"
      },
      "outputs": [],
      "source": [
        "# %% Libraries and modules\n",
        "import numpy               as np\n",
        "import matplotlib.pyplot   as plt\n",
        "import torch\n",
        "import torch.nn            as nn\n",
        "import seaborn             as sns\n",
        "import copy\n",
        "import torch.nn.functional as F\n",
        "import pandas              as pd\n",
        "import scipy.stats         as stats\n",
        "import sklearn.metrics     as skm\n",
        "import time\n",
        "import sys\n",
        "import imageio.v2          as imageio\n",
        "\n",
        "from torch.utils.data                 import DataLoader,TensorDataset\n",
        "from sklearn.model_selection          import train_test_split\n",
        "from google.colab                     import files\n",
        "from torchsummary                     import summary\n",
        "from scipy.stats                      import zscore\n",
        "from sklearn.decomposition            import PCA\n",
        "from scipy.signal                     import convolve2d\n",
        "from IPython                          import display\n",
        "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
        "set_matplotlib_formats('svg')\n",
        "plt.style.use('default')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_mk9yFdodI4",
        "outputId": "5bf5d3f8-ea6c-4b18-c2b2-8927aa8405a3"
      },
      "outputs": [],
      "source": [
        "# %% When using PyTorch, convolutions will be most likely run via the class Conv2d\n",
        "\n",
        "# Parameters\n",
        "chans_in  = 3   # (RGB)\n",
        "chans_out = 15  # (feature maps)\n",
        "krn_size  = 5   # (odd; 15 kernels of size 5x5)\n",
        "stride    = 1   # (no stride if =1)\n",
        "padding   = 0   # (no padding if =0)\n",
        "\n",
        "# Class instance (not dissimilar from nn.Linear)\n",
        "c = nn.Conv2d(chans_in,chans_out,krn_size,stride,padding)\n",
        "\n",
        "print(c),print()\n",
        "\n",
        "# Check weight tensor\n",
        "print(f'Weights size: {c.weight.shape}')\n",
        "print(f'Bias size: {c.bias.shape}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "id": "fDqr12aKrVJc",
        "outputId": "ea953a1b-4168-4f0c-f359-99f66d962015"
      },
      "outputs": [],
      "source": [
        "# What do these kernels look like?\n",
        "\n",
        "phi = (1 + np.sqrt(5)) / 2\n",
        "fig,axs = plt.subplots(3,5,figsize=(phi*5,5))\n",
        "\n",
        "for i,ax in enumerate(axs.flatten()):\n",
        "    ax.imshow(torch.squeeze(c.weight[i,0,:,:]).detach(),cmap='plasma')\n",
        "    ax.set_title(f'L1(0) -> L2 ({i+1})')\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.savefig('figure21_convolution.png')\n",
        "plt.show()\n",
        "files.download('figure21_convolution.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "ExH_9T7xrVGF",
        "outputId": "aa42d309-c127-424d-8b3d-205eb3b5d68f"
      },
      "outputs": [],
      "source": [
        "# %% Convolve an image\n",
        "\n",
        "# Image (N images, RGB, width, height)\n",
        "img_size = (1,3,64,64)\n",
        "img      = torch.rand(img_size)\n",
        "\n",
        "# PyTorch wants channels first, but matplotlib wants channels last. So, tensors\n",
        "# dims order must be permuted to visualize\n",
        "img2view = img.permute(2,3,1,0).numpy()\n",
        "print(img.shape)\n",
        "print(img2view.shape)\n",
        "\n",
        "plt.imshow(np.squeeze(img2view));\n",
        "\n",
        "# convolve the image with the filter bank (set of 'chans_out' kernels)\n",
        "conv_out = c(img)\n",
        "\n",
        "print(img.shape)\n",
        "print(conv_out.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "J3xU2qKMrVD5",
        "outputId": "8b69a615-80f4-4a3b-9917-384f28cda13b"
      },
      "outputs": [],
      "source": [
        "# %% Plotting\n",
        "\n",
        "phi = (1 + np.sqrt(5)) / 2\n",
        "fig,axs = plt.subplots(3,5,figsize=(phi*5,5))\n",
        "\n",
        "for i,ax in enumerate(axs.flatten()):\n",
        "\n",
        "    # extract feature map of the current convolution result\n",
        "    I = torch.squeeze(conv_out[0,i,:,:]).detach()\n",
        "\n",
        "    ax.imshow(I,cmap='plasma')\n",
        "    ax.set_title(f'Conv. filter {i+1}')\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.suptitle('Convolving noise with noise')\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.savefig('figure22_convolution.png')\n",
        "plt.show()\n",
        "files.download('figure22_convolution.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6JUbo7LVrU6n"
      },
      "outputs": [],
      "source": [
        "# %% Exercise 1\n",
        "#    Spend a few minutes changing the padding and stride parameters, and observe how those change the size of the result\n",
        "#    of convolution (variable convRes). In the upcoming CodeChallenge, we'll look into this more rigorously, but it's\n",
        "#    useful to have some initial familiarity.\n",
        "\n",
        "# Change params in the top cell\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
