{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wXpeehXZypvO"
      },
      "outputs": [],
      "source": [
        "# %% Deep learning - Section 14.136\n",
        "#    FFN project 1: a gratuitously complex adding machine\n",
        "#    1) Build an FFN that can add 2 integers between -10 and 10\n",
        "#    2) Input is 2 integers, output their sum\n",
        "#    3) You are free to select the architecture and the metaparameters\n",
        "#    4) Once the model is built, run it 10 times and report performance\n",
        "#    5) Visualise true and predicted sums (round to integer)\n",
        "\n",
        "# This code pertains a deep learning course provided by Mike X. Cohen on Udemy:\n",
        "#   > https://www.udemy.com/course/deeplearning_x\n",
        "# The \"base\" code in this repository is adapted (with very minor modifications)\n",
        "# from code developed by the course instructor (Mike X. Cohen), while the\n",
        "# \"exercises\" and the \"code challenges\" contain more original solutions and\n",
        "# creative input from my side. If you are interested in DL (and if you are\n",
        "# reading this statement, chances are that you are), go check out the course, it\n",
        "# is singularly good.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOF67jQJzQGb"
      },
      "outputs": [],
      "source": [
        "# %% Libraries and modules\n",
        "import numpy               as np\n",
        "import matplotlib.pyplot   as plt\n",
        "import torch\n",
        "import torch.nn            as nn\n",
        "import seaborn             as sns\n",
        "import copy\n",
        "import torch.nn.functional as F\n",
        "import pandas              as pd\n",
        "import scipy.stats         as stats\n",
        "import sklearn.metrics     as skm\n",
        "import time\n",
        "\n",
        "from torch.utils.data                 import DataLoader,TensorDataset\n",
        "from sklearn.model_selection          import train_test_split\n",
        "from google.colab                     import files\n",
        "from torchsummary                     import summary\n",
        "from IPython                          import display\n",
        "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
        "set_matplotlib_formats('svg')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YD94ud26-PmX"
      },
      "outputs": [],
      "source": [
        "# %% Function to generate the data\n",
        "\n",
        "def gen_dataset(sample_number=20):\n",
        "\n",
        "    # Generate the pairs of integers and get their true sum\n",
        "    data   = np.random.randint(low=-10,high=11,size=(sample_number,2))\n",
        "    labels = np.sum(data,axis=1)\n",
        "\n",
        "    # Covert to tensor (add extra col to labels)\n",
        "    data_T   = torch.tensor(data).float()\n",
        "    labels_T = torch.tensor(labels).float().view(-1,1)\n",
        "\n",
        "    # Split data with scikitlearn (train, dev, test)\n",
        "    train_data,tmp_data, train_labels,tmp_labels = train_test_split(data_T,labels_T,test_size=0.2)\n",
        "    dev_data,test_data, dev_labels,test_labels   = train_test_split(tmp_data,tmp_labels,test_size=0.5)\n",
        "\n",
        "    # PyTorch datasets\n",
        "    train_data = TensorDataset(train_data,train_labels)\n",
        "    dev_data   = TensorDataset(dev_data,dev_labels)\n",
        "    test_data  = TensorDataset(test_data,test_labels)\n",
        "\n",
        "    # DataLoader objects\n",
        "    batch_size   = 16\n",
        "    train_loader = DataLoader(train_data,batch_size=batch_size,shuffle=True)\n",
        "    dev_loader   = DataLoader(dev_data,batch_size=dev_data.tensors[0].shape[0])\n",
        "    test_loader  = DataLoader(test_data,batch_size=test_data.tensors[0].shape[0])\n",
        "\n",
        "    return train_loader,dev_loader,test_loader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GuvhgtexCWAo"
      },
      "outputs": [],
      "source": [
        "# %% Test data function\n",
        "\n",
        "train_loader,_,_ = gen_dataset(sample_number=50)\n",
        "\n",
        "print(f\"Int pairs:\\n{train_loader.dataset.tensors[0]}\")\n",
        "print()\n",
        "print(f\"True sums:\\n{train_loader.dataset.tensors[1]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LKA2VZlUDjPN"
      },
      "outputs": [],
      "source": [
        "# %% Model class\n",
        "\n",
        "# Optional parametrised metaparameters:\n",
        "#  > number of layers and of units per layer\n",
        "#  > starting learning rate\n",
        "#  > optimizer (e.g. 'SGD', 'RMSprop', or 'Adam')\n",
        "#  > L2 regularisation\n",
        "#  > activation function (e.g., 'ReLU', 'LeakyReLU', 'ReLU6', or 'GELU')\n",
        "\n",
        "def gen_model(n_units=16,n_layers=2,lr=0.01,optim='SGD',L2_lambda=0,act_fun='ReLU'):\n",
        "\n",
        "    class model(nn.Module):\n",
        "        def __init__(self,n_units,n_layers):\n",
        "            super().__init__()\n",
        "\n",
        "            # Dictionary to store the layers and the activation function\n",
        "            self.layers  = nn.ModuleDict()\n",
        "            self.nLayers = n_layers\n",
        "            self.act_fun = act_fun\n",
        "\n",
        "            # Architecture (input, hidden, output)\n",
        "            # Input layer\n",
        "            self.layers['input'] = nn.Linear(2,n_units)\n",
        "\n",
        "            # Hidden layers\n",
        "            for i in range(n_layers):\n",
        "                self.layers[f'hidden{i}'] = nn.Linear(n_units,n_units)\n",
        "\n",
        "            # Output layer\n",
        "            self.layers['output'] = nn.Linear(n_units,1)\n",
        "\n",
        "        def forward(self,x):\n",
        "\n",
        "            # Input layer\n",
        "            x = self.layers['input'](x)\n",
        "\n",
        "            # Hidden layers (fetch selected activation function)\n",
        "            act_fun = getattr(torch.nn,self.act_fun)()\n",
        "            for i in range(self.nLayers):\n",
        "                x = act_fun(self.layers[f'hidden{i}'](x))\n",
        "\n",
        "            # Output layer\n",
        "            x = self.layers['output'](x)\n",
        "\n",
        "            return x\n",
        "\n",
        "    # Model instance, loss function, and optimizer\n",
        "    ANN       = model(n_units,n_layers)\n",
        "    loss_fun  = nn.MSELoss()\n",
        "    opti_fun  = getattr( torch.optim,optim )\n",
        "    optimizer = opti_fun(ANN.parameters(),lr=lr,weight_decay=L2_lambda)\n",
        "\n",
        "    return ANN,loss_fun,optimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "GLglLFVZHMTY"
      },
      "outputs": [],
      "source": [
        "# %% Test model function\n",
        "\n",
        "n_units   = 16\n",
        "n_layers  = 2\n",
        "lr        = 0.01\n",
        "optim_alg = 'Adam'\n",
        "L2_decay  = 0.01\n",
        "act_fun   = 'ReLU'\n",
        "\n",
        "ANN,loss_fun,optimizer = gen_model(n_units,n_layers,lr,optim_alg,L2_decay,act_fun)\n",
        "print(ANN)\n",
        "print(loss_fun)\n",
        "print(optimizer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6Jcgq0XJNaO"
      },
      "outputs": [],
      "source": [
        "# %% Function to train the model\n",
        "\n",
        "# Optional parametrised metaparameters:\n",
        "#  > number of epochs\n",
        "#  > tol is hard-coded but set the tolerance to consider a prediction coorect\n",
        "\n",
        "def train_model(num_epochs=50):\n",
        "\n",
        "    # Epochs and fresh model instance\n",
        "    num_epochs = num_epochs\n",
        "    ANN,loss_fun,optimizer = gen_model(n_units,n_layers,lr,optim,L2_lambda,act_fun)\n",
        "\n",
        "    # Preallocate vars\n",
        "    train_loss  = torch.zeros(num_epochs)\n",
        "    train_psacc = torch.zeros(num_epochs)\n",
        "    dev_loss    = torch.zeros(num_epochs)\n",
        "    dev_psacc   = torch.zeros(num_epochs)\n",
        "\n",
        "    # Loop over epochs\n",
        "    for epoch_i in range(num_epochs):\n",
        "\n",
        "        # Loop over training data batches\n",
        "        batch_loss = []\n",
        "        batch_acc  = []\n",
        "\n",
        "        for X,y in train_loader:\n",
        "\n",
        "            # Forward pass, backpropagation, and optimizer step\n",
        "            yHat = ANN(X)\n",
        "            loss = loss_fun(yHat,y)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Loss and pseudo-accuracy from this batch\n",
        "            batch_loss.append(loss.item())\n",
        "            tol = 0.1\n",
        "            batch_acc.append( 100*torch.mean((torch.abs(yHat-y)<tol).float()) )\n",
        "\n",
        "        train_loss[epoch_i]  = np.mean(batch_loss).item()\n",
        "        train_psacc[epoch_i] = np.mean(batch_acc).item()\n",
        "\n",
        "        # Test loss and pseudo-accuracy\n",
        "        ANN.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            X,y  = next(iter(dev_loader))\n",
        "            yHat = ANN(X)\n",
        "            tol  = 0.1\n",
        "            dev_loss[epoch_i]  = loss_fun(yHat,y)\n",
        "            dev_psacc[epoch_i] = 100*torch.mean((torch.abs(yHat-y)<tol).float())\n",
        "\n",
        "        ANN.train()\n",
        "\n",
        "    return train_loss,train_psacc,dev_loss,dev_psacc,ANN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8YtCCgdNtWu"
      },
      "outputs": [],
      "source": [
        "# %% Test the whole setting\n",
        "\n",
        "# Generate data\n",
        "train_loader,dev_loader,test_loader = gen_dataset(sample_number=3000)\n",
        "\n",
        "# Set parameters and generate model\n",
        "n_units    = 32\n",
        "n_layers   = 2\n",
        "lr         = 0.0001\n",
        "optim      = 'SGD'\n",
        "L2_lambda  = 0\n",
        "act_fun    = 'ReLU'\n",
        "num_epochs = 100\n",
        "\n",
        "ANN,loss_fun,optimizer = gen_model( n_units   = n_units,\n",
        "                                    n_layers  = n_layers,\n",
        "                                    lr        = lr,\n",
        "                                    optim     = optim,\n",
        "                                    L2_lambda = L2_lambda,\n",
        "                                    act_fun   = act_fun )\n",
        "\n",
        "# Train model\n",
        "train_loss,train_psacc,dev_loss,dev_psacc,ANN = train_model(num_epochs=num_epochs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586
        },
        "id": "6lz6lfi6lzRA",
        "outputId": "64aef7d7-6dbc-4321-a750-ad24edd8eae6"
      },
      "outputs": [],
      "source": [
        "# %% Plotting\n",
        "\n",
        "phi = (1 + np.sqrt(5)) / 2\n",
        "fig,axs = plt.subplots(1,2,figsize=(1.5*phi*6,6))\n",
        "\n",
        "# Train loss\n",
        "l1 = axs[0].plot(train_loss.numpy(),label=\"Loss\")[0]\n",
        "axs[0].set_yscale(\"log\")\n",
        "axs[0].set_ylim(1e-3,1e-1)\n",
        "axs[0].set_title(\"Training set loss and pseudo-accuracy\")\n",
        "axs[0].set_xlabel(\"Epoch\")\n",
        "axs[0].set_ylabel(\"MSE loss (log-scaled)\")\n",
        "\n",
        "ax0b = axs[0].twinx()\n",
        "l2 = ax0b.plot(train_psacc.numpy(),label=\"Pseudo-acc\",color='tab:orange')[0]\n",
        "ax0b.set_ylim(0,102)\n",
        "\n",
        "axs[0].legend(handles=[l1,l2],loc='center right')\n",
        "\n",
        "# Dev loss\n",
        "l3 = axs[1].plot(dev_loss.numpy(),label=\"Loss\")[0]\n",
        "axs[1].set_yscale(\"log\")\n",
        "axs[1].set_ylim(1e-3,1e-1)\n",
        "axs[1].set_title(\"Development set loss and pseudo-accuracy\")\n",
        "axs[1].set_xlabel(\"Epoch\")\n",
        "\n",
        "ax1b = axs[1].twinx()\n",
        "l4 = ax1b.plot(dev_psacc.numpy(),label=\"Pseudo-acc\",color='tab:orange')[0]\n",
        "ax1b.set_ylim(0,102)\n",
        "ax1b.set_ylabel(\"Pseudoaccuracy\")\n",
        "\n",
        "axs[1].legend(handles=[l3,l4],loc='center right')\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.savefig('figure1_ffn_project_1.png')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "files.download('figure1_ffn_project_1.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "ngjyMKc2ymSZ",
        "outputId": "2263d38a-02df-48ee-e54f-3e69b6f71aaa"
      },
      "outputs": [],
      "source": [
        "# %% Test the model on the proper test set\n",
        "\n",
        "# Get predictions from test set\n",
        "ANN.eval()\n",
        "with torch.no_grad():\n",
        "    X,y   = next(iter(test_loader))\n",
        "    preds = ANN(X)\n",
        "\n",
        "\n",
        "# Flatten dimentions, get correct prediction (within tolerance) and accuracy\n",
        "tolerance = 0.1\n",
        "y_true    = y.numpy().ravel()\n",
        "y_pred    = preds.numpy().ravel()\n",
        "correct   = np.abs(y_pred-y_true)<=tolerance\n",
        "\n",
        "pseudo_acc = 100*torch.mean((torch.abs(preds-y)<=tolerance).float())\n",
        "\n",
        "# Plotting (true values, correct values, and wrong values within tollerance)\n",
        "phi = (1 + np.sqrt(5)) / 2\n",
        "plt.figure(figsize=(1.5*phi*6,6))\n",
        "\n",
        "plt.plot(y_true,label=\"True Sum\",marker='o',markerfacecolor='None',linestyle='',color='tab:blue',zorder=1)\n",
        "\n",
        "plt.scatter(np.where(correct)[0],y_pred[correct],color='green',marker='x',label=f\"Predicted (|error| ≤ {tolerance})\")\n",
        "plt.scatter(np.where(~correct)[0],y_pred[~correct],color='red',marker='x',label=f\"Predicted (|error| > {tolerance})\")\n",
        "\n",
        "plt.title(f\"True vs. predicted sums in test set (pseudo-accuracy = {pseudo_acc:.2f}%)\")\n",
        "plt.xlabel(\"Sample index\")\n",
        "plt.ylabel(\"Sum\")\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.3)\n",
        "\n",
        "plt.savefig('figure2_ffn_project_1.png')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "files.download('figure2_ffn_project_1.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NstNCojByl6M",
        "outputId": "40ac2527-8675-4660-cc75-4bb832992934"
      },
      "outputs": [],
      "source": [
        "# %% Check reproducibility on a few runs\n",
        "\n",
        "# Generate data and set parameters\n",
        "train_loader,dev_loader,test_loader = gen_dataset(sample_number=3000)\n",
        "\n",
        "n_units    = 32\n",
        "n_layers   = 2\n",
        "lr         = 0.0001\n",
        "optim      = 'SGD'\n",
        "L2_lambda  = 0\n",
        "act_fun    = 'ReLU'\n",
        "num_epochs = 100\n",
        "\n",
        "# Loop\n",
        "for i in range(10):\n",
        "\n",
        "    ANN,loss_fun,optimizer = gen_model( n_units   = n_units,\n",
        "                                        n_layers  = n_layers,\n",
        "                                        lr        = lr,\n",
        "                                        optim     = optim,\n",
        "                                        L2_lambda = L2_lambda,\n",
        "                                        act_fun   = act_fun )\n",
        "\n",
        "    train_loss,train_psacc,dev_loss,dev_psacc,ANN = train_model(num_epochs=num_epochs)\n",
        "\n",
        "    print(f\"Model instance {i+1}, final train pseudo-accuracy = {torch.mean(train_psacc[-5:]):.1f}%, final dev pseudo-accuracy = {torch.mean(dev_psacc[-5:]):.1f}%\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
