{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ah8yDU4CwjG6"
      },
      "outputs": [],
      "source": [
        "# %% Deep learning - Section 18.166\n",
        "#    Code challenge 26: choose the parameters\n",
        "#\n",
        "#    1) Solve the problems listed below\n",
        "\n",
        "# This code pertains a deep learning course provided by Mike X. Cohen on Udemy:\n",
        "#   > https://www.udemy.com/course/deeplearning_x\n",
        "# The \"base\" code in this repository is adapted (with very minor modifications)\n",
        "# from code developed by the course instructor (Mike X. Cohen), while the\n",
        "# \"exercises\" and the \"code challenges\" contain more original solutions and\n",
        "# creative input from my side. If you are interested in DL (and if you are\n",
        "# reading this statement, chances are that you are), go check out the course, it\n",
        "# is singularly good.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9HBC0_hUxBZT"
      },
      "outputs": [],
      "source": [
        "# %% Libraries and modules\n",
        "import numpy               as np\n",
        "import matplotlib.pyplot   as plt\n",
        "import torch\n",
        "import torch.nn            as nn\n",
        "import seaborn             as sns\n",
        "import copy\n",
        "import torch.nn.functional as F\n",
        "import pandas              as pd\n",
        "import scipy.stats         as stats\n",
        "import sklearn.metrics     as skm\n",
        "import time\n",
        "import sys\n",
        "import imageio.v2          as imageio\n",
        "\n",
        "from torch.utils.data                 import DataLoader,TensorDataset\n",
        "from sklearn.model_selection          import train_test_split\n",
        "from google.colab                     import files\n",
        "from torchsummary                     import summary\n",
        "from scipy.stats                      import zscore\n",
        "from sklearn.decomposition            import PCA\n",
        "from scipy.signal                     import convolve2d\n",
        "from IPython                          import display\n",
        "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
        "set_matplotlib_formats('svg')\n",
        "plt.style.use('default')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyFARs3SxBXM",
        "outputId": "73c57e9d-8937-480f-b70e-6d14ce5b07a0"
      },
      "outputs": [],
      "source": [
        "# %% Problem 0\n",
        "#    Convolve an image of size 1x256x256 to produce a 1x252x84 result\n",
        "\n",
        "# Parameters\n",
        "chans_in  = 3          # (RGB)\n",
        "chans_out = 15         # (feature maps)\n",
        "img_size  = [256,256]  # (input img size)\n",
        "krn_size  = 5          # (odd; 15 kernels of size 5x5)\n",
        "stride    = (1,3)      # (no stride if =1)\n",
        "padding   = 1          # (no padding if =0)\n",
        "\n",
        "# Class instance\n",
        "c = nn.Conv2d(chans_in,chans_out,krn_size,stride,padding)\n",
        "\n",
        "# Generate image\n",
        "img = torch.rand(1,chans_in,img_size[0],img_size[1])\n",
        "\n",
        "# Run convolution and compute its actual shape\n",
        "conv_img       = c(img)\n",
        "size_empirical = torch.squeeze(conv_img).shape\n",
        "\n",
        "# Compute the theoretical size of the result according to the formula\n",
        "size_expected    = np.array([chans_out,0,0],dtype=int)\n",
        "size_expected[1] = np.floor( (img_size[0]+2*padding-krn_size)/stride[0] ) + 1\n",
        "size_expected[2] = np.floor( (img_size[1]+2*padding-krn_size)/stride[1] ) + 1\n",
        "\n",
        "# Check\n",
        "print(f'Expected size: {size_expected}')\n",
        "print(f'Empirical size: {list(size_empirical)}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdBQK7HrxBUn",
        "outputId": "4f7b2847-c0fb-4148-9918-30638131d4e8"
      },
      "outputs": [],
      "source": [
        "# %% Problem 1\n",
        "#    Convolve an image of size 3x64x64 to produce a 10x28x28 result\n",
        "\n",
        "# Parameters\n",
        "chans_in  = 3          # (RGB)\n",
        "chans_out = 10         # (feature maps)\n",
        "img_size  = [64,64]    # (input img size)\n",
        "krn_size  = 13         # (odd; 15 kernels of size 5x5)\n",
        "stride    = (2,2)      # (no stride if =1)\n",
        "padding   = 2          # (no padding if =0)\n",
        "\n",
        "# Class instance\n",
        "c = nn.Conv2d(chans_in,chans_out,krn_size,stride,padding)\n",
        "\n",
        "# Generate image\n",
        "img = torch.rand(1,chans_in,img_size[0],img_size[1])\n",
        "\n",
        "# Run convolution and compute its actual shape\n",
        "conv_img       = c(img)\n",
        "size_empirical = torch.squeeze(conv_img).shape\n",
        "\n",
        "# Compute the theoretical size of the result according to the formula\n",
        "size_expected    = np.array([chans_out,0,0],dtype=int)\n",
        "size_expected[1] = np.floor( (img_size[0]+2*padding-krn_size)/stride[0] ) + 1\n",
        "size_expected[2] = np.floor( (img_size[1]+2*padding-krn_size)/stride[1] ) + 1\n",
        "\n",
        "# Check\n",
        "print(f'Expected size: {size_expected}')\n",
        "print(f'Empirical size: {list(size_empirical)}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5EfDWqqcxtaP",
        "outputId": "f47f398d-dd39-4c2f-92d4-e5ab80aa420a"
      },
      "outputs": [],
      "source": [
        "# %% Problem 2\n",
        "#    Convolve an image of size 3x196x96 to produce a 5x66x49 result\n",
        "\n",
        "# Parameters\n",
        "chans_in  = 3         # (RGB)\n",
        "chans_out = 5         # (feature maps)\n",
        "img_size  = [196,96]  # (input img size)\n",
        "krn_size  = 5         # (odd; 15 kernels of size 5x5)\n",
        "stride    = (3,2)     # (no stride if =1)\n",
        "padding   = 3         # (no padding if =0)\n",
        "\n",
        "# Class instance\n",
        "c = nn.Conv2d(chans_in,chans_out,krn_size,stride,padding)\n",
        "\n",
        "# Generate image\n",
        "img = torch.rand(1,chans_in,img_size[0],img_size[1])\n",
        "\n",
        "# Run convolution and compute its actual shape\n",
        "conv_img       = c(img)\n",
        "size_empirical = torch.squeeze(conv_img).shape\n",
        "\n",
        "# Compute the theoretical size of the result according to the formula\n",
        "size_expected    = np.array([chans_out,0,0],dtype=int)\n",
        "size_expected[1] = np.floor( (img_size[0]+2*padding-krn_size)/stride[0] ) + 1\n",
        "size_expected[2] = np.floor( (img_size[1]+2*padding-krn_size)/stride[1] ) + 1\n",
        "\n",
        "# Check\n",
        "print(f'Expected size: {size_expected}')\n",
        "print(f'Empirical size: {list(size_empirical)}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q505ijmrxtYX",
        "outputId": "47f36e0e-69dd-4c31-fdf9-f92871aacd98"
      },
      "outputs": [],
      "source": [
        "# %% Problem 3\n",
        "#    Convolve an image of size 1x32x32 to produce a 6x28x28 result\n",
        "\n",
        "# Parameters\n",
        "chans_in  = 1         # (RGB)\n",
        "chans_out = 6         # (feature maps)\n",
        "img_size  = [32,32]   # (input img size)\n",
        "krn_size  = 9         # (odd; 15 kernels of size 5x5)\n",
        "stride    = (1,1)      # (no stride if =1)\n",
        "padding   = 2         # (no padding if =0)\n",
        "\n",
        "# Class instance\n",
        "c = nn.Conv2d(chans_in,chans_out,krn_size,stride,padding)\n",
        "\n",
        "# Generate image\n",
        "img = torch.rand(1,chans_in,img_size[0],img_size[1])\n",
        "\n",
        "# Run convolution and compute its actual shape\n",
        "conv_img       = c(img)\n",
        "size_empirical = torch.squeeze(conv_img).shape\n",
        "\n",
        "# Compute the theoretical size of the result according to the formula\n",
        "size_expected    = np.array([chans_out,0,0],dtype=int)\n",
        "size_expected[1] = np.floor( (img_size[0]+2*padding-krn_size)/stride[0] ) + 1\n",
        "size_expected[2] = np.floor( (img_size[1]+2*padding-krn_size)/stride[1] ) + 1\n",
        "\n",
        "# Check\n",
        "print(f'Expected size: {size_expected}')\n",
        "print(f'Empirical size: {list(size_empirical)}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBvPrGsvxtVT",
        "outputId": "2eaadce0-e99d-4a09-f764-4a4ca9416854"
      },
      "outputs": [],
      "source": [
        "# %% Problem 4\n",
        "#    Convolve an image of size 3x227x227 to produce a 96x55x55 result\n",
        "\n",
        "# Parameters\n",
        "chans_in  = 3          # (RGB)\n",
        "chans_out = 96         # (feature maps)\n",
        "img_size  = [227,227]  # (input img size)\n",
        "krn_size  = 11          # (odd; 15 kernels of size 5x5)\n",
        "stride    = (4,4)      # (no stride if =1)\n",
        "padding   = 1          # (no padding if =0)\n",
        "\n",
        "# Class instance\n",
        "c = nn.Conv2d(chans_in,chans_out,krn_size,stride,padding)\n",
        "\n",
        "# Generate image\n",
        "img = torch.rand(1,chans_in,img_size[0],img_size[1])\n",
        "\n",
        "# Run convolution and compute its actual shape\n",
        "conv_img       = c(img)\n",
        "size_empirical = torch.squeeze(conv_img).shape\n",
        "\n",
        "# Compute the theoretical size of the result according to the formula\n",
        "size_expected    = np.array([chans_out,0,0],dtype=int)\n",
        "size_expected[1] = np.floor( (img_size[0]+2*padding-krn_size)/stride[0] ) + 1\n",
        "size_expected[2] = np.floor( (img_size[1]+2*padding-krn_size)/stride[1] ) + 1\n",
        "\n",
        "# Check\n",
        "print(f'Expected size: {size_expected}')\n",
        "print(f'Empirical size: {list(size_empirical)}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84xrI37IxtTK",
        "outputId": "f369767d-b62c-44ea-9e87-bd572c79e7cf"
      },
      "outputs": [],
      "source": [
        "# %% Problem 5\n",
        "#    Convolve an image of size 3x224x224 to produce a 64x224x224 result\n",
        "\n",
        "# Parameters\n",
        "chans_in  = 3          # (RGB)\n",
        "chans_out = 64         # (feature maps)\n",
        "img_size  = [224,224]  # (input img size)\n",
        "krn_size  = 5          # (odd; 15 kernels of size 5x5)\n",
        "stride    = (1,1)      # (no stride if =1)\n",
        "padding   = 2          # (no padding if =0)\n",
        "\n",
        "# Class instance\n",
        "c = nn.Conv2d(chans_in,chans_out,krn_size,stride,padding)\n",
        "\n",
        "# Generate image\n",
        "img = torch.rand(1,chans_in,img_size[0],img_size[1])\n",
        "\n",
        "# Run convolution and compute its actual shape\n",
        "conv_img       = c(img)\n",
        "size_empirical = torch.squeeze(conv_img).shape\n",
        "\n",
        "# Compute the theoretical size of the result according to the formula\n",
        "size_expected    = np.array([chans_out,0,0],dtype=int)\n",
        "size_expected[1] = np.floor( (img_size[0]+2*padding-krn_size)/stride[0] ) + 1\n",
        "size_expected[2] = np.floor( (img_size[1]+2*padding-krn_size)/stride[1] ) + 1\n",
        "\n",
        "# Check\n",
        "print(f'Expected size: {size_expected}')\n",
        "print(f'Empirical size: {list(size_empirical)}')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
