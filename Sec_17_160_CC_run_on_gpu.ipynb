{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5TXDWD4MRAbu"
      },
      "outputs": [],
      "source": [
        "# %% Deep learning - Section 17.160\n",
        "#    Code challenge 25: run an experiment on a GPU\n",
        "#\n",
        "#    1) Start from code from video 11.111 (mnist dataset)\n",
        "#    2) Train the model on the GPU\n",
        "#    3) Keep track of the time on GPU (it was ~14 mins on CPU)\n",
        "\n",
        "# This code pertains a deep learning course provided by Mike X. Cohen on Udemy:\n",
        "#   > https://www.udemy.com/course/deeplearning_x\n",
        "# The \"base\" code in this repository is adapted (with very minor modifications)\n",
        "# from code developed by the course instructor (Mike X. Cohen), while the\n",
        "# \"exercises\" and the \"code challenges\" contain more original solutions and\n",
        "# creative input from my side. If you are interested in DL (and if you are\n",
        "# reading this statement, chances are that you are), go check out the course, it\n",
        "# is singularly good.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iDe-5uKKR7YT"
      },
      "outputs": [],
      "source": [
        "# %% Libraries and modules\n",
        "import numpy               as np\n",
        "import matplotlib.pyplot   as plt\n",
        "import torch\n",
        "import torch.nn            as nn\n",
        "import seaborn             as sns\n",
        "import copy\n",
        "import torch.nn.functional as F\n",
        "import pandas              as pd\n",
        "import scipy.stats         as stats\n",
        "import time\n",
        "\n",
        "from torch.utils.data                 import DataLoader,TensorDataset\n",
        "from sklearn.model_selection          import train_test_split\n",
        "from google.colab                     import files\n",
        "from torchsummary                     import summary\n",
        "from IPython                          import display\n",
        "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
        "set_matplotlib_formats('svg')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n3iOtmYBSqx0"
      },
      "outputs": [],
      "source": [
        "# %% Note\n",
        "\n",
        "# To run models on a GPU you must select from the menu:\n",
        "#   -> Runtime\n",
        "#     -> Change runtime type\n",
        "#       -> Hardware accelerator\n",
        "#         -> GPU\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rht-znwnSqrE"
      },
      "outputs": [],
      "source": [
        "# %% Use GPU\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pgxI_5u3SFSX"
      },
      "outputs": [],
      "source": [
        "# %% Data\n",
        "\n",
        "# Load data\n",
        "data = np.loadtxt(open('sample_data/mnist_train_small.csv','rb'),delimiter=',')\n",
        "\n",
        "# Split labels from data\n",
        "labels = data[:,0]\n",
        "data   = data[:,1:]\n",
        "\n",
        "# Normalise data (original range is (0,255))\n",
        "data_norm = data / np.max(data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3HdYcslBSLMC"
      },
      "outputs": [],
      "source": [
        "# %% Create train and test datasets\n",
        "\n",
        "# Convert to tensor (float and integers)\n",
        "data_tensor   = torch.tensor(data_norm).float()\n",
        "labels_tensor = torch.tensor(labels).long()\n",
        "\n",
        "# Split data with scikitlearn (10% test data)\n",
        "train_data,test_data,train_labels,test_labels = train_test_split(data_tensor,labels_tensor,test_size=0.1)\n",
        "\n",
        "# Convert to PyTorch datasets\n",
        "train_data = TensorDataset(train_data,train_labels)\n",
        "test_data  = TensorDataset(test_data,test_labels)\n",
        "\n",
        "# Convert into DataLoader objects\n",
        "batch_size   = 32\n",
        "train_loader = DataLoader(train_data,batch_size=batch_size,shuffle=True,drop_last=True)\n",
        "test_loader  = DataLoader(test_data,batch_size=test_data.tensors[0].shape[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "DheUzeKGSQqc"
      },
      "outputs": [],
      "source": [
        "# %% Function to generate the model\n",
        "#    Flexibly loop over model depth/breadth\n",
        "\n",
        "def gen_model(nUnits,nLayers,drop_rate):\n",
        "\n",
        "    class mnist_FFN(nn.Module):\n",
        "        def __init__(self,nUnits,nLayers,dropout_rate):\n",
        "            super().__init__()\n",
        "\n",
        "            # Dictionary to store the layers\n",
        "            self.layers  = nn.ModuleDict()\n",
        "            self.nLayers = nLayers\n",
        "\n",
        "            # Dropout\n",
        "            self.dropout_rate = dropout_rate\n",
        "\n",
        "            # Architecture\n",
        "            self.layers['input'] = nn.Linear(784,nUnits)\n",
        "            for i in range(nLayers):\n",
        "                self.layers[f'hidden{i}'] = nn.Linear(nUnits,nUnits)\n",
        "            self.layers['output'] = nn.Linear(nUnits,10)\n",
        "\n",
        "        # Forward propagation\n",
        "        def forward(self,x):\n",
        "\n",
        "            x = F.relu(self.layers['input'](x))\n",
        "            x = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
        "\n",
        "            for i in range(self.nLayers):\n",
        "                x = F.relu(self.layers[f'hidden{i}'](x))\n",
        "                x = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
        "\n",
        "            x = self.layers['output'](x)\n",
        "\n",
        "            return x\n",
        "\n",
        "    # Create model instance\n",
        "    ANN = mnist_FFN(nUnits,nLayers,drop_rate)\n",
        "\n",
        "    # Loss function\n",
        "    loss_fun = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Optimizer (SGD to slow down learning for illustration purpose)\n",
        "    optimizer = torch.optim.SGD(ANN.parameters(),lr=0.01)\n",
        "\n",
        "    return ANN,loss_fun,optimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "1o2CNj0iSXBO"
      },
      "outputs": [],
      "source": [
        "# %% Function to train the model\n",
        "\n",
        "def train_model(nUnits,nLayers,drop_rate,device=device):\n",
        "\n",
        "    # Parameters, model instance, inizialise vars\n",
        "    num_epochs = 60\n",
        "    ANN,loss_fun,optimizer = gen_model(nUnits,nLayers,drop_rate)\n",
        "\n",
        "    # Ship model to GPU\n",
        "    ANN.to(device)\n",
        "\n",
        "    losses    = []\n",
        "    train_acc = []\n",
        "    test_acc  = []\n",
        "\n",
        "    # Loop over epochs\n",
        "    for epoch_i in range(num_epochs):\n",
        "\n",
        "        # Loop over training batches\n",
        "        batch_acc  = []\n",
        "        batch_loss = []\n",
        "\n",
        "        for X,y in train_loader:\n",
        "\n",
        "            # Ship data to GPU\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            # Forward propagation and loss\n",
        "            yHat = ANN(X)\n",
        "            loss = loss_fun(yHat,y)\n",
        "\n",
        "            # Backpropagation\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Loss and accuracy from this batch (ship data back)\n",
        "            batch_loss.append(loss.item())\n",
        "\n",
        "            yHat = yHat.cpu()\n",
        "            y    = y.cpu()\n",
        "\n",
        "            matches     = torch.argmax(yHat,axis=1) == y\n",
        "            matches_num = matches.float()\n",
        "            accuracy    = 100 * torch.mean(matches_num)\n",
        "            batch_acc.append(accuracy)\n",
        "\n",
        "        losses.append( np.mean(batch_loss) )\n",
        "        train_acc.append( np.mean(batch_acc) )\n",
        "\n",
        "        # Test accuracy\n",
        "        ANN.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            X,y = next(iter(test_loader))\n",
        "\n",
        "            # Ship to GPU (X only, y is only for accuracy)\n",
        "            X = X.to(device)\n",
        "\n",
        "            yHat = ANN(X)\n",
        "\n",
        "            # Ship back\n",
        "            yHat = yHat.cpu()\n",
        "\n",
        "            test_acc.append( 100*torch.mean((torch.argmax(yHat,axis=1)==y).float()) )\n",
        "\n",
        "        ANN.train()\n",
        "\n",
        "    return train_acc,test_acc,losses,ANN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "TOJD1c-kSZP2"
      },
      "outputs": [],
      "source": [
        "# %% Parametric experiment on model depth and breadth\n",
        "#    This cell takes ~ 14 mins on CPU and ~18 mins on CPU\n",
        "\n",
        "# Define model parameters (num of hidden layers and units per hidden layer)\n",
        "num_layers = np.linspace(1,3,3,dtype=int)\n",
        "num_units  = np.linspace(50,250,5,dtype=int)\n",
        "drop_rate  = 0.25\n",
        "\n",
        "# Preallocate output matrices\n",
        "accuracies_train = np.zeros(( len(num_units),len(num_layers) ))\n",
        "accuracies_test  = np.zeros(( len(num_units),len(num_layers) ))\n",
        "training_times   = np.zeros(( len(num_units),len(num_layers) ))\n",
        "\n",
        "# Buckle up, here's the experiment!\n",
        "for unit_i in range(len(num_units)):\n",
        "    for layer_i in range(len(num_layers)):\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Run model and store outputs\n",
        "        train_acc,test_acc,losses,ANN = train_model(num_units[unit_i],num_layers[layer_i],drop_rate)\n",
        "\n",
        "        duration = time.time() - start_time\n",
        "\n",
        "        # Store accuracies as average accuracy over last 5 epochs, and time\n",
        "        accuracies_train[unit_i,layer_i] = np.mean(train_acc[-5:])\n",
        "        accuracies_test[unit_i,layer_i]  = np.mean(test_acc[-5:])\n",
        "        training_times[unit_i,layer_i]   = duration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "id": "dXO4ATb8UoHD",
        "outputId": "49e880d0-1217-40ac-f89c-3282e8f780a6"
      },
      "outputs": [],
      "source": [
        "# %% Plotting\n",
        "\n",
        "phi = ( 1 + np.sqrt(5) ) / 2\n",
        "fig, axs = plt.subplots(1,2,figsize=(1.5*6*phi,6))\n",
        "\n",
        "cmaps = plt.cm.plasma(np.linspace(.2,.9,len(num_layers)))\n",
        "\n",
        "# Plot for Training Accuracy\n",
        "for i, nl in enumerate(num_layers):\n",
        "    axs[0].plot(num_units,accuracies_train[:, i],'-o',color=cmaps[i],label=f'{int(nl)} layers')\n",
        "axs[0].set_title('Training accuracy')\n",
        "axs[0].set_xlabel('Number of units')\n",
        "axs[0].set_ylabel('Accuracy (%)')\n",
        "axs[0].legend(title='Hidden layers')\n",
        "axs[0].grid(True)\n",
        "axs[0].set_ylim(94.8,100.2)\n",
        "\n",
        "# Plot for Test Accuracy\n",
        "for i, nl in enumerate(num_layers):\n",
        "    axs[1].plot(num_units,accuracies_test[:,i],'-o',color=cmaps[i],label=f'{int(nl)} layers')\n",
        "axs[1].set_title('Test accuracy')\n",
        "axs[1].set_xlabel('Number of units')\n",
        "axs[1].set_ylabel('Accuracy (%)')\n",
        "axs[1].legend(title='Hidden layers')\n",
        "axs[1].grid(True)\n",
        "axs[1].set_ylim(94.8,100.2)\n",
        "\n",
        "plt.suptitle('Model performance vs. width and depth', fontsize=14)\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.savefig('figure2_code_challenge_25.png')\n",
        "plt.show()\n",
        "files.download('figure2_code_challenge_25.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "id": "qfIQGtIlUn5l",
        "outputId": "7c1ec508-4a32-4032-f89a-5bb332cf37c1"
      },
      "outputs": [],
      "source": [
        "# %% Plotting\n",
        "\n",
        "phi = ( 1 + np.sqrt(5) ) / 2\n",
        "fig, axs = plt.subplots(1,2,figsize=(1.5*6*phi,6))\n",
        "\n",
        "cmaps = plt.cm.plasma(np.linspace(.2,.9,len(num_units)))\n",
        "\n",
        "# Plot for Training Accuracy\n",
        "for i,n_units in enumerate(num_units):\n",
        "    axs[0].plot(num_layers,accuracies_train[i,:],'-o',color=cmaps[i],label=f'{int(n_units)} units')\n",
        "axs[0].set_title('Training accuracy')\n",
        "axs[0].set_xlabel('Number of hidden layers')\n",
        "axs[0].set_ylabel('Accuracy (%)')\n",
        "axs[0].legend(title='Units per layer')\n",
        "axs[0].grid(True)\n",
        "axs[0].set_ylim(94.8,100.2)\n",
        "\n",
        "# Plot for Test Accuracy\n",
        "for i,n_units in enumerate(num_units):\n",
        "    axs[1].plot(num_layers,accuracies_test[i,:],'-o',color=cmaps[i],label=f'{int(n_units)} units')\n",
        "axs[1].set_title('Test accuracy')\n",
        "axs[1].set_xlabel('Number of hidden layers')\n",
        "axs[1].set_ylabel('Accuracy (%)')\n",
        "axs[1].legend(title='Units per layer')\n",
        "axs[1].grid(True)\n",
        "axs[1].set_ylim(94.8,100.2)\n",
        "\n",
        "plt.suptitle('Model performance vs. breadth and depth',fontsize=14)\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.savefig('figure3_code_challenge_25.png')\n",
        "plt.show()\n",
        "files.download('figure3_code_challenge_25.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 584
        },
        "id": "cDryKYWKUnxs",
        "outputId": "4330b26c-a1c4-414e-fe32-6fc65bffa3bd"
      },
      "outputs": [],
      "source": [
        "# %% Plotting\n",
        "\n",
        "#Plot time matrix\n",
        "fig, ax = plt.subplots(figsize=(phi*6,6))\n",
        "im = ax.imshow(training_times,cmap='plasma',aspect='auto')\n",
        "\n",
        "ax.set_xticks(range(len(num_layers)))\n",
        "ax.set_xticklabels([int(n) for n in num_layers])\n",
        "ax.set_xlabel('Number of Layers')\n",
        "\n",
        "ax.set_yticks(range(len(num_units)))\n",
        "ax.set_yticklabels([int(n) for n in num_units])\n",
        "ax.set_ylabel('Number of Units')\n",
        "\n",
        "cbar = plt.colorbar(im,ax=ax)\n",
        "cbar.set_label('Training time (s)',rotation=270,labelpad=15)\n",
        "\n",
        "threshold = (training_times.max() + training_times.min()) / 2\n",
        "\n",
        "for i in range(len(num_units)):\n",
        "    for j in range(len(num_layers)):\n",
        "        value = training_times[i,j]\n",
        "        ax.text(j,i,f'{value:.0f} s',ha='center',va='center',color='white' if value < threshold else 'black')\n",
        "\n",
        "total_secs = np.sum(training_times)\n",
        "mins       = int(total_secs // 60)\n",
        "secs       = int(total_secs % 60)\n",
        "ax.set_title(f'Training time per model configuration (GPU)\\n(Total time = {mins}:{secs} mins)')\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.savefig('figure4_code_challenge_25.png')\n",
        "plt.show()\n",
        "files.download('figure4_code_challenge_25.png')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
