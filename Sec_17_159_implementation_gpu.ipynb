{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y2ZPyPT3D_VG"
      },
      "outputs": [],
      "source": [
        "# %% Deep learning - Section 17.159\n",
        "#    Implementation\n",
        "\n",
        "# This code pertains a deep learning course provided by Mike X. Cohen on Udemy:\n",
        "#   > https://www.udemy.com/course/deeplearning_x\n",
        "# The \"base\" code in this repository is adapted (with very minor modifications)\n",
        "# from code developed by the course instructor (Mike X. Cohen), while the\n",
        "# \"exercises\" and the \"code challenges\" contain more original solutions and\n",
        "# creative input from my side. If you are interested in DL (and if you are\n",
        "# reading this statement, chances are that you are), go check out the course, it\n",
        "# is singularly good.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "oIWD8TazEUtR"
      },
      "outputs": [],
      "source": [
        "# %% Libraries and modules\n",
        "import torch\n",
        "import time\n",
        "\n",
        "import torch.nn          as nn\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab        import files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U_YITagkepxP"
      },
      "outputs": [],
      "source": [
        "# %% Note\n",
        "\n",
        "# To run models on a GPU you must select from the menu:\n",
        "#   -> Runtime\n",
        "#     -> Change runtime type\n",
        "#       -> Hardware accelerator\n",
        "#         -> GPU\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AyNiwPAGet4I",
        "outputId": "4f057fb3-2a97-4045-9c69-ccaf55275833"
      },
      "outputs": [],
      "source": [
        "# %% Use GPU\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DWYV-SdXet1X"
      },
      "outputs": [],
      "source": [
        "# %% Build a simple model and get some random data\n",
        "\n",
        "ANN = nn.Sequential( nn.Linear(20,100),\n",
        "                     nn.ReLU(),\n",
        "                     nn.Linear(100,500),\n",
        "                     nn.ReLU(),\n",
        "                     nn.Linear(500,30),\n",
        "                     nn.ReLU(),\n",
        "                     nn.Linear(30,2) )\n",
        "\n",
        "data   = torch.randn((1000,20))\n",
        "labels = torch.randint(low=0,high=2,size=(1,1000))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLT6-JOuety6",
        "outputId": "7fafcbbc-9ca9-4625-a4ed-b98257a4c985"
      },
      "outputs": [],
      "source": [
        "# %% Ship model and data to GPU\n",
        "\n",
        "# Ship model\n",
        "ANN.to(device)\n",
        "\n",
        "# Ship data\n",
        "data   = data.to(device)\n",
        "labels = labels.to(device)\n",
        "\n",
        "data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paWfcrhSfrQj",
        "outputId": "47803335-7367-483d-cd2f-636115330736"
      },
      "outputs": [],
      "source": [
        "# %% Data can also be created directly there on the GPU\n",
        "\n",
        "data_GPU = torch.randn((1000,20),device=device)\n",
        "data_CPU = torch.randn((1000,20),device='cpu')\n",
        "\n",
        "print(data.device)\n",
        "print(data_GPU.device)\n",
        "print(data_CPU.device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgozaVrzfrNM",
        "outputId": "74693ff1-601c-488c-b845-9d5406d47556"
      },
      "outputs": [],
      "source": [
        "# %% Get results from the model\n",
        "\n",
        "# Output will still be on the GPU\n",
        "output = ANN(data)\n",
        "output.device\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "rNdvNjQ-hLra",
        "outputId": "4baf80aa-8ce3-4ce2-b1e6-5f7fa87ad101"
      },
      "outputs": [],
      "source": [
        "# %% Some annoyances\n",
        "\n",
        "# Try to plot the GPU data (you need to transfer)\n",
        "# plt.plot(output.detach())\n",
        "plt.plot(output.detach().cpu())\n",
        "\n",
        "plt.savefig('figure1_implementation.png')\n",
        "plt.show()\n",
        "files.download('figure1_implementation.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "88ouXlHCheIJ"
      },
      "outputs": [],
      "source": [
        "# %% Computation time experiment (GPU)\n",
        "\n",
        "# Start the clock\n",
        "start_time = time.process_time()\n",
        "\n",
        "# Move everything, run on GPU, retrieve\n",
        "device = 'cuda:0'\n",
        "ANN.to(device)\n",
        "data   = data.to(device)\n",
        "labels = labels.to(device)\n",
        "output = ANN(data).detach().cpu()\n",
        "\n",
        "# Stop the clock\n",
        "GPU_time = 1000*(time.process_time() - start_time)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "MHWJuGssheFm"
      },
      "outputs": [],
      "source": [
        "# %% Computation time experiment (CPU)\n",
        "\n",
        "# Start the clock\n",
        "start_time = time.process_time()\n",
        "\n",
        "# Move everything, run on GPU, retrieve\n",
        "device = 'cpu'\n",
        "ANN.to(device)\n",
        "data   = data.to(device)\n",
        "labels = labels.to(device)\n",
        "output = ANN(data).detach().cpu()\n",
        "\n",
        "# Stop the clock\n",
        "CPU_time = 1000*(time.process_time() - start_time)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTaZhw2ViCoa",
        "outputId": "a925e0fc-61fb-4def-ffe0-42b130a8480c"
      },
      "outputs": [],
      "source": [
        "# %% Results\n",
        "\n",
        "print(f'GPU time = {GPU_time}')\n",
        "print(f'CPU time = {CPU_time}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUUb-qpaidbH",
        "outputId": "8fc4fa23-5076-474c-942a-c5913865b7c6"
      },
      "outputs": [],
      "source": [
        "# %% Test that it's not just because of sending the model to CPU\n",
        "\n",
        "# Recreate everything on CPU\n",
        "ANN2 = nn.Sequential( nn.Linear(20,100),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(100,500),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(500,30),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(30,2) )\n",
        "\n",
        "data2  = torch.randn((1000,20))\n",
        "\n",
        "start_time = time.process_time()\n",
        "output     = ANN(data2).detach()\n",
        "CPUtime_2  = 1000*(time.process_time() - start_time)\n",
        "\n",
        "print(f'CPU time = {CPUtime_2}')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
