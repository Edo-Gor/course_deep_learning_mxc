{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tc0TUnlTsAoF"
      },
      "outputs": [],
      "source": [
        "# %% Deep learning - Section 19.177\n",
        "#    Examine feature maps activations\n",
        "\n",
        "# This code pertains a deep learning course provided by Mike X. Cohen on Udemy:\n",
        "#   > https://www.udemy.com/course/deeplearning_x\n",
        "# The \"base\" code in this repository is adapted (with very minor modifications)\n",
        "# from code developed by the course instructor (Mike X. Cohen), while the\n",
        "# \"exercises\" and the \"code challenges\" contain more original solutions and\n",
        "# creative input from my side. If you are interested in DL (and if you are\n",
        "# reading this statement, chances are that you are), go check out the course, it\n",
        "# is singularly good.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Q549Ew7bsLpw"
      },
      "outputs": [],
      "source": [
        "# %% Libraries and modules\n",
        "import numpy                  as np\n",
        "import matplotlib.pyplot      as plt\n",
        "import torch\n",
        "import torch.nn               as nn\n",
        "import seaborn                as sns\n",
        "import copy\n",
        "import torch.nn.functional    as F\n",
        "import pandas                 as pd\n",
        "import scipy.stats            as stats\n",
        "import sklearn.metrics        as skm\n",
        "import time\n",
        "import sys\n",
        "import imageio.v2             as imageio\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "\n",
        "from torch.utils.data                 import DataLoader,TensorDataset,Dataset\n",
        "from sklearn.model_selection          import train_test_split\n",
        "from google.colab                     import files\n",
        "from torchsummary                     import summary\n",
        "from scipy.stats                      import zscore\n",
        "from sklearn.decomposition            import PCA\n",
        "from scipy.signal                     import convolve2d\n",
        "from torchsummary                     import summary\n",
        "from IPython                          import display\n",
        "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
        "set_matplotlib_formats('svg')\n",
        "plt.style.use('default')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hwYiO6phzQDF"
      },
      "outputs": [],
      "source": [
        "# %% Generate data\n",
        "\n",
        "# 2D Gaussian params\n",
        "n_per_class = 1000\n",
        "n_classes   = 2\n",
        "img_size    = 91\n",
        "x           = np.linspace(-4,4,img_size)\n",
        "X,Y         = np.meshgrid(x,x)\n",
        "\n",
        "widths      = [1.8,2.4]\n",
        "\n",
        "# Preallocate tensors for images (N,channels,size,size) and labels (N)\n",
        "images  = torch.zeros( n_classes*n_per_class,1,img_size,img_size )\n",
        "labels  = torch.zeros( n_classes*n_per_class )\n",
        "\n",
        "# Generate images\n",
        "for i in range(n_classes*n_per_class):\n",
        "\n",
        "    # Gaussian with random center offset (remainder trick for width, all even\n",
        "    # images go into category 0, all odd images go into category 1)\n",
        "    c = 2*np.random.randn(2)\n",
        "    G = np.exp( -((X-c[0])**2 + (Y-c[1])**2 ) / (2*widths[i%2]**2) )\n",
        "\n",
        "    # Layer some noise\n",
        "    G = G + np.random.randn(img_size,img_size)/5\n",
        "\n",
        "    # Add to tensor\n",
        "    images[i,:,:,:] = torch.tensor(G).view(1,img_size,img_size)\n",
        "    labels[i]       = i%2\n",
        "\n",
        "labels = labels[:,None]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "8Vm12wjvzjcZ",
        "outputId": "827461f2-8e98-41be-eb0d-87031294efd6"
      },
      "outputs": [],
      "source": [
        "# %% Plotting\n",
        "\n",
        "phi = (1 + np.sqrt(5))/2\n",
        "fig,axs = plt.subplots(3,7,figsize=(phi*7,7))\n",
        "\n",
        "for i,ax in enumerate(axs.flatten()):\n",
        "\n",
        "    pic = np.random.randint(2*n_per_class)\n",
        "    G   = np.squeeze( images[pic,:,:] )\n",
        "\n",
        "    ax.imshow(G,vmin=-1,vmax=1,cmap='jet')\n",
        "    ax.set_title('Class %s'%int(labels[pic].item()))\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "\n",
        "plt.savefig('figure17_feature_maps.png')\n",
        "plt.show()\n",
        "files.download('figure17_feature_maps.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "V3vAIrznzjaJ"
      },
      "outputs": [],
      "source": [
        "# %% Create train and test datasets\n",
        "\n",
        "# Split data with scikitlearn (10% test data)\n",
        "train_data,test_data,train_labels,test_labels = train_test_split(images,labels,test_size=0.1)\n",
        "\n",
        "# Convert to PyTorch datasets\n",
        "train_data = TensorDataset(train_data,train_labels)\n",
        "test_data  = TensorDataset(test_data,test_labels)\n",
        "\n",
        "# Convert into DataLoader objects\n",
        "batch_size   = 32\n",
        "train_loader = DataLoader(train_data,batch_size=batch_size,shuffle=True,drop_last=True)\n",
        "test_loader  = DataLoader(test_data,batch_size=test_data.tensors[0].shape[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "NX2guURhzjXZ"
      },
      "outputs": [],
      "source": [
        "# %% Function to generate the model\n",
        "\n",
        "def gen_model():\n",
        "\n",
        "    class mnist_CNN(nn.Module):\n",
        "        def __init__(self):\n",
        "            super().__init__()\n",
        "\n",
        "            # Convolution layer 1\n",
        "            # output size: (91+2*1-3)/1 + 1 = 91\n",
        "            # post-pooling: 91/2 = 45\n",
        "            self.conv1 = nn.Conv2d(1,6,kernel_size=3,stride=1,padding=1)\n",
        "\n",
        "            # Convolution layer 2\n",
        "            # output size: (45+2*1-3)/1 + 1 = 45\n",
        "            # post-pooling: 45/2 = 22\n",
        "            self.conv2 = nn.Conv2d(6,4,kernel_size=3,stride=1,padding=1)\n",
        "\n",
        "            # Fully connected layer\n",
        "            self.fc1 = nn.Linear(22*22*4,50)\n",
        "\n",
        "            # Output layer\n",
        "            self.output = nn.Linear(50,1)\n",
        "\n",
        "        def forward(self,x):\n",
        "\n",
        "            # Adapt to export\n",
        "            # MaxPool and ReLu on convolution layer 1\n",
        "            conv1_act = F.relu(self.conv1(x))\n",
        "            x         = F.avg_pool2d(conv1_act,(2,2))\n",
        "\n",
        "            # MaxPool and ReLu on convolution layer 2\n",
        "            conv2_act = F.relu(self.conv2(x))\n",
        "            x         = F.avg_pool2d(conv2_act,(2,2))\n",
        "\n",
        "            # Vectorise for linear layer\n",
        "            x = torch.flatten(x,start_dim=1)\n",
        "\n",
        "            # Linear and output layers\n",
        "            x = F.relu(self.fc1(x))\n",
        "            x = self.output(x)\n",
        "\n",
        "            return x,conv1_act,conv2_act\n",
        "\n",
        "    # Create model instance\n",
        "    CNN = mnist_CNN()\n",
        "\n",
        "    # Loss function\n",
        "    loss_fun = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    # Optimizer\n",
        "    optimizer = torch.optim.Adam(CNN.parameters(),lr=0.001)\n",
        "\n",
        "    return CNN,loss_fun,optimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFhCEWsfzjVO",
        "outputId": "8d8268a0-7d7c-4345-d6c4-fe4dc438be5b"
      },
      "outputs": [],
      "source": [
        "# %% Test the model on one batch\n",
        "\n",
        "# test the model with one batch\n",
        "CNN,loss_fun,optimizer = gen_model()\n",
        "\n",
        "# test that the model runs and can compute a loss\n",
        "X,y = next(iter(train_loader))\n",
        "yHat,feat_map1,feat_map2 = CNN(X)\n",
        "loss = loss_fun(yHat,y)\n",
        "\n",
        "# check sizes of outputs\n",
        "print('Predicted category:')\n",
        "print(yHat.shape)\n",
        "print('\\nFeature map after conv1')\n",
        "print(feat_map1.shape)\n",
        "print('\\nFeature map after conv2')\n",
        "print(feat_map2.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8ubUJZTHA6B",
        "outputId": "2334fac9-b81c-48f4-97eb-581517e27253"
      },
      "outputs": [],
      "source": [
        "# %% Check all the parameters in the model\n",
        "\n",
        "summary(CNN,(1,img_size,img_size))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "cb9vazKfHA3M"
      },
      "outputs": [],
      "source": [
        "# %% Function to train the model\n",
        "\n",
        "def train_model():\n",
        "\n",
        "    # Parameters, model instance, inizialise vars\n",
        "    num_epochs = 10\n",
        "    CNN,loss_fun,optimizer = gen_model()\n",
        "\n",
        "    train_losses = []\n",
        "    test_losses  = []\n",
        "    train_acc    = []\n",
        "    test_acc     = []\n",
        "\n",
        "    # Loop over epochs\n",
        "    for epoch_i in range(num_epochs):\n",
        "\n",
        "        # Loop over training batches\n",
        "        batch_acc  = []\n",
        "        batch_loss = []\n",
        "\n",
        "        for X,y in train_loader:\n",
        "\n",
        "            # Forward propagation and loss (only select 1st output)\n",
        "            yHat = CNN(X)[0]\n",
        "            loss = loss_fun(yHat,y)\n",
        "\n",
        "            # Backpropagation\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Loss and accuracy from this batch\n",
        "            batch_loss.append(loss.item())\n",
        "            batch_acc.append( torch.mean( ((yHat>0)==y).float() ).item() )\n",
        "\n",
        "        train_losses.append( np.mean(batch_loss) )\n",
        "        train_acc.append( 100*np.mean(batch_acc) )\n",
        "\n",
        "        # Test accuracy\n",
        "        CNN.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            X,y = next(iter(test_loader))\n",
        "            yHat = CNN(X)[0]\n",
        "            loss = loss_fun(yHat,y)\n",
        "\n",
        "            test_acc.append( 100*torch.mean( ((yHat>0)==y).float() ).item() )\n",
        "            test_losses.append(loss.item())\n",
        "\n",
        "        CNN.train()\n",
        "\n",
        "    return train_acc,test_acc,train_losses,test_losses,CNN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "FwcO5uGiHA0R"
      },
      "outputs": [],
      "source": [
        "# %% Run the model\n",
        "\n",
        "# Takes ~30 secs\n",
        "train_acc,test_acc,train_losses,test_losses,CNN = train_model()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "4kqFDK7GHAyM",
        "outputId": "925069ee-8c71-45e8-b7ac-0c42b36092ba"
      },
      "outputs": [],
      "source": [
        "# %% Plotting\n",
        "\n",
        "phi = (1 + np.sqrt(5)) / 2\n",
        "fig,ax = plt.subplots(1,2,figsize=(1.5*phi*6,6))\n",
        "\n",
        "ax[0].plot(train_losses,'s-',label='Train')\n",
        "ax[0].plot(test_losses,'o-',label='Test')\n",
        "ax[0].set_xlabel('Epochs')\n",
        "ax[0].set_ylabel('Loss (MSE)')\n",
        "ax[0].set_title('Model loss')\n",
        "\n",
        "ax[1].plot(train_acc,'s-',label='Train')\n",
        "ax[1].plot(test_acc,'o-',label='Test')\n",
        "ax[1].set_xlabel('Epochs')\n",
        "ax[1].set_ylabel('Accuracy (%)')\n",
        "ax[1].set_title(f'Final model test accuracy: {test_acc[-1]:.2f}%')\n",
        "ax[1].legend()\n",
        "\n",
        "plt.savefig('figure18_feature_maps.png')\n",
        "plt.show()\n",
        "files.download('figure18_feature_maps.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "TXzU9klbNB-z",
        "outputId": "c5f38f3c-bafd-42cb-ce9f-c49be375b369"
      },
      "outputs": [],
      "source": [
        "# %% Plotting\n",
        "\n",
        "# Pass test data through model\n",
        "X,y = next(iter(test_loader))\n",
        "yHat,feat_map1,feat_map2 = CNN(X)\n",
        "\n",
        "# Plot\n",
        "phi = (1 + np.sqrt(5)) / 2\n",
        "fig,axs = plt.subplots(2,10,figsize=(2*phi*5,5))\n",
        "\n",
        "for i,ax in enumerate(axs.flatten()):\n",
        "\n",
        "    G = torch.squeeze( X[i,0,:,:] ).detach()\n",
        "    ax.imshow(G,vmin=-1,vmax=1,cmap='jet')\n",
        "    t = ( int(y[i].item()), int(yHat[i].item()>0) )\n",
        "\n",
        "    ax.set_title('T=%s, P=%s'%t)\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "\n",
        "plt.savefig('figure19_feature_maps.png')\n",
        "plt.show()\n",
        "files.download('figure19_feature_maps.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "id": "lQT66_GwNB8f",
        "outputId": "ff45dac7-8ee4-4a94-b8ce-166da8ef551d"
      },
      "outputs": [],
      "source": [
        "# %% Plotting\n",
        "\n",
        "phi = (1 + np.sqrt(5)) / 2\n",
        "fig,axs = plt.subplots(7,10,figsize=(1.5*phi*6,6))\n",
        "\n",
        "for pic_i in range(10):\n",
        "\n",
        "    # Show the original picture\n",
        "    img = X[pic_i,0,:,:].detach()\n",
        "    axs[0,pic_i].imshow(img,cmap='jet',vmin=0,vmax=1)\n",
        "    axs[0,pic_i].axis('off')\n",
        "    axs[0,pic_i].text(2,2,'T=%s'%int(y[pic_i].item()),ha='left',va='top',color='w',fontweight='bold')\n",
        "\n",
        "    for feat_i in range(6):\n",
        "\n",
        "        # Extract the feature map from this image\n",
        "        img = feat_map1[pic_i,feat_i,:,:].detach()\n",
        "        axs[feat_i+1,pic_i].imshow(img,cmap='plasma',vmin=0,vmax=torch.max(img)*.9)\n",
        "        axs[feat_i+1,pic_i].axis('off')\n",
        "        axs[feat_i+1,pic_i].text(-5,45,feat_i,ha='right') if pic_i==0 else None\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.suptitle('First set of feature map activations for 10 test images',x=.5,y=1.01)\n",
        "\n",
        "plt.savefig('figure20_feature_maps.png')\n",
        "plt.show()\n",
        "files.download('figure20_feature_maps.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "id": "5Wiy4TABNB6A",
        "outputId": "834dc7a1-2d51-44b0-9fa0-8b3e9533e6a6"
      },
      "outputs": [],
      "source": [
        "# %% Plotting\n",
        "\n",
        "phi = (1 + np.sqrt(5)) / 2\n",
        "fig,axs = plt.subplots(5,10,figsize=(1.5*phi*6,6))\n",
        "\n",
        "for pic_i in range(10):\n",
        "\n",
        "    # Show the original picture\n",
        "    img = X[pic_i,0,:,:].detach()\n",
        "    axs[0,pic_i].imshow(img,cmap='jet',vmin=0,vmax=1)\n",
        "    axs[0,pic_i].axis('off')\n",
        "    axs[0,pic_i].text(2,2,'T=%s'%int(y[pic_i].item()),ha='left',va='top',color='w',fontweight='bold')\n",
        "\n",
        "    for feat_i in range(4):\n",
        "\n",
        "        # Extract the feature map from this image\n",
        "        img = feat_map2[pic_i,feat_i,:,:].detach()\n",
        "        axs[feat_i+1,pic_i].imshow(img,cmap='plasma',vmin=0,vmax=torch.max(img)*.9)\n",
        "        axs[feat_i+1,pic_i].axis('off')\n",
        "        axs[feat_i+1,pic_i].text(-5,22,feat_i,ha='right') if pic_i==0 else None\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.suptitle('Second set of feature map activations for 10 test images',x=.5,y=1.01)\n",
        "\n",
        "plt.savefig('figure21_feature_maps.png')\n",
        "plt.show()\n",
        "files.download('figure21_feature_maps.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "CcMnR2VRNB3r"
      },
      "outputs": [],
      "source": [
        "# %% Spatial correlations across feature maps in convolutional layer 1\n",
        "\n",
        "# Variables\n",
        "n_stim  = feat_map1.shape[0]\n",
        "n_maps  = feat_map1.shape[1]\n",
        "n_corrs = (n_maps*(n_maps-1))//2\n",
        "\n",
        "all_rs    = np.zeros((n_stim,n_corrs))\n",
        "all_corrs = np.zeros((n_maps,n_maps))\n",
        "\n",
        "# Loop over each stimulus (input images)\n",
        "for i in range(n_stim):\n",
        "\n",
        "    # Vectorised feature maps from current image\n",
        "    feat_maps = feat_map1[i,:,:,:].view(n_maps,-1).detach()\n",
        "\n",
        "    # Correlation matrix\n",
        "    C = np.corrcoef(feat_maps)\n",
        "    all_corrs += C\n",
        "\n",
        "    # extract the unique correlations from the matrix\n",
        "    idx = np.nonzero(np.triu(C,1))\n",
        "    all_rs[i,:] = C[idx]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "id": "9smDe1IiQebC",
        "outputId": "3009c853-e91b-4830-ecf6-b69c162a7c57"
      },
      "outputs": [],
      "source": [
        "# %% Plotting\n",
        "\n",
        "# define the x-axis labels\n",
        "xlab = []*n_corrs\n",
        "for i in range(n_corrs):\n",
        "    xlab.append('%s-%s' %(idx[0][i],idx[1][i]))\n",
        "\n",
        "# Plot\n",
        "phi = (1 + np.sqrt(5)) / 2\n",
        "fig,(ax0,ax1) = plt.subplots(1,2,figsize=(2*phi*5,5))\n",
        "\n",
        "cmap = plt.cm.plasma(np.linspace(0.2,0.9,n_corrs))\n",
        "\n",
        "for i in range(n_corrs):\n",
        "    ax0.plot(i+np.random.randn(n_stim)/30,all_rs[:,i],'o',color=cmap[i],markerfacecolor='w',markersize=8)\n",
        "\n",
        "ax0.set_xlim([-.5,n_corrs-.5])\n",
        "ax0.set_ylim([-1.05,1.05])\n",
        "ax0.set_xticks(range(n_corrs))\n",
        "ax0.set_xticklabels(xlab)\n",
        "ax0.set_xlabel('Feature map pair')\n",
        "ax0.set_ylabel('Correlation coefficient')\n",
        "ax0.set_title('Correlations for each image\\n(Conv. layer 1)')\n",
        "\n",
        "# Average correlation matrix\n",
        "h = ax1.imshow(all_corrs/n_stim,vmin=-1,vmax=1,cmap='plasma')\n",
        "ax1.set_title('Correlation matrix')\n",
        "ax1.set_xlabel('Feature map')\n",
        "ax1.set_ylabel('Feature map')\n",
        "fig.colorbar(h,ax=ax1)\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.savefig('figure22_feature_maps.png')\n",
        "plt.show()\n",
        "files.download('figure22_feature_maps.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "STT4AWN2M0xq"
      },
      "outputs": [],
      "source": [
        "# %% Spatial correlations across feature maps in convolutional layer 2\n",
        "\n",
        "# Variables\n",
        "n_stim  = feat_map2.shape[0]\n",
        "n_maps  = feat_map2.shape[1]\n",
        "n_corrs = (n_maps*(n_maps-1))//2\n",
        "\n",
        "all_rs    = np.zeros((n_stim,n_corrs))\n",
        "all_corrs = np.zeros((n_maps,n_maps))\n",
        "\n",
        "# Loop over each stimulus (input images)\n",
        "for i in range(n_stim):\n",
        "\n",
        "    # Vectorised feature maps from current image\n",
        "    feat_maps = feat_map2[i,:,:,:].view(n_maps,-1).detach()\n",
        "\n",
        "    # Correlation matrix\n",
        "    C = np.corrcoef(feat_maps)\n",
        "    all_corrs += C\n",
        "\n",
        "    # extract the unique correlations from the matrix\n",
        "    idx = np.nonzero(np.triu(C,1))\n",
        "    all_rs[i,:] = C[idx]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "id": "aypH_pbcM0uJ",
        "outputId": "9b3bbfaf-b92d-47a2-854f-1e9634988238"
      },
      "outputs": [],
      "source": [
        "# %% Plotting\n",
        "\n",
        "# define the x-axis labels\n",
        "xlab = []*n_corrs\n",
        "for i in range(n_corrs):\n",
        "    xlab.append('%s-%s' %(idx[0][i],idx[1][i]))\n",
        "\n",
        "# Plot\n",
        "phi = (1 + np.sqrt(5)) / 2\n",
        "fig,(ax0,ax1) = plt.subplots(1,2,figsize=(2*phi*5,5))\n",
        "\n",
        "cmap = plt.cm.plasma(np.linspace(0.2,0.9,n_corrs))\n",
        "\n",
        "for i in range(n_corrs):\n",
        "    ax0.plot(i+np.random.randn(n_stim)/30,all_rs[:,i],'o',color=cmap[i],markerfacecolor='w',markersize=8)\n",
        "\n",
        "ax0.set_xlim([-.5,n_corrs-.5])\n",
        "ax0.set_ylim([-1.05,1.05])\n",
        "ax0.set_xticks(range(n_corrs))\n",
        "ax0.set_xticklabels(xlab)\n",
        "ax0.set_xlabel('Feature map pair')\n",
        "ax0.set_ylabel('Correlation coefficient')\n",
        "ax0.set_title('Correlations for each image\\n(Conv. layer 2)')\n",
        "\n",
        "# Average correlation matrix\n",
        "h = ax1.imshow(all_corrs/n_stim,vmin=-1,vmax=1,cmap='plasma')\n",
        "ax1.set_title('Correlation matrix')\n",
        "ax1.set_xlabel('Feature map')\n",
        "ax1.set_ylabel('Feature map')\n",
        "fig.colorbar(h,ax=ax1)\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.savefig('figure23_feature_maps.png')\n",
        "plt.show()\n",
        "files.download('figure23_feature_maps.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "xMSzUdqhQRtP"
      },
      "outputs": [],
      "source": [
        "# %% Exercise 1\n",
        "#    The code here grabs the activation of the feature maps *after* relu is applied. Modify the code to get the *pre-relu*\n",
        "#    activations, which corresponds to the linear part of the activations. Redraw the maps (do you need to modify the\n",
        "#    color range?). Do they look similar or different before vs after relu? Which maps are more relevant to interpret\n",
        "#    when trying to understand how the CNN works and how it represents data?\n",
        "\n",
        "# Function to generate the model\n",
        "def gen_model():\n",
        "\n",
        "    class mnist_CNN(nn.Module):\n",
        "        def __init__(self):\n",
        "            super().__init__()\n",
        "\n",
        "            # Convolution layer 1\n",
        "            # output size: (91+2*1-3)/1 + 1 = 91\n",
        "            # post-pooling: 91/2 = 45\n",
        "            self.conv1 = nn.Conv2d(1,6,kernel_size=3,stride=1,padding=1)\n",
        "\n",
        "            # Convolution layer 2\n",
        "            # output size: (45+2*1-3)/1 + 1 = 45\n",
        "            # post-pooling: 45/2 = 22\n",
        "            self.conv2 = nn.Conv2d(6,4,kernel_size=3,stride=1,padding=1)\n",
        "\n",
        "            # Fully connected layer\n",
        "            self.fc1 = nn.Linear(22*22*4,50)\n",
        "\n",
        "            # Output layer\n",
        "            self.output = nn.Linear(50,1)\n",
        "\n",
        "        def forward(self,x):\n",
        "\n",
        "            # Adapt to export\n",
        "            # MaxPool and ReLu on convolution layer 1\n",
        "            conv1_act_pre = self.conv1(x)\n",
        "            conv1_act     = F.relu(conv1_act_pre)\n",
        "            x             = F.avg_pool2d(conv1_act,(2,2))\n",
        "\n",
        "            # MaxPool and ReLu on convolution layer 2\n",
        "            conv2_act_pre = self.conv2(x)\n",
        "            conv2_act     = F.relu(conv2_act_pre)\n",
        "            x             = F.avg_pool2d(conv2_act,(2,2))\n",
        "\n",
        "            # Vectorise for linear layer\n",
        "            x = torch.flatten(x,start_dim=1)\n",
        "\n",
        "            # Linear and output layers\n",
        "            x = F.relu(self.fc1(x))\n",
        "            x = self.output(x)\n",
        "\n",
        "            return x,conv1_act_pre,conv2_act_pre\n",
        "\n",
        "    # Create model instance\n",
        "    CNN = mnist_CNN()\n",
        "\n",
        "    # Loss function\n",
        "    loss_fun = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    # Optimizer\n",
        "    optimizer = torch.optim.Adam(CNN.parameters(),lr=0.001)\n",
        "\n",
        "    return CNN,loss_fun,optimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "kvVSWe_8QRoG"
      },
      "outputs": [],
      "source": [
        "# %% Exercise 2\n",
        "#    Relatedly, how much difference would it make to export the activations after the pooling layers? Which is better\n",
        "#    and what are the advantages of inspecting the pre- vs. post-pooled activation maps?\n",
        "\n",
        "# Function to generate the model\n",
        "def gen_model():\n",
        "\n",
        "    class mnist_CNN(nn.Module):\n",
        "        def __init__(self):\n",
        "            super().__init__()\n",
        "\n",
        "            # Convolution layer 1\n",
        "            # output size: (91+2*1-3)/1 + 1 = 91\n",
        "            # post-pooling: 91/2 = 45\n",
        "            self.conv1 = nn.Conv2d(1,6,kernel_size=3,stride=1,padding=1)\n",
        "\n",
        "            # Convolution layer 2\n",
        "            # output size: (45+2*1-3)/1 + 1 = 45\n",
        "            # post-pooling: 45/2 = 22\n",
        "            self.conv2 = nn.Conv2d(6,4,kernel_size=3,stride=1,padding=1)\n",
        "\n",
        "            # Fully connected layer\n",
        "            self.fc1 = nn.Linear(22*22*4,50)\n",
        "\n",
        "            # Output layer\n",
        "            self.output = nn.Linear(50,1)\n",
        "\n",
        "        def forward(self,x):\n",
        "\n",
        "            # Adapt to export\n",
        "            # MaxPool and ReLu on convolution layer 1\n",
        "            conv1_act_pre  = self.conv1(x)\n",
        "            conv1_act      = F.relu(conv1_act_pre)\n",
        "            conv1_act_post = F.avg_pool2d(conv1_act,(2,2))\n",
        "\n",
        "            # MaxPool and ReLu on convolution layer 2\n",
        "            conv2_act_pre  = self.conv2(conv1_act_post) # Corrected: Pass conv1_act_post here\n",
        "            conv2_act      = F.relu(conv2_act_pre)\n",
        "            conv2_act_post = F.avg_pool2d(conv2_act,(2,2))\n",
        "\n",
        "            # Vectorise for linear layer\n",
        "            x = torch.flatten(conv2_act_post,start_dim=1)\n",
        "\n",
        "            # Linear and output layers\n",
        "            x = F.relu(self.fc1(x))\n",
        "            x = self.output(x)\n",
        "\n",
        "            return x,conv1_act_post,conv2_act_post\n",
        "\n",
        "    # Create model instance\n",
        "    CNN = mnist_CNN()\n",
        "\n",
        "    # Loss function\n",
        "    loss_fun = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    # Optimizer\n",
        "    optimizer = torch.optim.Adam(CNN.parameters(),lr=0.001)\n",
        "\n",
        "    return CNN,loss_fun,optimizer\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
