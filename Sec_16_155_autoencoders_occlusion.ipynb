{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y2ZPyPT3D_VG"
      },
      "outputs": [],
      "source": [
        "# %% Deep learning - Section 16.155\n",
        "#    AEs for occlusion\n",
        "\n",
        "# This code pertains a deep learning course provided by Mike X. Cohen on Udemy:\n",
        "#   > https://www.udemy.com/course/deeplearning_x\n",
        "# The \"base\" code in this repository is adapted (with very minor modifications)\n",
        "# from code developed by the course instructor (Mike X. Cohen), while the\n",
        "# \"exercises\" and the \"code challenges\" contain more original solutions and\n",
        "# creative input from my side. If you are interested in DL (and if you are\n",
        "# reading this statement, chances are that you are), go check out the course, it\n",
        "# is singularly good.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "id": "oIWD8TazEUtR"
      },
      "outputs": [],
      "source": [
        "# %% Libraries and modules\n",
        "import numpy               as np\n",
        "import matplotlib.pyplot   as plt\n",
        "import torch\n",
        "import torch.nn            as nn\n",
        "import seaborn             as sns\n",
        "import copy\n",
        "import torch.nn.functional as F\n",
        "import pandas              as pd\n",
        "import scipy.stats         as stats\n",
        "import sklearn.metrics     as skm\n",
        "import time\n",
        "import sys\n",
        "\n",
        "from torch.utils.data                 import DataLoader,TensorDataset\n",
        "from sklearn.model_selection          import train_test_split\n",
        "from google.colab                     import files\n",
        "from torchsummary                     import summary\n",
        "from scipy.stats                      import zscore\n",
        "from IPython                          import display\n",
        "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
        "set_matplotlib_formats('svg')\n",
        "plt.style.use('default')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "3rgWz4o1EfFg"
      },
      "outputs": [],
      "source": [
        "# %% Data\n",
        "\n",
        "# Load data\n",
        "data = np.loadtxt(open('sample_data/mnist_train_small.csv','rb'),delimiter=',')\n",
        "\n",
        "# Split labels from data\n",
        "labels = data[:,0]\n",
        "data   = data[:,1:]\n",
        "\n",
        "# Normalise data (original range is (0,255))\n",
        "data_norm = data / np.max(data)\n",
        "\n",
        "# Convert to tensor\n",
        "data_tensor = torch.tensor(data_norm).float()\n",
        "labels_tensor = torch.tensor(labels).long()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "ChF6M1D3Ee8q",
        "outputId": "9d62190a-f64a-45f2-b432-6d5a3462daa7"
      },
      "outputs": [],
      "source": [
        "# %% Demonstrate occlusion\n",
        "\n",
        "img = data_tensor[12345,:].view(28,28)\n",
        "\n",
        "occluded_img = copy.deepcopy(img)\n",
        "occluded_img[10:13,:] = 1\n",
        "\n",
        "phi = (1 + np.sqrt(5)) / 2\n",
        "fig,ax = plt.subplots(1,2,figsize=(phi*5,5))\n",
        "\n",
        "ax[0].imshow(img,cmap='gray')\n",
        "ax[0].set_title('Original image')\n",
        "ax[0].axis('off')\n",
        "\n",
        "ax[1].imshow(occluded_img,cmap='gray')\n",
        "ax[1].set_title('Occluded image')\n",
        "ax[1].axis('off')\n",
        "\n",
        "plt.savefig('figure29_autoencoders_occlusion.png')\n",
        "plt.show()\n",
        "files.download('figure29_autoencoders_occlusion.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "7dKNxW9nEexX"
      },
      "outputs": [],
      "source": [
        "# %% Model class\n",
        "\n",
        "# No need to create train and test datasets!\n",
        "\n",
        "def gen_model():\n",
        "\n",
        "    class mnist_AE(nn.Module):\n",
        "        def __init__(self):\n",
        "            super().__init__()\n",
        "\n",
        "            # Architecture\n",
        "            self.input  = nn.Linear(784,128)\n",
        "            self.encode = nn.Linear(128, 50)\n",
        "            self.mid    = nn.Linear( 50,128)\n",
        "            self.decode = nn.Linear(128,784)\n",
        "\n",
        "        # Forward propagation (sigmoid to scale between 0 and 1)\n",
        "        def forward(self,x):\n",
        "\n",
        "            x = F.relu(self.input(x))\n",
        "            x = F.relu(self.encode(x))\n",
        "            x = F.relu(self.mid(x))\n",
        "            x = torch.sigmoid(self.decode(x))\n",
        "\n",
        "            return x\n",
        "\n",
        "    # Generate model instance\n",
        "    ANN = mnist_AE()\n",
        "\n",
        "    # Loss function\n",
        "    loss_fun = nn.MSELoss()\n",
        "\n",
        "    # Optimizer\n",
        "    optimizer = torch.optim.Adam(ANN.parameters(),lr=0.001)\n",
        "\n",
        "    return ANN,loss_fun,optimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "vpawLd26GVs4"
      },
      "outputs": [],
      "source": [
        "# %% Function to train the model\n",
        "\n",
        "def train_model(ANN,loss_fun,optimizer):\n",
        "\n",
        "    # Parameters, inizialise vars\n",
        "    num_epochs = 20\n",
        "    batch_size = 32\n",
        "    n_samples  = data_tensor.shape[0]\n",
        "    losses     = []\n",
        "\n",
        "    # Loop over epochs\n",
        "    for epoch_i in range(num_epochs):\n",
        "\n",
        "        batch_losses = []\n",
        "        batch_sizes  = []\n",
        "\n",
        "        # Select a random subset of images\n",
        "        rand_idx = np.random.permutation(data_tensor.shape[0]).astype(int)\n",
        "\n",
        "        for i in range(0,n_samples,batch_size):\n",
        "\n",
        "            # Pick a sample\n",
        "            sample = rand_idx[i:i+batch_size]\n",
        "            X      = data_tensor[sample,:]\n",
        "\n",
        "            # Forward propagation and loss (pass data themselves to loss_fun)\n",
        "            yHat = ANN(X)\n",
        "            loss = loss_fun(yHat,X)\n",
        "\n",
        "            # Backpropagation\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Batch mean loss and actual batch size (last sample might be <32)\n",
        "            batch_losses.append(loss.item())\n",
        "            batch_sizes.append(X.shape[0])\n",
        "\n",
        "        # Current epoch loss\n",
        "        losses.append(np.average(batch_losses,weights=batch_sizes))\n",
        "\n",
        "    return losses,ANN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "BrOQF9oFGVrA"
      },
      "outputs": [],
      "source": [
        "# %% Train and fit\n",
        "\n",
        "ANN,loss_fun,optimizer = gen_model()\n",
        "losses,ANN             = train_model(ANN,loss_fun,optimizer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "id": "mc27gZgZGVnt",
        "outputId": "59b02c72-d7ed-4890-fa76-5426751523e8"
      },
      "outputs": [],
      "source": [
        "# %% Plotting\n",
        "\n",
        "phi = (1 + np.sqrt(5)) / 2\n",
        "fig = plt.figure(figsize=(phi*5,5))\n",
        "\n",
        "plt.plot(losses,'-')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Model loss')\n",
        "plt.title('Model loss over epochs')\n",
        "\n",
        "plt.savefig('figure30_autoencoders_occlusion.png')\n",
        "plt.show()\n",
        "files.download('figure30_autoencoders_occlusion.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "bCl50z46KKmi",
        "outputId": "f2087299-c4e1-46df-bdcc-b7e8e2ce5b50"
      },
      "outputs": [],
      "source": [
        "# %% Occlude some images\n",
        "\n",
        "# Get some images\n",
        "X = copy.deepcopy( data_tensor[:10,:] )\n",
        "\n",
        "# Reshape and occlude random rows or cols (if even, horizontal occlusion; if\n",
        "# odd, vertical)\n",
        "for i in range(X.shape[0]):\n",
        "\n",
        "    img       = X[i,:].view(28,28)\n",
        "    start_loc = np.random.choice(range(10,21))\n",
        "\n",
        "    if i%2==0:\n",
        "        img[start_loc:start_loc+1,:] = 1\n",
        "    else:\n",
        "        img[:,start_loc:start_loc+1] = 1\n",
        "\n",
        "# Pass occluded data to trained model\n",
        "reconstructed = ANN(X)\n",
        "\n",
        "# Plotting\n",
        "phi = (1 + np.sqrt(5)) / 2\n",
        "fig,axs = plt.subplots(3,10,figsize=(1.5*phi*5,5))\n",
        "\n",
        "for i in range(10):\n",
        "    axs[0,i].imshow(data_tensor[i,:].view(28,28).detach() ,cmap='gray')\n",
        "    axs[1,i].imshow(X[i,:].view(28,28).detach() ,cmap='gray')\n",
        "    axs[2,i].imshow(reconstructed[i,:].view(28,28).detach() ,cmap='gray')\n",
        "    axs[0,i].set_xticks([]), axs[0,i].set_yticks([])\n",
        "    axs[1,i].set_xticks([]), axs[1,i].set_yticks([])\n",
        "    axs[2,i].set_xticks([]), axs[2,i].set_yticks([])\n",
        "\n",
        "plt.suptitle('Original, occluded and reconstructed images')\n",
        "\n",
        "plt.savefig('figure31_autoencoders_occlusion.png')\n",
        "plt.show()\n",
        "files.download('figure31_autoencoders_occlusion.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "id": "lU2-CXWeKKjs",
        "outputId": "e33f5207-dca5-415a-9885-21adbb72752d"
      },
      "outputs": [],
      "source": [
        "# Quantify the performance (correlate reconstructed with original)\n",
        "\n",
        "corr = np.corrcoef(data_tensor[9,:].detach(),reconstructed[9,:].detach())\n",
        "\n",
        "# Plotting\n",
        "phi = (1 + np.sqrt(5)) / 2\n",
        "fig = plt.figure(figsize=(phi*5,5))\n",
        "plt.plot(data_tensor[9,:].detach(),reconstructed[9,:].detach(),'.',markersize=8)\n",
        "plt.xlabel('Original pixel values')\n",
        "plt.ylabel('Reconstructed pixel values')\n",
        "plt.title(f'Correlation r={corr[0,1] :.3f}')\n",
        "\n",
        "plt.savefig('figure32_autoencoders_occlusion.png')\n",
        "plt.show()\n",
        "files.download('figure32_autoencoders_occlusion.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "id": "0JIUYAKRKKhd",
        "outputId": "5f0274df-272c-4bcd-9361-5a1dcf5046a3"
      },
      "outputs": [],
      "source": [
        "# Quantify the performance (correlate reconstructed with original, exclude zero pixels)\n",
        "\n",
        "# Variables for convenience\n",
        "orig  = data_tensor[9,:].detach()\n",
        "recon = reconstructed[9,:].detach()\n",
        "\n",
        "# boolean for pixels > 0\n",
        "tol      = 1e-4\n",
        "non_zero = (orig>tol) & (recon>tol)\n",
        "\n",
        "# Recompute correlation\n",
        "corr_no_zero = np.corrcoef(orig[non_zero],recon[non_zero])\n",
        "\n",
        "# Plotting\n",
        "phi = (1 + np.sqrt(5)) / 2\n",
        "fig = plt.figure(figsize=(phi*5,5))\n",
        "plt.plot(orig[non_zero],recon[non_zero],'.',markersize=8)\n",
        "plt.xlabel('Original pixel values')\n",
        "plt.ylabel('Reconstructed pixel values')\n",
        "plt.title(f'Correlation r={corr_no_zero[0,1] :.3f}')\n",
        "\n",
        "plt.savefig('figure33_autoencoders_occlusion.png')\n",
        "plt.show()\n",
        "files.download('figure33_autoencoders_occlusion.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "id": "i3fEdd07KKez",
        "outputId": "050c4aea-52cb-4dd4-ab71-3bb733fc53b3"
      },
      "outputs": [],
      "source": [
        "# %% Test reconstructed occluded data against non-occluded reconstructed data (more 'fair')\n",
        "\n",
        "# Reconstructed with no occlusion\n",
        "no_occlusion = ANN(data_tensor[:10,:])\n",
        "\n",
        "# Compare reconstructed with and without occlusion\n",
        "r = np.zeros((10,2))\n",
        "for i in range(reconstructed.shape[0]):\n",
        "\n",
        "    tol      = 1e-4\n",
        "    non_zero = (data_tensor[i,:]>tol) & (no_occlusion[i,:]>tol) & (reconstructed[i,:]>tol)\n",
        "\n",
        "    r[i,0] = np.corrcoef(data_tensor[i,non_zero].detach(),no_occlusion[i,non_zero].detach())[0,1]\n",
        "    r[i,1] = np.corrcoef(data_tensor[i,non_zero].detach(),reconstructed[i,non_zero].detach())[0,1]\n",
        "\n",
        "\n",
        "# plot the correlation coefficients\n",
        "phi = (1 + np.sqrt(5)) / 2\n",
        "fig = plt.figure(figsize=(phi*5,5))\n",
        "\n",
        "plt.plot(r,'o-',markersize=8)\n",
        "plt.legend(['No occlusion','Occlusion'])\n",
        "plt.xlabel('Sample number')\n",
        "plt.ylabel('Correlation with original')\n",
        "plt.title('Correlation with original (occluded and non-occluded images)')\n",
        "\n",
        "plt.savefig('figure34_autoencoders_occlusion.png')\n",
        "plt.show()\n",
        "files.download('figure34_autoencoders_occlusion.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "iQRzoftCKKZq",
        "outputId": "d3a2a370-cd84-4615-fa2d-3b04c0c94e28"
      },
      "outputs": [],
      "source": [
        "# %% Exercise 1\n",
        "#    Does occlusion affect some numbers more than others? Run the entire dataset through the autoencoder with occluded\n",
        "#    images. Compute the image correlations for each sample. Then compute the average correlation for each number (image\n",
        "#    label). Show the results in a plot. (Bonus: Also compute the standard deviation across correlations and use those\n",
        "#    to draw error bars.) What do the results tell you about the difficulty of fixing occlusions in images?\n",
        "\n",
        "# Indeed the occlusion seems to be worse for some numbers rather than others\n",
        "\n",
        "# Occlude all images\n",
        "data_tensor_occluded = copy.deepcopy( data_tensor )\n",
        "for i in range(data_tensor_occluded.shape[0]):\n",
        "\n",
        "    img       = data_tensor_occluded[i,:].view(28,28)\n",
        "    start_loc = np.random.choice(range(10,21))\n",
        "\n",
        "    if i%2==0:\n",
        "        img[start_loc:start_loc+1,:] = 1\n",
        "    else:\n",
        "        img[:,start_loc:start_loc+1] = 1\n",
        "\n",
        "# Pass to model\n",
        "reconstructed_all = ANN(data_tensor_occluded)\n",
        "\n",
        "# Correlations\n",
        "r = np.zeros((reconstructed_all.shape[0]))\n",
        "for i in range(reconstructed_all.shape[0]):\n",
        "\n",
        "    tol = 1e-4\n",
        "    non_zero = (data_tensor[i,:]>tol) & (reconstructed_all[i,:]>tol)\n",
        "    n_valid  = non_zero.sum().item()\n",
        "\n",
        "    r[i] = np.corrcoef(data_tensor[i,non_zero].detach(),reconstructed_all[i,non_zero].detach())[0,1]\n",
        "\n",
        "print(f\"Warning: {np.isnan(r).sum()} correlations are nans.\")\n",
        "\n",
        "# Averages by digit (a few rs might be nans, possibly because no variance in\n",
        "# either vector used to compute the correlation)\n",
        "mean_corr = np.zeros(10)\n",
        "std_corr  = np.zeros(10)\n",
        "\n",
        "for digit in range(10):\n",
        "\n",
        "    digit_corr       = r[labels == digit]\n",
        "    mean_corr[digit] = np.nanmean(digit_corr)\n",
        "    std_corr[digit]  = np.nanstd(digit_corr)\n",
        "\n",
        "# Plotting\n",
        "cmap = plt.cm.plasma(np.linspace(0.2,0.9,len(mean_corr)))\n",
        "\n",
        "phi = (1 + np.sqrt(5)) / 2\n",
        "fig = plt.figure(figsize=(phi*5,5))\n",
        "\n",
        "for digit in range(10):\n",
        "\n",
        "    plt.errorbar(\n",
        "        digit,\n",
        "        mean_corr[digit],\n",
        "        yerr=std_corr[digit],\n",
        "        fmt='o',\n",
        "        color=cmap[digit],\n",
        "        capsize=5 )\n",
        "\n",
        "plt.xticks(range(10))\n",
        "plt.xlabel('Digit')\n",
        "plt.ylabel('Correlation (mean Â± std)')\n",
        "plt.title('Reconstruction correlation by digit\\n(occluded data)')\n",
        "plt.grid(alpha=0.3)\n",
        "\n",
        "plt.savefig('figure35_autoencoders_occlusion_extra1.png')\n",
        "plt.show()\n",
        "files.download('figure35_autoencoders_occlusion_extra1.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "o1j0QUTxf6Nm",
        "outputId": "172cbb2e-06c0-45be-f518-a3ab5fb4572f"
      },
      "outputs": [],
      "source": [
        "# %% Exercise 1\n",
        "#    Continue ...\n",
        "\n",
        "import statsmodels.stats.multicomp as mc\n",
        "\n",
        "# Remove nans\n",
        "mask         = ~np.isnan(r)\n",
        "r_clean      = r[mask]\n",
        "labels_clean = labels[mask]\n",
        "\n",
        "# Fisher transform to spread out tails (corrs are bounded [-1,1])\n",
        "z = np.arctanh(r_clean)\n",
        "\n",
        "# Groups\n",
        "groups = [z[labels_clean == d] for d in range(10)]\n",
        "\n",
        "# Assume normality and homoscedasticity\n",
        "\n",
        "# One-way ANOVA\n",
        "f,p = stats.f_oneway(*groups)\n",
        "print(f\"ANOVA F = {f}, p = {p:.5f}\"),print()\n",
        "\n",
        "# Tukey post-hoc\n",
        "z_all        = np.concatenate(groups)\n",
        "digit_labels = np.concatenate([[d]*len(groups[d]) for d in range(10)])\n",
        "\n",
        "comp  = mc.MultiComparison(z_all,digit_labels)\n",
        "tukey = comp.tukeyhsd()\n",
        "\n",
        "print(tukey)\n",
        "\n",
        "# Plotting\n",
        "md     = tukey.meandiffs\n",
        "groups = tukey.groupsunique\n",
        "matrix = np.zeros((len(groups),len(groups)))\n",
        "\n",
        "phi = (1 + np.sqrt(5)) / 2\n",
        "fig = plt.figure(figsize=(phi*5,5))\n",
        "\n",
        "k = 0\n",
        "for i in range(len(groups)):\n",
        "    for j in range(i+1, len(groups)):\n",
        "        matrix[i,j] = md[k]\n",
        "        matrix[j,i] = -md[k]\n",
        "        k += 1\n",
        "\n",
        "sns.heatmap(matrix,annot=True,fmt=\".2f\",cmap=\"plasma\",center=0,xticklabels=groups,yticklabels=groups)\n",
        "plt.title(\"Tukey post-hoc\\n(Mean differences in avg correlations between digits)\")\n",
        "\n",
        "plt.savefig('figure36_autoencoders_occlusion_extra1.png')\n",
        "plt.show()\n",
        "files.download('figure36_autoencoders_occlusion_extra1.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "id": "i3KEG0epSFbq",
        "outputId": "4a1dd25f-d889-41f2-dae1-07659c26b4df"
      },
      "outputs": [],
      "source": [
        "# %% Exercise 2\n",
        "#    Perhaps a correlation coefficient isn't really the best performance metric. Try this: Binarize the images like we\n",
        "#    did in the video \"CodeChallenge: Binarized MNIST images\" (section FFN). Then compute the number of pixels in the\n",
        "#    original and reconstructed images that overlap (hint: try summing them). Make sure your new metric has a possible\n",
        "#    range of 0 (absolutely no overlap) to 1 (perfect overlap). Does this metric seem more consistent with your visual\n",
        "#    intuition?\n",
        "\n",
        "# Seems very similar in pattern to the correlation approach\n",
        "\n",
        "# Occlude all images\n",
        "data_tensor_occluded = copy.deepcopy( data_tensor )\n",
        "for i in range(data_tensor_occluded.shape[0]):\n",
        "\n",
        "    img       = data_tensor_occluded[i,:].view(28,28)\n",
        "    start_loc = np.random.choice(range(10,21))\n",
        "\n",
        "    if i%2==0:\n",
        "        img[start_loc:start_loc+1,:] = 1\n",
        "    else:\n",
        "        img[:,start_loc:start_loc+1] = 1\n",
        "\n",
        "# Pass to model\n",
        "reconstructed_all_obstructed = ANN(data_tensor_occluded)\n",
        "\n",
        "# Binarise\n",
        "split_val         = 0.5\n",
        "reconstructed_bin = np.where(reconstructed_all_obstructed.detach().numpy()>split_val, 1,0)\n",
        "original_bin      = np.where(data_tensor.detach().numpy()>split_val, 1,0)\n",
        "\n",
        "# Compute overlap (pixels 1 in both / pixels 1 in either; i.e., intersection / union)\n",
        "overlap = np.zeros(original_bin.shape[0])\n",
        "\n",
        "for i in range(original_bin.shape[0]):\n",
        "    orig  = original_bin[i]\n",
        "    recon = reconstructed_bin[i]\n",
        "\n",
        "    intersection = np.sum(orig & recon)\n",
        "    union        = np.sum(orig | recon)\n",
        "\n",
        "    if union == 0:\n",
        "        overlap[i] = 1.0\n",
        "    else:\n",
        "        overlap[i] = intersection / union\n",
        "\n",
        "# Average per digit\n",
        "mean_overlap = np.zeros(10)\n",
        "std_overlap  = np.zeros(10)\n",
        "\n",
        "for d in range(10):\n",
        "    digit_idx       = labels == d\n",
        "    mean_overlap[d] = np.mean(overlap[digit_idx])\n",
        "    std_overlap[d]  = np.std(overlap[digit_idx])\n",
        "\n",
        "# Plotting\n",
        "phi = (1 + np.sqrt(5)) / 2\n",
        "fig = plt.figure(figsize=(phi*5,5))\n",
        "\n",
        "for digit in range(10):\n",
        "\n",
        "    plt.errorbar(\n",
        "        digit,\n",
        "        mean_overlap[digit],\n",
        "        yerr=std_overlap[digit],\n",
        "        fmt='o',\n",
        "        color=cmap[digit],\n",
        "        capsize=5 )\n",
        "\n",
        "plt.xticks(range(10))\n",
        "plt.xlabel('Digit')\n",
        "plt.ylabel('Pixel overlap')\n",
        "plt.title('Binarized overlap between reconstructed original and obstructed images')\n",
        "plt.grid(alpha=0.3)\n",
        "\n",
        "plt.savefig('figure37_autoencoders_occlusion_extra2.png')\n",
        "plt.show()\n",
        "files.download('figure37_autoencoders_occlusion_extra2.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmQzZ0lqSFZi",
        "outputId": "e9a8c814-08fe-4e8d-c904-5485edc319cc"
      },
      "outputs": [],
      "source": [
        "# %% Exercise 3\n",
        "#    But wait a minute, don't we already have a quantitative measure of the similarity between the AE input and output?\n",
        "#    Of course we do -- it's the loss function! Mean-squared error already accounts for zeros because those get ignored\n",
        "#    [zero-valued pixels have MSE=(0-0)**2 ]. In fact, question #2 is kindof a \"rough MSE.\" Take a moment to write down\n",
        "#    the formulas for MSE and correlation, and see whether they are related (hint: the relationship isn't linear because of\n",
        "#    the squared term). Finally, compute MSE on our example occlusion images and compare MSE to correlation empirically\n",
        "#    by making a scatter plot. (Hint 1: Use more than 10 examples to see trends. Hint 2: Consider the signs (+/-).)\n",
        "\n",
        "# Correlation and MSE are strictly related, they bot measure similarity between\n",
        "# vectors. MSE gets the absolute difference and is not scale-free (square of\n",
        "# differences), while correlation is a scale-free measure of similarity\n",
        "# (normalised covariance)\n",
        "\n",
        "# Get some images\n",
        "subsample = copy.deepcopy( data_tensor[:400,:] )\n",
        "\n",
        "for i in range(subsample.shape[0]):\n",
        "\n",
        "    img       = subsample[i,:].view(28,28)\n",
        "    start_loc = np.random.choice(range(10,21))\n",
        "\n",
        "    if i%2==0:\n",
        "        img[start_loc:start_loc+1,:] = 1\n",
        "    else:\n",
        "        img[:,start_loc:start_loc+1] = 1\n",
        "\n",
        "# Pass occluded data to trained model\n",
        "reconstructed_occluded = ANN(subsample)\n",
        "\n",
        "# Correlations\n",
        "orig = subsample.detach().numpy()\n",
        "recon = reconstructed_occluded.detach().numpy()\n",
        "\n",
        "r = np.zeros((recon.shape[0]))\n",
        "for i in range(recon.shape[0]):\n",
        "\n",
        "    tol = 1e-4\n",
        "    non_zero = (orig[i,:]>tol) & (recon[i,:]>tol)\n",
        "    n_valid  = non_zero.sum().item()\n",
        "\n",
        "    r[i] = np.corrcoef(orig[i,non_zero],recon[i,non_zero])[0,1]\n",
        "\n",
        "print(f\"Warning: {np.isnan(r).sum()} correlations are nans.\")\n",
        "\n",
        "# MSE\n",
        "mse = np.mean((orig - recon)**2, axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "XuXq6-4-0j3b",
        "outputId": "f829b523-cca5-46de-86b9-481094a3196e"
      },
      "outputs": [],
      "source": [
        "# %% Exercise 3\n",
        "#    Continue ...\n",
        "\n",
        "phi = (1 + np.sqrt(5)) / 2\n",
        "fig = plt.figure(figsize=(phi*5,5))\n",
        "\n",
        "plt.scatter(r,mse,c='tab:blue',alpha=0.6)\n",
        "plt.xlabel(\"Pixel-wise correlation\")\n",
        "plt.ylabel(\"Pixel-wise MSE\")\n",
        "plt.title(\"Reconstruction quality\\n(correlation vs MSE)\")\n",
        "plt.grid(True)\n",
        "\n",
        "plt.savefig('figure38_autoencoders_occlusion_extra3.png')\n",
        "plt.show()\n",
        "files.download('figure38_autoencoders_occlusion_extra3.png')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
