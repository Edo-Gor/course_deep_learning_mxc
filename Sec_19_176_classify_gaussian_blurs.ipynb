{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tc0TUnlTsAoF"
      },
      "outputs": [],
      "source": [
        "# %% Deep learning - Section 19.176\n",
        "#    Classify Gaussian blurs\n",
        "\n",
        "# This code pertains a deep learning course provided by Mike X. Cohen on Udemy:\n",
        "#   > https://www.udemy.com/course/deeplearning_x\n",
        "# The \"base\" code in this repository is adapted (with very minor modifications)\n",
        "# from code developed by the course instructor (Mike X. Cohen), while the\n",
        "# \"exercises\" and the \"code challenges\" contain more original solutions and\n",
        "# creative input from my side. If you are interested in DL (and if you are\n",
        "# reading this statement, chances are that you are), go check out the course, it\n",
        "# is singularly good.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Q549Ew7bsLpw"
      },
      "outputs": [],
      "source": [
        "# %% Libraries and modules\n",
        "import numpy                  as np\n",
        "import matplotlib.pyplot      as plt\n",
        "import torch\n",
        "import torch.nn               as nn\n",
        "import seaborn                as sns\n",
        "import copy\n",
        "import torch.nn.functional    as F\n",
        "import pandas                 as pd\n",
        "import scipy.stats            as stats\n",
        "import sklearn.metrics        as skm\n",
        "import time\n",
        "import sys\n",
        "import imageio.v2             as imageio\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "\n",
        "from torch.utils.data                 import DataLoader,TensorDataset,Dataset\n",
        "from sklearn.model_selection          import train_test_split\n",
        "from google.colab                     import files\n",
        "from torchsummary                     import summary\n",
        "from scipy.stats                      import zscore\n",
        "from sklearn.decomposition            import PCA\n",
        "from scipy.signal                     import convolve2d\n",
        "from torchsummary                     import summary\n",
        "from IPython                          import display\n",
        "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
        "set_matplotlib_formats('svg')\n",
        "plt.style.use('default')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZVlsAsjUMNAc"
      },
      "outputs": [],
      "source": [
        "# %% Reminder of 2D Gaussian parameters\n",
        "\n",
        "# G = exp( -(Ã^2 + Õ^2) / 2sig^2 )\n",
        "# Ã = A - C_a\n",
        "# Õ = O - C_o\n",
        "#\n",
        "# where A and O are 2D coords grids, C the center of locations, and sig is the\n",
        "# full width at half maximum\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "U0182-ChMfp6"
      },
      "outputs": [],
      "source": [
        "# %% Generate data\n",
        "\n",
        "# 2D Gaussian params\n",
        "n_per_class = 1000\n",
        "n_classes   = 2\n",
        "img_size    = 91\n",
        "x           = np.linspace(-4,4,img_size)\n",
        "X,Y         = np.meshgrid(x,x)\n",
        "\n",
        "widths      = [1.8,2.4]\n",
        "\n",
        "# Preallocate tensors for images (N,channels,size,size) and labels (N)\n",
        "images  = torch.zeros( n_classes*n_per_class,1,img_size,img_size )\n",
        "labels  = torch.zeros( n_classes*n_per_class )\n",
        "\n",
        "# Generate images\n",
        "for i in range(n_classes*n_per_class):\n",
        "\n",
        "    # Gaussian with random center offset (remainder trick for width, all even\n",
        "    # images go into category 0, all odd images go into category 1)\n",
        "    c = 2*np.random.randn(2)\n",
        "    G = np.exp( -((X-c[0])**2 + (Y-c[1])**2 ) / (2*widths[i%2]**2) )\n",
        "\n",
        "    # Layer some noise\n",
        "    G = G + np.random.randn(img_size,img_size)/5\n",
        "\n",
        "    # Add to tensor\n",
        "    images[i,:,:,:] = torch.tensor(G).view(1,img_size,img_size)\n",
        "    labels[i]       = i%2\n",
        "\n",
        "labels = labels[:,None]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "54OSv75gMfiW",
        "outputId": "fb1586b1-aef6-4764-aef2-2bb7297c6286"
      },
      "outputs": [],
      "source": [
        "# %% Plotting\n",
        "\n",
        "phi = (1 + np.sqrt(5))/2\n",
        "fig,axs = plt.subplots(3,7,figsize=(phi*7,7))\n",
        "\n",
        "for i,ax in enumerate(axs.flatten()):\n",
        "\n",
        "    pic = np.random.randint(2*n_per_class)\n",
        "    G   = np.squeeze( images[pic,:,:] )\n",
        "\n",
        "    ax.imshow(G,vmin=-1,vmax=1,cmap='jet')\n",
        "    ax.set_title('Class %s'%int(labels[pic].item()))\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "\n",
        "plt.savefig('figure8_classify_gaussian_blurs.png')\n",
        "plt.show()\n",
        "files.download('figure8_classify_gaussian_blurs.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "TGP_xAERMffp"
      },
      "outputs": [],
      "source": [
        "# %% Create train and test datasets\n",
        "\n",
        "# Split data with scikitlearn (10% test data)\n",
        "train_data,test_data,train_labels,test_labels = train_test_split(images,labels,test_size=0.1)\n",
        "\n",
        "# Convert to PyTorch datasets\n",
        "train_data = TensorDataset(train_data,train_labels)\n",
        "test_data  = TensorDataset(test_data,test_labels)\n",
        "\n",
        "# Convert into DataLoader objects\n",
        "batch_size   = 32\n",
        "train_loader = DataLoader(train_data,batch_size=batch_size,shuffle=True,drop_last=True)\n",
        "test_loader  = DataLoader(test_data,batch_size=test_data.tensors[0].shape[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7tAOGuJuMfcp"
      },
      "outputs": [],
      "source": [
        "# %% Check sizes\n",
        "\n",
        "# Should be (N,channels,width,height) and (N)\n",
        "print( train_loader.dataset.tensors[0].shape )\n",
        "print( train_loader.dataset.tensors[1].shape )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "3m4AUS5pMfZI"
      },
      "outputs": [],
      "source": [
        "# %% Function to generate the model\n",
        "\n",
        "# Combine custom class and nn.Sequential\n",
        "def gen_model():\n",
        "\n",
        "    class Gauss_CNN(nn.Module):\n",
        "        def __init__(self):\n",
        "            super().__init__()\n",
        "\n",
        "            # Layers with nn.Sequential (activation function is treated as layer)\n",
        "            self.model = nn.Sequential( nn.Conv2d(1,6,3,padding=1),  # out size: (91+2*1-3)/1 + 1 = 91\n",
        "                                        nn.ReLU(),\n",
        "                                        nn.AvgPool2d(2,2),           # out size: 91/2 = 45\n",
        "                                        nn.Conv2d(6,4,3,padding=1),  # out size: (45+2*1-3)/1 + 1 = 45\n",
        "                                        nn.ReLU(),\n",
        "                                        nn.AvgPool2d(2,2),           # out size: 45/2 = 22\n",
        "                                        nn.Flatten(),                # vectorise\n",
        "                                        nn.Linear(22*22*4,50),       # out size: 50\n",
        "                                        nn.Linear(50,1)              # out size: 1\n",
        "                                        )\n",
        "\n",
        "        def forward(self,x):\n",
        "            return self.model(x)\n",
        "\n",
        "    # Create model instance\n",
        "    CNN = Gauss_CNN()\n",
        "\n",
        "    # Loss function\n",
        "    loss_fun = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    # Optimizer\n",
        "    optimizer = torch.optim.Adam(CNN.parameters(),lr=0.001)\n",
        "\n",
        "    return CNN,loss_fun,optimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74thkx19MfXE",
        "outputId": "67e7f778-6a5c-4729-938c-c424dc8014d1"
      },
      "outputs": [],
      "source": [
        "# %% Test the model on one batch\n",
        "\n",
        "CNN,loss_fun,optimizer = gen_model()\n",
        "\n",
        "X,y  = next(iter(train_loader))\n",
        "yHat = CNN(X)\n",
        "\n",
        "# Check sizes of output and target variable\n",
        "print()\n",
        "print(yHat.shape), print()\n",
        "print(y.shape), print()\n",
        "\n",
        "# Check loss\n",
        "loss = loss_fun(yHat,y)\n",
        "print(loss)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHSRWxCvvMXp"
      },
      "outputs": [],
      "source": [
        "# %% Check all the parameters in the model\n",
        "\n",
        "summary(CNN,(1,img_size,img_size))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "Zj_F49p_vMUR"
      },
      "outputs": [],
      "source": [
        "# %% Function to train the model\n",
        "\n",
        "def train_model():\n",
        "\n",
        "    # Parameters, model instance, inizialise vars\n",
        "    num_epochs = 10\n",
        "    CNN,loss_fun,optimizer = gen_model()\n",
        "\n",
        "    train_losses = []\n",
        "    test_losses  = []\n",
        "    train_acc    = []\n",
        "    test_acc     = []\n",
        "\n",
        "    # Loop over epochs\n",
        "    for epoch_i in range(num_epochs):\n",
        "\n",
        "        # Loop over training batches\n",
        "        batch_acc  = []\n",
        "        batch_loss = []\n",
        "\n",
        "        for X,y in train_loader:\n",
        "\n",
        "            # Forward propagation and loss\n",
        "            yHat = CNN(X)\n",
        "            loss = loss_fun(yHat,y)\n",
        "\n",
        "            # Backpropagation\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Loss and accuracy from this batch\n",
        "            batch_loss.append(loss.item())\n",
        "            batch_acc.append( torch.mean( ((yHat>0)==y).float() ).item() )\n",
        "\n",
        "        train_losses.append( np.mean(batch_loss) )\n",
        "        train_acc.append( 100*np.mean(batch_acc) )\n",
        "\n",
        "        # Test accuracy\n",
        "        CNN.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            X,y = next(iter(test_loader))\n",
        "            yHat = CNN(X)\n",
        "            loss = loss_fun(yHat,y)\n",
        "\n",
        "            test_acc.append( 100*torch.mean( ((yHat>0)==y).float() ).item() )\n",
        "            test_losses.append(loss.item())\n",
        "\n",
        "        CNN.train()\n",
        "\n",
        "    return train_acc,test_acc,train_losses,test_losses,CNN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "6UmQFnUsvMR8"
      },
      "outputs": [],
      "source": [
        "# %% Run the model\n",
        "\n",
        "# Takes ~30 secs\n",
        "train_acc,test_acc,train_losses,test_losses,CNN = train_model()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "c4mvOjZGvMP2",
        "outputId": "bf487e25-62f8-4008-863f-38cd0e34459e"
      },
      "outputs": [],
      "source": [
        "# %% Plotting\n",
        "\n",
        "phi = (1 + np.sqrt(5)) / 2\n",
        "fig,ax = plt.subplots(1,2,figsize=(1.5*phi*6,6))\n",
        "\n",
        "ax[0].plot(train_losses,'s-',label='Train')\n",
        "ax[0].plot(test_losses,'o-',label='Test')\n",
        "ax[0].set_xlabel('Epochs')\n",
        "ax[0].set_ylabel('Loss (MSE)')\n",
        "ax[0].set_title('Model loss')\n",
        "\n",
        "ax[1].plot(train_acc,'s-',label='Train')\n",
        "ax[1].plot(test_acc,'o-',label='Test')\n",
        "ax[1].set_xlabel('Epochs')\n",
        "ax[1].set_ylabel('Accuracy (%)')\n",
        "ax[1].set_title(f'Final model test accuracy: {test_acc[-1]:.2f}%')\n",
        "ax[1].legend()\n",
        "\n",
        "plt.savefig('figure9_classify_gaussian_blurs.png')\n",
        "plt.show()\n",
        "files.download('figure9_classify_gaussian_blurs.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "JFnRHCgcvMNu",
        "outputId": "63ff7e2f-d8b6-4127-8b80-04b83d832ee7"
      },
      "outputs": [],
      "source": [
        "# %% Plotting\n",
        "\n",
        "# Pass test data through model\n",
        "X,y  = next(iter(test_loader))\n",
        "yHat = CNN(X)\n",
        "\n",
        "# Plot\n",
        "phi = (1 + np.sqrt(5)) / 2\n",
        "fig,axs = plt.subplots(2,10,figsize=(2*phi*5,5))\n",
        "\n",
        "for i,ax in enumerate(axs.flatten()):\n",
        "\n",
        "    G = torch.squeeze( X[i,0,:,:] ).detach()\n",
        "    ax.imshow(G,vmin=-1,vmax=1,cmap='jet')\n",
        "    t = ( int(y[i].item()), int(yHat[i].item()>0) )\n",
        "\n",
        "    ax.set_title('T=%s, P=%s'%t)\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "\n",
        "plt.savefig('figure10_classify_gaussian_blurs.png')\n",
        "plt.show()\n",
        "files.download('figure10_classify_gaussian_blurs.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlx6GdIqvMLo",
        "outputId": "1aa2666b-7736-436d-9494-bfad3ae024b9"
      },
      "outputs": [],
      "source": [
        "# %% Explore kernels\n",
        "\n",
        "# Grab some filters\n",
        "print(CNN), print()\n",
        "\n",
        "layer_1_k = CNN.model[0].weight\n",
        "layer_3_k = CNN.model[3].weight\n",
        "\n",
        "print(layer_1_k.shape)\n",
        "print(layer_3_k.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "DbiOrG7I6Enp",
        "outputId": "53f2ccac-a004-4b4b-9b36-3bd1b11ced93"
      },
      "outputs": [],
      "source": [
        "# %% Plotting\n",
        "\n",
        "phi = (1 + np.sqrt(5)) / 2\n",
        "fig,axs = plt.subplots(1,6,figsize=(2*phi*6,6))\n",
        "\n",
        "for i,ax in enumerate(axs.flatten()):\n",
        "\n",
        "    ax.imshow( torch.squeeze(layer_1_k[i,:,:,:]).detach() ,cmap='plasma')\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.suptitle('First convolution layer filters')\n",
        "\n",
        "plt.savefig('figure11_classify_gaussian_blurs.png')\n",
        "plt.show()\n",
        "files.download('figure11_classify_gaussian_blurs.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "id": "efPX41Du8fju",
        "outputId": "cd816951-49b9-4d4b-9511-020d29362da6"
      },
      "outputs": [],
      "source": [
        "# %% Plotting\n",
        "\n",
        "phi = (1 + np.sqrt(5)) / 2\n",
        "fig,axs = plt.subplots(4,6,figsize=(2*phi*6,6))\n",
        "\n",
        "for i in range(6*4):\n",
        "\n",
        "    idx = np.unravel_index(i,(4,6))\n",
        "    axs[idx].imshow( torch.squeeze(layer_3_k[idx[0],idx[1],:,:]).detach() ,cmap='plasma')\n",
        "    axs[idx].axis('off')\n",
        "\n",
        "plt.suptitle('Second convolution layer filters')\n",
        "\n",
        "plt.savefig('figure12_classify_gaussian_blurs.png')\n",
        "plt.show()\n",
        "files.download('figure12_classify_gaussian_blurs.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "kA3OsTkp8aYn"
      },
      "outputs": [],
      "source": [
        "# %% Exercise 1\n",
        "#    Rewrite the model architecture without using nn.Sequential. Your final result must be the same as the current version,\n",
        "#    just defined in a different way. This is great practice at constructing models using classes.\n",
        "\n",
        "# %% Function to generate the model\n",
        "\n",
        "def gen_model():\n",
        "\n",
        "    class mnist_CNN(nn.Module):\n",
        "        def __init__(self):\n",
        "            super().__init__()\n",
        "\n",
        "            # Convolution layer 1\n",
        "            # size = np.floor( (91+2*1-3)/1 )+1 = 91 (divide by 2 because will\n",
        "            # have maxpool with extent 2)\n",
        "            self.conv1 = nn.Conv2d(1,6,kernel_size=3,stride=1,padding=1)\n",
        "\n",
        "            # Convolution layer 2\n",
        "            # size = np.floor( (45+2*1-3)/1 )+1 = 45 (divide by 2 because will\n",
        "            # have maxpool with extent 2)\n",
        "            self.conv2 = nn.Conv2d(6,4,kernel_size=3,stride=1,padding=1)\n",
        "\n",
        "            # Number of units expected in fully connected layer (out of conv2);\n",
        "            # note that fc1 layer has no padding nor kernel, so we set those\n",
        "            # params to be 0 and 1 respectively; we can also square because the\n",
        "            # images are squares\n",
        "            expected_size = np.floor( 22+2*0-1 ) + 1\n",
        "            expected_size = 4*int(expected_size**2)\n",
        "\n",
        "            # Fully connected layer\n",
        "            self.fc1 = nn.Linear(expected_size,50)\n",
        "\n",
        "            # Output layer\n",
        "            self.output = nn.Linear(50,1)\n",
        "\n",
        "        def forward(self,x):\n",
        "\n",
        "            # MaxPool and ReLu on convolution layer 1\n",
        "            x = F.relu(F.avg_pool2d(self.conv1(x),2))\n",
        "\n",
        "            # MaxPool and ReLu on convolution layer 2\n",
        "            x = F.relu(F.avg_pool2d(self.conv2(x),2))\n",
        "\n",
        "            # Vectorise for linear layer\n",
        "            x = torch.flatten(x,start_dim=1)\n",
        "\n",
        "            # Linear and output layers\n",
        "            x = F.relu(self.fc1(x))\n",
        "            x = self.output(x)\n",
        "\n",
        "            return x\n",
        "\n",
        "    # Create model instance\n",
        "    CNN = mnist_CNN()\n",
        "\n",
        "    # Loss function\n",
        "    loss_fun = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    # Optimizer\n",
        "    optimizer = torch.optim.Adam(CNN.parameters(),lr=0.001)\n",
        "\n",
        "    return CNN,loss_fun,optimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-s6fWJ96Ekl",
        "outputId": "9831a4af-605a-47c0-daa6-81d7190ef3ef"
      },
      "outputs": [],
      "source": [
        "# %% Exercise 2\n",
        "#    Find and plot the stimuli that the model guessed incorrectly. Is the correct answer obvious to you? Do the errors\n",
        "#    tend to be obscured by the boundaries of the image, or is there any other reason you can find for why the model got\n",
        "#    those wrong?\n",
        "\n",
        "# Pass test data through model\n",
        "X,y  = next(iter(test_loader))\n",
        "yHat = CNN(X)\n",
        "\n",
        "# Convert logits to predictions and find indices\n",
        "preds     = (yHat > 0).float()\n",
        "wrong_idx = torch.where(preds != y)[0]\n",
        "\n",
        "print(f'Number of misclassified samples in this batch: {len(wrong_idx)}')\n",
        "\n",
        "# If fewer than 4 mistakes exist, adjust automatically\n",
        "n_plot = min(4, len(wrong_idx))\n",
        "\n",
        "# Randomly choose misclassified samples\n",
        "rand_idx = wrong_idx[torch.randperm(len(wrong_idx))[:n_plot]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "id": "0BzCtsSkOTgw",
        "outputId": "99ae89ab-0761-4ebe-f8bf-84460d437179"
      },
      "outputs": [],
      "source": [
        "# %% Exercise 2\n",
        "#    Continue ...\n",
        "\n",
        "# Plot\n",
        "phi = (1 + np.sqrt(5)) / 2\n",
        "fig,axs = plt.subplots(1,n_plot,figsize=(phi*6,6))\n",
        "\n",
        "# If only 1 image, axs is not iterable\n",
        "if n_plot == 1:\n",
        "    axs = [axs]\n",
        "\n",
        "for ax,i in zip(axs,rand_idx):\n",
        "\n",
        "    G = torch.squeeze(X[i,0,:,:]).detach()\n",
        "    ax.imshow(G,vmin=-1,vmax=1,cmap='jet')\n",
        "\n",
        "    true_label = int(y[i].item())\n",
        "    pred_label = int(preds[i].item())\n",
        "\n",
        "    ax.set_title(f'T={true_label}, P={pred_label}')\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "\n",
        "plt.suptitle('Misclassified samples')\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.savefig('figure14_classify_gaussian_blurs_extra2.png')\n",
        "plt.show()\n",
        "files.download('figure14_classify_gaussian_blurs_extra2.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "USoo0_ce6EiZ"
      },
      "outputs": [],
      "source": [
        "# %% Exercise 3\n",
        "#    Notice the choice of architecture here: 6 channels in the first convolution layer and 4 channels in the second. In\n",
        "#    the lecture I said that CNNs typically get wider with each successive \"convpool block.\" Does that mean that this\n",
        "#    model is wrong? Or suboptimal? Think of some arguments for and against this organization. Then modify the code to\n",
        "#    swap the widths (4 channels in the first conv layer and 6 channels in the second conv layer). Does that affect the\n",
        "#    model's performance?\n",
        "\n",
        "# I mean... so hard to say, even this \"unusual\" model works so well; probably\n",
        "# this level of compression is more than enough for this simple dataset, where\n",
        "# the only feature that has to be extracted is the difference in the gaussian\n",
        "# spread. The modified model behaves very similarly, and the images that are\n",
        "# more likely to be misclassified are still those that end up in the corner\n",
        "\n",
        "# Function to generate the model\n",
        "def gen_model():\n",
        "\n",
        "    class Gauss_CNN(nn.Module):\n",
        "        def __init__(self):\n",
        "            super().__init__()\n",
        "\n",
        "            # Layers with nn.Sequential (activation function is treated as layer)\n",
        "            self.model = nn.Sequential( nn.Conv2d(1,4,3,padding=1),  # out size: (91+2*1-3)/1 + 1 = 91\n",
        "                                        nn.ReLU(),\n",
        "                                        nn.AvgPool2d(2,2),           # out size: 91/2 = 45\n",
        "                                        nn.Conv2d(4,6,3,padding=1),  # out size: (45+2*1-3)/1 + 1 = 45\n",
        "                                        nn.ReLU(),\n",
        "                                        nn.AvgPool2d(2,2),           # out size: 45/2 = 22\n",
        "                                        nn.Flatten(),                # vectorise\n",
        "                                        nn.Linear(22*22*6,50),       # out size: 50\n",
        "                                        nn.Linear(50,1)              # out size: 1\n",
        "                                        )\n",
        "\n",
        "        def forward(self,x):\n",
        "            return self.model(x)\n",
        "\n",
        "    # Create model instance\n",
        "    CNN = Gauss_CNN()\n",
        "\n",
        "    # Loss function\n",
        "    loss_fun = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    # Optimizer\n",
        "    optimizer = torch.optim.Adam(CNN.parameters(),lr=0.001)\n",
        "\n",
        "    return CNN,loss_fun,optimizer\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
