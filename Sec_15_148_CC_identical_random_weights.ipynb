{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Ysii3sksEG0"
      },
      "outputs": [],
      "source": [
        "# %% Deep learning - Section 15.148\n",
        "#    Code challenge 23: identically random weights\n",
        "#\n",
        "#    1) Use PyTorch random seeds to create reproducible random networks\n",
        "#    2) Create a network with an input layer (2 nodes), an hidden layer (8),\n",
        "#       and an output layer (1); use nn.Sequential and not a Class (no need for\n",
        "#       actual data or training)\n",
        "#    3) Make 4 copies and use Xavier initialisation: i) no seed, ii) seed a,\n",
        "#       iii) seed b, iv) seed a again\n",
        "#    4) Networks ii and iv should be the same, print ii - iv to confirm\n",
        "#    5) Plot the flattened weights to confirm\n",
        "\n",
        "# This code pertains a deep learning course provided by Mike X. Cohen on Udemy:\n",
        "#   > https://www.udemy.com/course/deeplearning_x\n",
        "# The \"base\" code in this repository is adapted (with very minor modifications)\n",
        "# from code developed by the course instructor (Mike X. Cohen), while the\n",
        "# \"exercises\" and the \"code challenges\" contain more original solutions and\n",
        "# creative input from my side. If you are interested in DL (and if you are\n",
        "# reading this statement, chances are that you are), go check out the course, it\n",
        "# is singularly good.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jCgpG8h6siyU"
      },
      "outputs": [],
      "source": [
        "# %% Libraries and modules\n",
        "import numpy               as np\n",
        "import matplotlib.pyplot   as plt\n",
        "import torch\n",
        "import torch.nn            as nn\n",
        "import seaborn             as sns\n",
        "import copy\n",
        "import torch.nn.functional as F\n",
        "import pandas              as pd\n",
        "import scipy.stats         as stats\n",
        "import sklearn.metrics     as skm\n",
        "import time\n",
        "\n",
        "from torch.utils.data                 import DataLoader,TensorDataset\n",
        "from sklearn.model_selection          import train_test_split\n",
        "from google.colab                     import files\n",
        "from torchsummary                     import summary\n",
        "from IPython                          import display\n",
        "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
        "set_matplotlib_formats('svg')\n",
        "plt.style.use('default')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "wMQn_35Psivh"
      },
      "outputs": [],
      "source": [
        "# %% Build toy models\n",
        "\n",
        "# Fully random\n",
        "model_0 = nn.Sequential( nn.Linear(2,8),\n",
        "                         nn.Linear(8,1),\n",
        "                         nn.Linear(1,1) )\n",
        "\n",
        "for p in model_0.named_parameters():\n",
        "    if 'weight' in p[0]:\n",
        "        nn.init.xavier_normal_(p[1].data)\n",
        "\n",
        "# Seed a\n",
        "torch.manual_seed(22)\n",
        "model_1 = nn.Sequential( nn.Linear(2,8),\n",
        "                         nn.Linear(8,1),\n",
        "                         nn.Linear(1,1) )\n",
        "\n",
        "for p in model_1.named_parameters():\n",
        "    if 'weight' in p[0]:\n",
        "        nn.init.xavier_normal_(p[1].data)\n",
        "\n",
        "# Seed b\n",
        "torch.manual_seed(88)\n",
        "model_2 = nn.Sequential( nn.Linear(2,8),\n",
        "                         nn.Linear(8,1),\n",
        "                         nn.Linear(1,1) )\n",
        "\n",
        "for p in model_2.named_parameters():\n",
        "    if 'weight' in p[0]:\n",
        "        nn.init.xavier_normal_(p[1].data)\n",
        "\n",
        "# Seed a\n",
        "torch.manual_seed(22)\n",
        "model_3 = nn.Sequential( nn.Linear(2,8),\n",
        "                         nn.Linear(8,1),\n",
        "                         nn.Linear(1,1) )\n",
        "\n",
        "for p in model_3.named_parameters():\n",
        "    if 'weight' in p[0]:\n",
        "        nn.init.xavier_normal_(p[1].data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "DmXvYOELwtwo"
      },
      "outputs": [],
      "source": [
        "# %% Function to get the flattened weight vector\n",
        "\n",
        "def flatten_weights(model):\n",
        "\n",
        "    w = torch.cat([ param.detach().flatten()\n",
        "                    for name, param in model.named_parameters()\n",
        "                    if 'weight' in name ])\n",
        "\n",
        "    return w\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Or2Wfu66sitT",
        "outputId": "aca94723-bda9-4957-a13c-707f6eae45f7"
      },
      "outputs": [],
      "source": [
        "# %% Extract weights\n",
        "\n",
        "w0 = flatten_weights(model_0).numpy()\n",
        "w1 = flatten_weights(model_1).numpy()\n",
        "w2 = flatten_weights(model_2).numpy()\n",
        "w3 = flatten_weights(model_3).numpy()\n",
        "\n",
        "# Note that w1 - w3 should been zero\n",
        "print(w0 - w1)\n",
        "print(w1 - w3)\n",
        "print(w1 - w2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "id": "xF10tR3tsipl",
        "outputId": "24786a57-a465-48d8-cdc4-326a53cdbea9"
      },
      "outputs": [],
      "source": [
        "# %% Plotting\n",
        "\n",
        "phi = (1 + np.sqrt(5)) / 2\n",
        "fig = plt.figure(figsize=(1.5*phi*5,5))\n",
        "\n",
        "plt.plot(w0,'o',markersize=9,label='no seed')\n",
        "plt.plot(w2,'^',markersize=9,label='seed b')\n",
        "plt.plot(w1,'s',markersize=9,label='seed a')\n",
        "plt.plot(w3,'+',markersize=9,label='seed a',markeredgewidth=3)\n",
        "\n",
        "plt.axhline(y=0,color='grey',linestyle=':',linewidth=0.8)\n",
        "\n",
        "plt.legend()\n",
        "plt.xlabel('Vectorized weight index')\n",
        "plt.ylabel('Weight value')\n",
        "plt.title(\"Random (seeded) weights for four networks\")\n",
        "\n",
        "plt.savefig('figure37_code_challenge_23.png')\n",
        "plt.show()\n",
        "files.download('figure37_code_challenge_23.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jujjD2yjzCCq"
      },
      "outputs": [],
      "source": [
        "# %% Exercise 1\n",
        "#    The code here only fixed the *weights*, not the biases. Does that mean that net_rs1a and net_rs1b are actually\n",
        "#    DIFFERENT networks??\n",
        "\n",
        "# Well, depends on the definition of \"different network\"; de facto, I'd say they\n",
        "# may be considered the same starting network, because the purpose of the biases\n",
        "# is only to allow for the error function to shift away from the origin. The of\n",
        "# course fitting occurs and the weights will most likely change to diffent\n",
        "# values, model fitting being inherently stochastic (even though they might well\n",
        "# end up around the same minimum, depending on data, architecture,\n",
        "# metaparameters, etc. etc.)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "7qyTMTnpzB_m"
      },
      "outputs": [],
      "source": [
        "# %% Exercise 2\n",
        "#    Change the code to plot/subtract the biases instead of the weights. Are the results what you expected? If not,\n",
        "#    figure out why!\n",
        "\n",
        "# Given that the seeding occurs before each model is created, also the biases\n",
        "# are seeded in the same way\n",
        "\n",
        "# Function\n",
        "def flatten_biases(model):\n",
        "\n",
        "    w = torch.cat([ param.detach().flatten()\n",
        "                    for name, param in model.named_parameters()\n",
        "                    if 'bias' in name ])\n",
        "\n",
        "    return w\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "id": "vf1_8iUf0ujl",
        "outputId": "7cc68c0e-461e-4192-d053-c75228f7b4c2"
      },
      "outputs": [],
      "source": [
        "# %% Exercise 2\n",
        "#    Continue ...\n",
        "\n",
        "# Get biases\n",
        "b0 = flatten_biases(model_0).numpy()\n",
        "b1 = flatten_biases(model_1).numpy()\n",
        "b2 = flatten_biases(model_2).numpy()\n",
        "b3 = flatten_biases(model_3).numpy()\n",
        "\n",
        "# Plotting\n",
        "phi = (1 + np.sqrt(5)) / 2\n",
        "fig = plt.figure(figsize=(1.5*phi*5,5))\n",
        "\n",
        "plt.plot(b0,'o',markersize=9,label='no seed')\n",
        "plt.plot(b2,'^',markersize=9,label='seed b')\n",
        "plt.plot(b1,'s',markersize=9,label='seed a')\n",
        "plt.plot(b3,'+',markersize=9,label='seed a',markeredgewidth=3)\n",
        "\n",
        "plt.axhline(y=0,color='grey',linestyle=':',linewidth=0.8)\n",
        "\n",
        "plt.legend()\n",
        "plt.xlabel('Vectorized weight index')\n",
        "plt.ylabel('Weight value')\n",
        "plt.title(\"Random (seeded) biases for four networks\")\n",
        "\n",
        "plt.savefig('figure38_code_challenge_23_extra2.png')\n",
        "plt.show()\n",
        "files.download('figure38_code_challenge_23_extra2.png')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
