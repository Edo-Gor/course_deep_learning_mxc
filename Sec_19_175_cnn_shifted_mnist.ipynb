{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tc0TUnlTsAoF"
      },
      "outputs": [],
      "source": [
        "# %% Deep learning - Section 19.175\n",
        "#    CNN on shifted MNIST\n",
        "\n",
        "# This code pertains a deep learning course provided by Mike X. Cohen on Udemy:\n",
        "#   > https://www.udemy.com/course/deeplearning_x\n",
        "# The \"base\" code in this repository is adapted (with very minor modifications)\n",
        "# from code developed by the course instructor (Mike X. Cohen), while the\n",
        "# \"exercises\" and the \"code challenges\" contain more original solutions and\n",
        "# creative input from my side. If you are interested in DL (and if you are\n",
        "# reading this statement, chances are that you are), go check out the course, it\n",
        "# is singularly good.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Q549Ew7bsLpw"
      },
      "outputs": [],
      "source": [
        "# %% Libraries and modules\n",
        "import numpy                  as np\n",
        "import matplotlib.pyplot      as plt\n",
        "import torch\n",
        "import torch.nn               as nn\n",
        "import seaborn                as sns\n",
        "import copy\n",
        "import torch.nn.functional    as F\n",
        "import pandas                 as pd\n",
        "import scipy.stats            as stats\n",
        "import sklearn.metrics        as skm\n",
        "import time\n",
        "import sys\n",
        "import imageio.v2             as imageio\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "\n",
        "from torch.utils.data                 import DataLoader,TensorDataset,Dataset\n",
        "from sklearn.model_selection          import train_test_split\n",
        "from google.colab                     import files\n",
        "from torchsummary                     import summary\n",
        "from scipy.stats                      import zscore\n",
        "from sklearn.decomposition            import PCA\n",
        "from scipy.signal                     import convolve2d\n",
        "from torchsummary                     import summary\n",
        "from IPython                          import display\n",
        "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
        "set_matplotlib_formats('svg')\n",
        "plt.style.use('default')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "knwvXS8h95_O"
      },
      "outputs": [],
      "source": [
        "# %% Data\n",
        "\n",
        "# Load data\n",
        "data = np.loadtxt(open('sample_data/mnist_train_small.csv','rb'),delimiter=',')\n",
        "\n",
        "# Split labels from data\n",
        "labels = data[:,0]\n",
        "data   = data[:,1:]\n",
        "\n",
        "# Normalise data (original range is (0,255))\n",
        "data_norm = data / np.max(data)\n",
        "\n",
        "# Reshape to 2D actual images\n",
        "data_norm = data_norm.reshape(data_norm.shape[0],1,28,28)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "nU52ps8G-i-g"
      },
      "outputs": [],
      "source": [
        "# %% Create train and test datasets\n",
        "\n",
        "# Convert to tensor (float and integers)\n",
        "data_tensor   = torch.tensor(data_norm).float()\n",
        "labels_tensor = torch.tensor(labels).long()\n",
        "\n",
        "# Split data with scikitlearn (10% test data)\n",
        "train_data,test_data,train_labels,test_labels = train_test_split(data_tensor,labels_tensor,test_size=0.1)\n",
        "\n",
        "# Convert to PyTorch datasets\n",
        "train_data = TensorDataset(train_data,train_labels)\n",
        "test_data  = TensorDataset(test_data,test_labels)\n",
        "\n",
        "# Convert into DataLoader objects\n",
        "batch_size   = 32\n",
        "train_loader = DataLoader(train_data,batch_size=batch_size,shuffle=True,drop_last=True)\n",
        "test_loader  = DataLoader(test_data,batch_size=test_data.tensors[0].shape[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "bPOnQtHD_khX",
        "outputId": "09d3073d-d7d2-43db-ae1a-d76603325388"
      },
      "outputs": [],
      "source": [
        "# %% How to shift an image\n",
        "\n",
        "# Grab one 2D image\n",
        "tmp = test_loader.dataset.tensors[0][0,:,:].squeeze()\n",
        "\n",
        "# Shift the image (pytorch calls it \"rolling\"), dim=0 for vertical shift\n",
        "tmpS = torch.roll(tmp,8,dims=1)\n",
        "\n",
        "# Plot\n",
        "phi = ( 1 + np.sqrt(5) ) / 2\n",
        "fig,ax = plt.subplots(1,2,figsize=(1.5*5*phi,5))\n",
        "\n",
        "ax[0].imshow(tmp, cmap='gray')\n",
        "ax[0].set_title('Original')\n",
        "\n",
        "ax[1].imshow(tmpS, cmap='gray')\n",
        "ax[1].set_title('Shifted (rolled)')\n",
        "\n",
        "plt.savefig('figure4_cnn_shifted_mnist.png')\n",
        "plt.show()\n",
        "files.download('figure4_cnn_shifted_mnist.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "I_wXRCxSGAab"
      },
      "outputs": [],
      "source": [
        "# %% Shift all images in the train set\n",
        "\n",
        "# Train set\n",
        "for i in range(train_loader.dataset.tensors[0].shape[0]):\n",
        "\n",
        "    # Get the image\n",
        "    img = train_loader.dataset.tensors[0][i,0,:,:]\n",
        "\n",
        "    # Reshape and roll by max. 10 pixels\n",
        "    rand_roll = np.random.randint(-10,11)\n",
        "    img       = torch.roll( img,rand_roll,dims=1 )\n",
        "\n",
        "    # Put back into the matrix\n",
        "    train_loader.dataset.tensors[0][i,0,:,:] = img\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "WfLe7kNOBDqe"
      },
      "outputs": [],
      "source": [
        "# %% Shift all images in the test set\n",
        "# Note: you can re-run the previous cell to confirm the shifting\n",
        "\n",
        "# Test set\n",
        "for i in range(test_loader.dataset.tensors[0].shape[0]):\n",
        "\n",
        "    # Get the image\n",
        "    img = test_loader.dataset.tensors[0][i,0,:,:]\n",
        "\n",
        "    # Reshape and roll by max. 10 pixels\n",
        "    rand_roll = np.random.randint(-10,11)\n",
        "    img       = torch.roll( img,rand_roll,dims=1 )\n",
        "\n",
        "    # Put back into the matrix\n",
        "    test_loader.dataset.tensors[0][i,0,:,:] = img\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "ZOLfAYOmBzVP"
      },
      "outputs": [],
      "source": [
        "# %% Function to generate the model\n",
        "\n",
        "def gen_model(printing_toggle=False):\n",
        "\n",
        "    class mnist_CNN(nn.Module):\n",
        "        def __init__(self,printing_toggle):\n",
        "            super().__init__()\n",
        "\n",
        "            # Convolution layer 1\n",
        "            # size = np.floor( (28+2*1-5)/1 )+1 = 26/2 = 13 (divide by 2 because\n",
        "            # will have maxpool with extent 2)\n",
        "            self.conv1 = nn.Conv2d(1,10,kernel_size=5,stride=1,padding=1)\n",
        "\n",
        "            # Convolution layer 2\n",
        "            # size = np.floor( (13+2*1-5)/1 )+1 = 11/2 = 5 (divide by 2 because\n",
        "            # will have maxpool with extent 2)\n",
        "            self.conv2 = nn.Conv2d(10,20,kernel_size=5,stride=1,padding=1)\n",
        "\n",
        "            # Number of units expected in fully connected layer (out of conv2);\n",
        "            # note that fc1 layer has no padding nor kernel, so we set those\n",
        "            # params to be 0 and 1 respectively; we can also square because the\n",
        "            # images are squares\n",
        "            expected_size = np.floor( 5+2*0-1 ) + 1\n",
        "            expected_size = 20*int(expected_size**2)\n",
        "\n",
        "            # Fully connected layer\n",
        "            self.fc1 = nn.Linear(expected_size,50)\n",
        "\n",
        "            # Output layer\n",
        "            self.output = nn.Linear(50,10)\n",
        "\n",
        "            # Toggle for the printing of tensor sizes during forward propagation\n",
        "            self.print = printing_toggle\n",
        "\n",
        "        def forward(self,x):\n",
        "\n",
        "            # Print input layer size\n",
        "            print(f'Input size: {x.shape}') if self.print else None\n",
        "\n",
        "            # MaxPool and ReLu on convolution layer 1\n",
        "            x = F.relu(F.max_pool2d(self.conv1(x),2))\n",
        "            print(f'Conv. layer 1 size: {x.shape}') if self.print else None\n",
        "\n",
        "            # MaxPool and ReLu on convolution layer 2\n",
        "            x = F.relu(F.max_pool2d(self.conv2(x),2))\n",
        "            print(f'Conv. layer 2 size: {x.shape}') if self.print else None\n",
        "\n",
        "            # Vectorise for linear layer\n",
        "            n_units = x.shape.numel() / x.shape[0]\n",
        "            x       = x.view(-1,int(n_units))\n",
        "            print(f'Vectorised conv. 2 layer size: {x.shape}') if self.print else None\n",
        "\n",
        "            # Linear and output layers\n",
        "            x = F.relu(self.fc1(x))\n",
        "            print(f'Linear layer size: {x.shape}') if self.print else None\n",
        "            x = self.output(x)\n",
        "            print(f'Output layer size: {x.shape}') if self.print else None\n",
        "\n",
        "            return x\n",
        "\n",
        "    # Create model instance\n",
        "    CNN = mnist_CNN(printing_toggle)\n",
        "\n",
        "    # Loss function\n",
        "    loss_fun = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Optimizer\n",
        "    optimizer = torch.optim.Adam(CNN.parameters(),lr=0.001)\n",
        "\n",
        "    return CNN,loss_fun,optimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "bZPFb73QCMRY"
      },
      "outputs": [],
      "source": [
        "# %% Function to train the model\n",
        "\n",
        "def train_model():\n",
        "\n",
        "    # Parameters, model instance, inizialise vars\n",
        "    num_epochs = 30\n",
        "    CNN,loss_fun,optimizer = gen_model()\n",
        "\n",
        "    losses    = []\n",
        "    train_acc = []\n",
        "    test_acc  = []\n",
        "\n",
        "    # Loop over epochs\n",
        "    for epoch_i in range(num_epochs):\n",
        "\n",
        "        # Loop over training batches\n",
        "        batch_acc  = []\n",
        "        batch_loss = []\n",
        "\n",
        "        for X,y in train_loader:\n",
        "\n",
        "            # Forward propagation and loss\n",
        "            yHat = CNN(X)\n",
        "            loss = loss_fun(yHat,y)\n",
        "\n",
        "            # Backpropagation\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Loss and accuracy from this batch\n",
        "            batch_loss.append(loss.item())\n",
        "\n",
        "            matches     = torch.argmax(yHat,axis=1) == y\n",
        "            matches_num = matches.float()\n",
        "            accuracy    = 100 * torch.mean(matches_num)\n",
        "            batch_acc.append(accuracy)\n",
        "\n",
        "        losses.append( np.mean(batch_loss) )\n",
        "        train_acc.append( np.mean(batch_acc) )\n",
        "\n",
        "        # Test accuracy\n",
        "        CNN.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            X,y = next(iter(test_loader))\n",
        "            yHat = CNN(X)\n",
        "            test_acc.append( 100*torch.mean((torch.argmax(yHat,axis=1)==y).float()) )\n",
        "\n",
        "        CNN.train()\n",
        "\n",
        "    return train_acc,test_acc,losses,CNN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "RKjwsSprCSOg"
      },
      "outputs": [],
      "source": [
        "# %% Run the model\n",
        "\n",
        "# Takes ~5 mins\n",
        "train_acc,test_acc,losses,CNN = train_model()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "id": "1C2RvVu0CSL3",
        "outputId": "f83a62b4-12d1-47e6-8c59-d3e4f32d51ea"
      },
      "outputs": [],
      "source": [
        "# Plotting\n",
        "\n",
        "phi = (1 + np.sqrt(5)) / 2\n",
        "fig,ax = plt.subplots(1,2,figsize=(1.5*phi*5,5))\n",
        "\n",
        "ax[0].plot(losses,'s-')\n",
        "ax[0].set_xlabel('Epochs')\n",
        "ax[0].set_ylabel('Loss')\n",
        "ax[0].set_title('Model loss')\n",
        "\n",
        "ax[1].plot(train_acc,'s-',label='Train')\n",
        "ax[1].plot(test_acc,'o-',label='Test')\n",
        "ax[1].set_xlabel('Epochs')\n",
        "ax[1].set_ylabel('Accuracy (%)')\n",
        "ax[1].set_title(f'Final model test accuracy: {test_acc[-1]:.2f}%')\n",
        "ax[1].legend()\n",
        "\n",
        "plt.savefig('figure5_cnn_shifted_mnist.png')\n",
        "plt.show()\n",
        "files.download('figure5_cnn_shifted_mnist.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YwFOUnPcCSJR"
      },
      "outputs": [],
      "source": [
        "# %% Exercise 1\n",
        "#    Don't translate the train images; only the test images. How does the model do now? What does this tell you about\n",
        "#    what the model learned during training? (Tip: compare the test performance here to a similar performance in the ANN\n",
        "#    model.)\n",
        "\n",
        "# Well, not sure I was expecting such a drop in the performance, but the test\n",
        "# eccuracy went down to 50%; now, this is still better than the FFN version,\n",
        "# where I had a catastrophic collapse to 30%\n",
        "# Also tried to add only some shifted images to the train dataset, and still\n",
        "# test on only shifted images, in this case the performance jumps back\n",
        "# immediately, so injecting even a small-ish amount of shifted data helps a lot\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "p4I-THRWWWlm"
      },
      "outputs": [],
      "source": [
        "# %% Exercise 1\n",
        "#    Continue ...\n",
        "\n",
        "# Train set (shift ~20% images)\n",
        "for i in range(train_loader.dataset.tensors[0].shape[0]):\n",
        "\n",
        "    # Apply random shift with approx. overall 30% probability\n",
        "    if np.random.rand() < 0.20:\n",
        "\n",
        "        # Get the image\n",
        "        img = train_loader.dataset.tensors[0][i,0,:,:]\n",
        "\n",
        "        # Reshape and roll by max. 10 pixels\n",
        "        rand_roll = np.random.randint(-10,11)\n",
        "        img       = torch.roll( img,rand_roll,dims=1 )\n",
        "\n",
        "        # Put back into the matrix\n",
        "        train_loader.dataset.tensors[0][i,0,:,:] = img\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
