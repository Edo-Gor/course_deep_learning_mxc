{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tc0TUnlTsAoF"
      },
      "outputs": [],
      "source": [
        "# %% Deep learning - Section 18.171\n",
        "#    Image transforms\n",
        "\n",
        "# This code pertains a deep learning course provided by Mike X. Cohen on Udemy:\n",
        "#   > https://www.udemy.com/course/deeplearning_x\n",
        "# The \"base\" code in this repository is adapted (with very minor modifications)\n",
        "# from code developed by the course instructor (Mike X. Cohen), while the\n",
        "# \"exercises\" and the \"code challenges\" contain more original solutions and\n",
        "# creative input from my side. If you are interested in DL (and if you are\n",
        "# reading this statement, chances are that you are), go check out the course, it\n",
        "# is singularly good.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Q549Ew7bsLpw"
      },
      "outputs": [],
      "source": [
        "# %% Libraries and modules\n",
        "import numpy                  as np\n",
        "import matplotlib.pyplot      as plt\n",
        "import torch\n",
        "import torch.nn               as nn\n",
        "import seaborn                as sns\n",
        "import copy\n",
        "import torch.nn.functional    as F\n",
        "import pandas                 as pd\n",
        "import scipy.stats            as stats\n",
        "import sklearn.metrics        as skm\n",
        "import time\n",
        "import sys\n",
        "import imageio.v2             as imageio\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "\n",
        "from torch.utils.data                 import DataLoader,TensorDataset\n",
        "from sklearn.model_selection          import train_test_split\n",
        "from google.colab                     import files\n",
        "from torchsummary                     import summary\n",
        "from scipy.stats                      import zscore\n",
        "from sklearn.decomposition            import PCA\n",
        "from scipy.signal                     import convolve2d\n",
        "from IPython                          import display\n",
        "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
        "set_matplotlib_formats('svg')\n",
        "plt.style.use('default')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3bSowhL5Vm2",
        "outputId": "a2225844-2c2f-424f-9e96-400849823afb"
      },
      "outputs": [],
      "source": [
        "# %% New dataset !\n",
        "\n",
        "cifar10_data = torchvision.datasets.CIFAR10(root='cifar10',download=True)\n",
        "print(cifar10_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtTZ5u6D6Nd3",
        "outputId": "92239a47-c880-4ae2-c2d0-565200c78524"
      },
      "outputs": [],
      "source": [
        "# %% Check dataset\n",
        "\n",
        "# Shape of the dataset (num of images, [size, size], RGB channels)\n",
        "print( cifar10_data.data.shape )\n",
        "\n",
        "# Unique categories\n",
        "print( cifar10_data.classes )\n",
        "\n",
        "# .targets is a list of targets converted to integers\n",
        "print( len(cifar10_data.targets) )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 875
        },
        "id": "w9-_EWyh6nYR",
        "outputId": "daa8fb6c-2a9c-43d7-a17a-933c0e130b6d"
      },
      "outputs": [],
      "source": [
        "# %% Plotting\n",
        "\n",
        "# Inspect a few random images\n",
        "phi = (1 + np.sqrt(5)) / 2\n",
        "fig,axs = plt.subplots(5,5,figsize=(phi*9,9))\n",
        "\n",
        "for ax in axs.flatten():\n",
        "\n",
        "  randidx = np.random.choice(len(cifar10_data.targets))\n",
        "\n",
        "  # extract image and label\n",
        "  pic   = cifar10_data.data[randidx,:,:,:]\n",
        "  label = cifar10_data.classes[cifar10_data.targets[randidx]]\n",
        "\n",
        "  ax.imshow(pic)\n",
        "  ax.text(16,0,label,ha='center',fontweight='bold',color='k',backgroundcolor='y')\n",
        "  ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.savefig('figure26_image_transforms.png')\n",
        "plt.show()\n",
        "files.download('figure26_image_transforms.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULt0VUDa7co7",
        "outputId": "04532656-0212-4b7c-a6f1-00b01c53aeca"
      },
      "outputs": [],
      "source": [
        "# %% Appy some transform\n",
        "\n",
        "# Upsampling and greyscaling\n",
        "Ts = T.Compose([ T.ToTensor(),\n",
        "                 T.Resize(32*4),\n",
        "                 T.Grayscale(num_output_channels=1)  ])\n",
        "\n",
        "# Include the transform in the dataset\n",
        "cifar10_data.transform = Ts\n",
        "\n",
        "# You can also apply the transforms immediately when loading in the data\n",
        "# cifar10_data = torchvision.datasets.CIFAR10(root='cifar10', download=True, transform=Ts)\n",
        "\n",
        "# Nota Bene: adding a transform doesn't change the image data:\n",
        "print(cifar10_data.data[123,:,:,:].shape)\n",
        "\n",
        "# Option 1 to apply transform: apply \"externally\" to an image\n",
        "img_1 = Ts( cifar10_data.data[123,:,:,:] )\n",
        "print(img_1.shape)\n",
        "\n",
        "# Option 2 to apply transform: use the embedded transform method\n",
        "img_2 = cifar10_data.transform( cifar10_data.data[123,:,:,:] )\n",
        "print(img_2.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "FpKXZT7j7clu",
        "outputId": "1ffef572-2a41-45c4-d5a1-88de73ed8492"
      },
      "outputs": [],
      "source": [
        "# %% Plotting\n",
        "\n",
        "phi = (1 + np.sqrt(5)) / 2\n",
        "fig,ax = plt.subplots(1,3,figsize=(phi*6,6))\n",
        "ax[0].imshow(cifar10_data.data[123,:,:,:])\n",
        "ax[0].set_title('Original')\n",
        "\n",
        "ax[1].imshow(torch.squeeze(img_1),cmap='gray')\n",
        "ax[1].set_title('Upsampled 1')\n",
        "\n",
        "ax[2].imshow(torch.squeeze(img_2),cmap='gray')\n",
        "ax[2].set_title('Upsampled 2')\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.savefig('figure27_image_transforms.png')\n",
        "plt.show()\n",
        "files.download('figure27_image_transforms.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "9Ajjezad7cjC"
      },
      "outputs": [],
      "source": [
        "# %% Note about ToTensor() and normalization:\n",
        "\n",
        "# Convert image (e.g. numpy array) into tensor, and also normalise images from a\n",
        "# [1,256] range to a [0,1] range\n",
        "??T.ToTensor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "C7rLrGlC7cdn"
      },
      "outputs": [],
      "source": [
        "# %% Exercise 1\n",
        "#    There are many other transforms available in torchvision: https://pytorch.org/vision/stable/transforms.html\n",
        "#    Many transformations are useful for data preparation and augmentation. We'll cover some of them later in the course,\n",
        "#    but for now, read about RandomCrop(), RandomHorizontalFlip(), and CenterCrop(). Then implement them to understand\n",
        "#    what they do to images.\n",
        "#    Tip: It's probably best to test these transforms separately, and on one test image, as we did above.\n",
        "\n",
        "# RandomCrop(n); n = cropping window size\n",
        "# RandomHorizontalFlip(p); p = probability of flipping\n",
        "# CenterCrop(n); n =\n",
        "\n",
        "# Transform\n",
        "Ts = T.Compose([ T.ToTensor(),\n",
        "                 T.CenterCrop(24),\n",
        "                 T.Grayscale(num_output_channels=1)  ])\n",
        "\n",
        "cifar10_data.transform = Ts\n",
        "img_transformed        = cifar10_data.transform( cifar10_data.data[123,:,:,:] )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "cqB4X_2BSzUQ",
        "outputId": "90a13e19-f6ca-4ecc-fb7c-4750d5ac7943"
      },
      "outputs": [],
      "source": [
        "# %% Exercise 1\n",
        "#    Continue ...\n",
        "\n",
        "# Plotting\n",
        "phi = (1 + np.sqrt(5)) / 2\n",
        "fig,ax = plt.subplots(1,2,figsize=(phi*6,6))\n",
        "ax[0].imshow(cifar10_data.data[123,:,:,:])\n",
        "ax[0].set_title('Original')\n",
        "\n",
        "ax[1].imshow(torch.squeeze(img_transformed),cmap='gray')\n",
        "ax[1].set_title('RandomHorizontalFlip()')\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.savefig('figure28_image_transforms_extra1.png')\n",
        "plt.show()\n",
        "files.download('figure28_image_transforms_extra1.png')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
