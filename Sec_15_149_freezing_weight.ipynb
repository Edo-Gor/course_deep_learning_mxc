{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wXpeehXZypvO"
      },
      "outputs": [],
      "source": [
        "# %% Deep learning - Section 15.146\n",
        "#    Freezing weights during learning\n",
        "\n",
        "# This code pertains a deep learning course provided by Mike X. Cohen on Udemy:\n",
        "#   > https://www.udemy.com/course/deeplearning_x\n",
        "# The \"base\" code in this repository is adapted (with very minor modifications)\n",
        "# from code developed by the course instructor (Mike X. Cohen), while the\n",
        "# \"exercises\" and the \"code challenges\" contain more original solutions and\n",
        "# creative input from my side. If you are interested in DL (and if you are\n",
        "# reading this statement, chances are that you are), go check out the course, it\n",
        "# is singularly good.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qOF67jQJzQGb"
      },
      "outputs": [],
      "source": [
        "# %% Libraries and modules\n",
        "import numpy               as np\n",
        "import matplotlib.pyplot   as plt\n",
        "import torch\n",
        "import torch.nn            as nn\n",
        "import seaborn             as sns\n",
        "import copy\n",
        "import torch.nn.functional as F\n",
        "import pandas              as pd\n",
        "import scipy.stats         as stats\n",
        "import sklearn.metrics     as skm\n",
        "import time\n",
        "\n",
        "from torch.utils.data                 import DataLoader,TensorDataset\n",
        "from sklearn.model_selection          import train_test_split\n",
        "from google.colab                     import files\n",
        "from torchsummary                     import summary\n",
        "from IPython                          import display\n",
        "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
        "set_matplotlib_formats('svg')\n",
        "plt.style.use('default')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "p2NS_KjlGVOR"
      },
      "outputs": [],
      "source": [
        "# %% Data\n",
        "\n",
        "# Load data\n",
        "data = np.loadtxt(open('sample_data/mnist_train_small.csv','rb'),delimiter=',')\n",
        "\n",
        "# Split labels from data\n",
        "labels = data[:,0]\n",
        "data   = data[:,1:]\n",
        "\n",
        "# Normalise data (original range is (0,255))\n",
        "data_norm = data / np.max(data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WHCN8Ql9HkbA"
      },
      "outputs": [],
      "source": [
        "# %% Create train and test datasets\n",
        "\n",
        "# Convert to tensor (float and integers)\n",
        "data_tensor   = torch.tensor(data_norm).float()\n",
        "labels_tensor = torch.tensor(labels).long()\n",
        "\n",
        "# Split data with scikitlearn (10% test data)\n",
        "train_data,test_data,train_labels,test_labels = train_test_split(data_tensor,labels_tensor,test_size=0.1)\n",
        "\n",
        "# Convert to PyTorch datasets\n",
        "train_data = TensorDataset(train_data,train_labels)\n",
        "test_data  = TensorDataset(test_data,test_labels)\n",
        "\n",
        "# Convert into DataLoader objects\n",
        "batch_size   = 32\n",
        "train_loader = DataLoader(train_data,batch_size=batch_size,shuffle=True,drop_last=True)\n",
        "test_loader  = DataLoader(test_data,batch_size=test_data.tensors[0].shape[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ABwKA8hrHrvY"
      },
      "outputs": [],
      "source": [
        "# %% Model class\n",
        "\n",
        "def gen_model():\n",
        "\n",
        "    class mnist_FFN(nn.Module):\n",
        "        def __init__(self):\n",
        "            super().__init__()\n",
        "\n",
        "            # Architecture\n",
        "            self.input   = nn.Linear(784,64)\n",
        "            self.hidden1 = nn.Linear(64,32)\n",
        "            self.hidden2 = nn.Linear(32,32)\n",
        "            self.output  = nn.Linear(32,10)\n",
        "\n",
        "        # Forward propagation\n",
        "        def forward(self,x):\n",
        "\n",
        "            x = F.relu(self.input(x))\n",
        "            x = F.relu(self.hidden1(x))\n",
        "            x = F.relu(self.hidden2(x))\n",
        "            x = self.output(x)\n",
        "\n",
        "            return x\n",
        "\n",
        "\n",
        "    # Generate model instance\n",
        "    ANN = mnist_FFN()\n",
        "\n",
        "    # Loss function\n",
        "    loss_fun = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Optimizer (SGD and small lr for illustration purposes)\n",
        "    optimizer = torch.optim.SGD(ANN.parameters(),lr=0.001)\n",
        "\n",
        "    return ANN,loss_fun,optimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOz-Aw81ITkm",
        "outputId": "58dc3f9f-33fc-4d66-8a0a-41e6d4de5dc6"
      },
      "outputs": [],
      "source": [
        "# %% Inspect requires_grad\n",
        "\n",
        "ANN = gen_model()[0]\n",
        "print(ANN.hidden1.weight.requires_grad)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcwO5leEIrqF",
        "outputId": "6ea6fe08-513c-49b6-df5c-efbb80296f7f"
      },
      "outputs": [],
      "source": [
        "# %% Freeze one layer\n",
        "\n",
        "ANN = gen_model()[0]\n",
        "\n",
        "for p in ANN.named_parameters():\n",
        "    if 'input' not in p[0]:\n",
        "        p[1].requires_grad = False\n",
        "\n",
        "for p in ANN.named_parameters():\n",
        "    print(\"requires_grad status in layer %s: %s\" %(p[0],p[1].requires_grad))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "KV1XRNDxpKQD"
      },
      "outputs": [],
      "source": [
        "# %% Function to train the model with some frozen layers\n",
        "\n",
        "def train_model(ANN,loss_fun,optimizer):\n",
        "\n",
        "    # Parameters, inizialise vars\n",
        "    num_epochs = 100\n",
        "\n",
        "    losses    = []\n",
        "    train_acc = []\n",
        "    test_acc  = []\n",
        "\n",
        "    # Loop over epochs\n",
        "    for epoch_i in range(num_epochs):\n",
        "\n",
        "        # Switch off g.d. in all but the output layers during the first half epochs\n",
        "        if epoch_i < (num_epochs/2):\n",
        "            for p in ANN.named_parameters():\n",
        "                if 'output' not in p[0]:\n",
        "                    p[1].requires_grad = False\n",
        "        else:\n",
        "            for p in ANN.named_parameters():\n",
        "                p[1].requires_grad = True\n",
        "\n",
        "        # Loop over training batches\n",
        "        batch_acc  = []\n",
        "        batch_loss = []\n",
        "\n",
        "        for X,y in train_loader:\n",
        "\n",
        "            # Forward propagation and loss\n",
        "            yHat = ANN(X)\n",
        "            loss = loss_fun(yHat,y)\n",
        "\n",
        "            # Backpropagation\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Loss and accuracy from this batch\n",
        "            batch_loss.append(loss.item())\n",
        "\n",
        "            matches     = torch.argmax(yHat,axis=1) == y\n",
        "            matches_num = matches.float()\n",
        "            accuracy    = 100 * torch.mean(matches_num)\n",
        "            batch_acc.append(accuracy)\n",
        "\n",
        "        losses.append( np.mean(batch_loss) )\n",
        "        train_acc.append( np.mean(batch_acc) )\n",
        "\n",
        "        # Test accuracy\n",
        "        ANN.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            X,y = next(iter(test_loader))\n",
        "            yHat = ANN(X)\n",
        "            test_acc.append( 100*torch.mean((torch.argmax(yHat,axis=1)==y).float()) )\n",
        "\n",
        "        ANN.train()\n",
        "\n",
        "    return train_acc,test_acc,losses,ANN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "cZ5SqIzVIrm8"
      },
      "outputs": [],
      "source": [
        "# %% Let's see what happens\n",
        "\n",
        "# Model instance and fitting\n",
        "ANN,loss_fun,optimizer = gen_model()\n",
        "train_acc,test_acc,losses,ANN = train_model(ANN,loss_fun,optimizer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "6YKAlKGSJgBb",
        "outputId": "bd5a0a56-ad1b-4398-e1b5-f0908ed15566"
      },
      "outputs": [],
      "source": [
        "# Plotting\n",
        "\n",
        "phi = (1+np.sqrt(5))/2\n",
        "plt.figure(figsize=(phi*5,5))\n",
        "\n",
        "plt.plot(train_acc,label='Train')\n",
        "plt.plot(test_acc,label='Test')\n",
        "plt.axvline(x=len(train_acc)/2,color='grey',linestyle=':',linewidth=0.8,label='g.d. switched on')\n",
        "\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.legend()\n",
        "\n",
        "plt.savefig('figure39_freezing_weights.png')\n",
        "plt.show()\n",
        "files.download('figure39_freezing_weights.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "kA7sPChCLT2t"
      },
      "outputs": [],
      "source": [
        "# %% Exercise 1\n",
        "#    Switch off all the weights, but leave all the biases switched on. Can the model still learn (at least, better than\n",
        "#    chance level)? Then do the opposite: let the weights learn but turn off learnign in the biases. How does the model\n",
        "#    perform now, and what does this tell you about weights vs. biases?\n",
        "\n",
        "# %% Function to train the model freezing the weights accordingly\n",
        "def train_model(ANN,loss_fun,optimizer):\n",
        "\n",
        "    num_epochs = 100\n",
        "\n",
        "    losses    = []\n",
        "    train_acc = []\n",
        "    test_acc  = []\n",
        "\n",
        "    for epoch_i in range(num_epochs):\n",
        "\n",
        "        if epoch_i < (num_epochs/2):\n",
        "            for p in ANN.named_parameters():\n",
        "                if 'weight' in p[0]:\n",
        "                    p[1].requires_grad = False\n",
        "        else:\n",
        "            for p in ANN.named_parameters():\n",
        "                p[1].requires_grad = True\n",
        "\n",
        "        batch_acc  = []\n",
        "        batch_loss = []\n",
        "\n",
        "        for X,y in train_loader:\n",
        "\n",
        "            yHat = ANN(X)\n",
        "            loss = loss_fun(yHat,y)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            batch_loss.append(loss.item())\n",
        "\n",
        "            matches     = torch.argmax(yHat,axis=1) == y\n",
        "            matches_num = matches.float()\n",
        "            accuracy    = 100 * torch.mean(matches_num)\n",
        "            batch_acc.append(accuracy)\n",
        "\n",
        "        losses.append( np.mean(batch_loss) )\n",
        "        train_acc.append( np.mean(batch_acc) )\n",
        "\n",
        "        ANN.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            X,y = next(iter(test_loader))\n",
        "            yHat = ANN(X)\n",
        "            test_acc.append( 100*torch.mean((torch.argmax(yHat,axis=1)==y).float()) )\n",
        "\n",
        "        ANN.train()\n",
        "\n",
        "    return train_acc,test_acc,losses,ANN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "_E5nw4MIL6Me"
      },
      "outputs": [],
      "source": [
        "# %% Exercise 2\n",
        "#    Freeze only one layer, e.g., layer fc1 (freeze both the weights and biases). Store the accuracy output as a separate\n",
        "#    variable, so you run the network again without freezing anything. Then plot the accuracies (with and without\n",
        "#    freezing) on the same graph. How important is fc1 based on this plot?\n",
        "\n",
        "# %% Function to train the model freezing the weights accordingly\n",
        "def train_model(ANN,loss_fun,optimizer):\n",
        "\n",
        "    num_epochs = 100\n",
        "\n",
        "    losses    = []\n",
        "    train_acc = []\n",
        "    test_acc  = []\n",
        "\n",
        "    for epoch_i in range(num_epochs):\n",
        "\n",
        "        if epoch_i < (num_epochs/2):\n",
        "            for p in ANN.named_parameters():\n",
        "                if 'hidden1' in p[0]:\n",
        "                    p[1].requires_grad = False\n",
        "        else:\n",
        "            for p in ANN.named_parameters():\n",
        "                p[1].requires_grad = True\n",
        "\n",
        "        batch_acc  = []\n",
        "        batch_loss = []\n",
        "\n",
        "        for X,y in train_loader:\n",
        "\n",
        "            yHat = ANN(X)\n",
        "            loss = loss_fun(yHat,y)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            batch_loss.append(loss.item())\n",
        "\n",
        "            matches     = torch.argmax(yHat,axis=1) == y\n",
        "            matches_num = matches.float()\n",
        "            accuracy    = 100 * torch.mean(matches_num)\n",
        "            batch_acc.append(accuracy)\n",
        "\n",
        "        losses.append( np.mean(batch_loss) )\n",
        "        train_acc.append( np.mean(batch_acc) )\n",
        "\n",
        "        ANN.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            X,y = next(iter(test_loader))\n",
        "            yHat = ANN(X)\n",
        "            test_acc.append( 100*torch.mean((torch.argmax(yHat,axis=1)==y).float()) )\n",
        "\n",
        "        ANN.train()\n",
        "\n",
        "    return train_acc,test_acc,losses,ANN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "V0IRxz_ZNyFR"
      },
      "outputs": [],
      "source": [
        "# %% Exercise 2\n",
        "#    Continue ...\n",
        "\n",
        "ANN_extra2,loss_fun,optimizer = gen_model()\n",
        "train_acc_extra2,test_acc_extra2,losses_extra2,ANN_extra2 = train_model(ANN_extra2,loss_fun,optimizer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "enTTMhSBOBvK",
        "outputId": "f1482bd8-59da-4f6b-d9fd-b08ece1fe344"
      },
      "outputs": [],
      "source": [
        "# %% Exercise 2\n",
        "#    Continue ...\n",
        "\n",
        "phi = (1+np.sqrt(5))/2\n",
        "plt.figure(figsize=(phi*5,5))\n",
        "\n",
        "plt.plot(train_acc,label='Train')\n",
        "plt.plot(test_acc,label='Test')\n",
        "plt.plot(train_acc_extra2,'--',color='tab:blue',label='Train hid1 off')\n",
        "plt.plot(test_acc_extra2,'--',color='tab:orange',label='Test hid1 off')\n",
        "plt.axvline(x=len(train_acc)/2,color='grey',linestyle=':',linewidth=0.8,label='g.d. switched on')\n",
        "\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.legend()\n",
        "\n",
        "plt.savefig('figure42_freezing_weights_extra2.png')\n",
        "plt.show()\n",
        "files.download('figure42_freezing_weights_extra2.png')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
